{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea086d2",
   "metadata": {},
   "source": [
    "# Amazon electronics dataset exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfe36f0",
   "metadata": {},
   "source": [
    "## 2018 Amazon Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3461d2",
   "metadata": {},
   "source": [
    "A subset of the Amazon Review Data (2018), the electronics category data is roughly 20M engagements from Amazon users.  \n",
    "\n",
    "*Source*: Justifying recommendations using distantly-labeled reviews and fined-grained aspects\n",
    "Jianmo Ni, Jiacheng Li, Julian McAuley\n",
    "Empirical Methods in Natural Language Processing (EMNLP), 2019, https://nijianmo.github.io/amazon/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e6438",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../data/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/2018/Electronics.csv', nrows=10000, names=[\"item\", \"user\", \"rating\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea0dedc",
   "metadata": {},
   "source": [
    "Ratings only: These datasets include no metadata or reviews, but only (item,user,rating,timestamp) tuples. Thus they are suitable for use with mymedialite (or similar) packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f848cfe3",
   "metadata": {},
   "source": [
    "Hmm... are the four columns sufficient for our system? Can we infer a purchase based on the presence of a rating? Do we assume a user with no rating for a product failed to purchase? Yeesh... that doesn't seem supportable. I guess the prediction here is not whether they bought it but whether they were motivated to source a review. Here the review becomes the reward, not the sale ... go off and read the paper: https://cseweb.ucsd.edu/~jmcauley/pdfs/emnlp19a.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94334a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.item.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c026314",
   "metadata": {},
   "source": [
    "## 2023 Amazon Reviews Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863ccb77",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb8aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh ../data/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f123f848",
   "metadata": {},
   "source": [
    "2023 publication, see https://amazon-reviews-2023.github.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2ffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1256a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_json('../data/2023/Electronics.jsonl', lines=True, nrows=100, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d4e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to reduce the size of this dataset or risk blowing our memory budget, filter down to essentials for our prediction task \n",
    "!cd ../data/2023 && jq -c '{rating, parent_asin, user_id, timestamp}' Electronics.jsonl > Electronics_min.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bdce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_json('../data/2023/Electronics_min.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e732bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_parquet(\"../data/2023/Electronics_min.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ee691",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reviews.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad4e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_json(\"../data/2023/meta_Electronics.jsonl\", lines=True, nrows=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844fb19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down to essential fields\n",
    "!cd ../data/2023 && jq -c '{title, average_rating, description, price, images, rating_number, parent_asin}' meta_Electronics.jsonl > meta_Electronics_min.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f5bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this for whatever reason burns about 30G of RAM during the load, even though the json is only 2.8G uncompressed, we should get this into a parquet file stat\n",
    "items = pd.read_json(\"../data/2023/meta_Electronics.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d5e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "items.drop(['main_category', 'features', 'videos', 'store', 'categories', 'details', 'bought_together', 'subtitle', 'author'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d36c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b19f1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "items.price = items.price.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a714bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "items.to_parquet(\"../data/2023/meta_Electronics.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040dd5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "items.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "items.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per the dataset documentation: Note: Products with different colors, styles, sizes usually belong to the same parent ID. \n",
    "# The “asin” in previous Amazon datasets is actually parent ID. Please use parent ID to find product meta.\n",
    "item = reviews.iloc[5].parent_asin\n",
    "items[items.parent_asin == item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beab1229",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[reviews.parent_asin == items.iloc[1].parent_asin]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fed92af",
   "metadata": {},
   "source": [
    "I can't load the entirety of the reviews in one shot... but I can fit every item in memory. So every review will be grounded to an item, but many reviews will be hidden. I don't think this matters for this project. If I want to fit more reviews, I can simply preprocess the data to rejct unneeded fields and (notably text fields) and dramatically reduce memory requirements. I can alternatively load only the critical columns, yes? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
