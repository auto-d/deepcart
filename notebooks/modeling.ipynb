{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ad0120",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6aea5c",
   "metadata": {},
   "source": [
    "Python version spiral ... \n",
    "- > tf 2.11.0 introduced changes that break recommenders integration, need to step back in time \n",
    "- pyenv install 3.9\n",
    "- pyenv virtualenv 3.9 recommenders\n",
    "- pyenv uninstall recommenders\n",
    "- pyenv activate recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83962e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env TF_USE_LEGACY_KERAS=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "914076d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1862e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_parquet(\"../data/processed/reviews_small.parquet\")\n",
    "items = pd.read_parquet(\"../data/processed/items_small.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8255337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>5</td>\n",
       "      <td>B07SMNZK8H</td>\n",
       "      <td>AGJY4LG74YJEJBVWIPIMIZ464ELA</td>\n",
       "      <td>2020-08-08 18:36:03.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>5</td>\n",
       "      <td>B081B15L2D</td>\n",
       "      <td>AGJY4LG74YJEJBVWIPIMIZ464ELA</td>\n",
       "      <td>2020-01-15 02:13:23.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>4</td>\n",
       "      <td>B076WXJPQ1</td>\n",
       "      <td>AGJY4LG74YJEJBVWIPIMIZ464ELA</td>\n",
       "      <td>2020-01-15 02:07:49.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>5</td>\n",
       "      <td>B08KZ1TZYB</td>\n",
       "      <td>AGJY4LG74YJEJBVWIPIMIZ464ELA</td>\n",
       "      <td>2020-01-15 01:37:19.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>5</td>\n",
       "      <td>B07961C64Q</td>\n",
       "      <td>AGJY4LG74YJEJBVWIPIMIZ464ELA</td>\n",
       "      <td>2020-01-15 01:34:23.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992866</th>\n",
       "      <td>2</td>\n",
       "      <td>B08LKZ27C9</td>\n",
       "      <td>AGZD4JETABL3LFXWWHAKX4LTZLYA</td>\n",
       "      <td>2021-09-17 02:12:14.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992867</th>\n",
       "      <td>2</td>\n",
       "      <td>B0BVH2SZRZ</td>\n",
       "      <td>AGZD4JETABL3LFXWWHAKX4LTZLYA</td>\n",
       "      <td>2021-08-08 23:14:55.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992868</th>\n",
       "      <td>3</td>\n",
       "      <td>B002GAXWFW</td>\n",
       "      <td>AGZD4JETABL3LFXWWHAKX4LTZLYA</td>\n",
       "      <td>2019-02-02 02:34:43.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992869</th>\n",
       "      <td>4</td>\n",
       "      <td>B013PKPP24</td>\n",
       "      <td>AGZD4JETABL3LFXWWHAKX4LTZLYA</td>\n",
       "      <td>2015-12-15 20:10:16.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992870</th>\n",
       "      <td>5</td>\n",
       "      <td>B003DKL57G</td>\n",
       "      <td>AGZD4JETABL3LFXWWHAKX4LTZLYA</td>\n",
       "      <td>2015-04-24 18:57:36.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196325 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating     item_id                       user_id  \\\n",
       "2458          5  B07SMNZK8H  AGJY4LG74YJEJBVWIPIMIZ464ELA   \n",
       "2459          5  B081B15L2D  AGJY4LG74YJEJBVWIPIMIZ464ELA   \n",
       "2460          4  B076WXJPQ1  AGJY4LG74YJEJBVWIPIMIZ464ELA   \n",
       "2461          5  B08KZ1TZYB  AGJY4LG74YJEJBVWIPIMIZ464ELA   \n",
       "2462          5  B07961C64Q  AGJY4LG74YJEJBVWIPIMIZ464ELA   \n",
       "...         ...         ...                           ...   \n",
       "9992866       2  B08LKZ27C9  AGZD4JETABL3LFXWWHAKX4LTZLYA   \n",
       "9992867       2  B0BVH2SZRZ  AGZD4JETABL3LFXWWHAKX4LTZLYA   \n",
       "9992868       3  B002GAXWFW  AGZD4JETABL3LFXWWHAKX4LTZLYA   \n",
       "9992869       4  B013PKPP24  AGZD4JETABL3LFXWWHAKX4LTZLYA   \n",
       "9992870       5  B003DKL57G  AGZD4JETABL3LFXWWHAKX4LTZLYA   \n",
       "\n",
       "                      timestamp  \n",
       "2458    2020-08-08 18:36:03.807  \n",
       "2459    2020-01-15 02:13:23.360  \n",
       "2460    2020-01-15 02:07:49.114  \n",
       "2461    2020-01-15 01:37:19.189  \n",
       "2462    2020-01-15 01:34:23.669  \n",
       "...                         ...  \n",
       "9992866 2021-09-17 02:12:14.502  \n",
       "9992867 2021-08-08 23:14:55.627  \n",
       "9992868 2019-02-02 02:34:43.866  \n",
       "9992869 2015-12-15 20:10:16.000  \n",
       "9992870 2015-04-24 18:57:36.000  \n",
       "\n",
       "[196325 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a83408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>images</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Digi-Tatoo Decal Skin Compatible With MacBook ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>246</td>\n",
       "      <td>[]</td>\n",
       "      <td>19.99</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B07SM135LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NotoCity Compatible with Vivoactive 4 band 22m...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>233</td>\n",
       "      <td>[]</td>\n",
       "      <td>9.99</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B089CNGZCW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QGHXO Band for Garmin Vivofit 4, Soft Silicone...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>707</td>\n",
       "      <td>[Compatibility, Custom designed for your preci...</td>\n",
       "      <td>14.89</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B07BJ7ZZL7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NANW Bands Compatible with Fitbit Versa/Versa ...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4249</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B07PXWYLQX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eForCity Leather Case with Stand for 7-Inch Sa...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>144</td>\n",
       "      <td>[Compatible With Samsung Galaxy Tab 2 P3100 7....</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': None, 'large': 'https://m.media-am...</td>\n",
       "      <td>B00ABEQ6TY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609786</th>\n",
       "      <td>14-15 Inch Waterproof Laptop Tablet Sleeve Bag...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>109</td>\n",
       "      <td>[360° Protective Laptop Sleeve Case Bag, Ultra...</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B0817QF9BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609816</th>\n",
       "      <td>Lekaby Wireless Earbuds Bluetooth 5.3 Headphon...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>162</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B0BZ8K2LJX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609838</th>\n",
       "      <td>Synology DiskStation DS213+</td>\n",
       "      <td>4.3</td>\n",
       "      <td>137</td>\n",
       "      <td>[DiskStation DS213+]</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B0091MHMZ4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609860</th>\n",
       "      <td>16GB Flash Drive, JEVDES 10 Pack Swivel Data S...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>130</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B085L8BYPW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609975</th>\n",
       "      <td>Blaupunkt 200201800007 Palma 190 BT 2DIN Car R...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>199</td>\n",
       "      <td>[Car Radio 2 DIN Bluetooth connection FM RDS T...</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B07RV29QQQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259987 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  average_rating  \\\n",
       "2        Digi-Tatoo Decal Skin Compatible With MacBook ...             4.5   \n",
       "3        NotoCity Compatible with Vivoactive 4 band 22m...             4.5   \n",
       "6        QGHXO Band for Garmin Vivofit 4, Soft Silicone...             4.4   \n",
       "12       NANW Bands Compatible with Fitbit Versa/Versa ...             4.6   \n",
       "13       eForCity Leather Case with Stand for 7-Inch Sa...             3.9   \n",
       "...                                                    ...             ...   \n",
       "1609786  14-15 Inch Waterproof Laptop Tablet Sleeve Bag...             4.6   \n",
       "1609816  Lekaby Wireless Earbuds Bluetooth 5.3 Headphon...             5.0   \n",
       "1609838                        Synology DiskStation DS213+             4.3   \n",
       "1609860  16GB Flash Drive, JEVDES 10 Pack Swivel Data S...             4.6   \n",
       "1609975  Blaupunkt 200201800007 Palma 190 BT 2DIN Car R...             3.8   \n",
       "\n",
       "         rating_number                                        description  \\\n",
       "2                  246                                                 []   \n",
       "3                  233                                                 []   \n",
       "6                  707  [Compatibility, Custom designed for your preci...   \n",
       "12                4249                                                 []   \n",
       "13                 144  [Compatible With Samsung Galaxy Tab 2 P3100 7....   \n",
       "...                ...                                                ...   \n",
       "1609786            109  [360° Protective Laptop Sleeve Case Bag, Ultra...   \n",
       "1609816            162                                                 []   \n",
       "1609838            137                               [DiskStation DS213+]   \n",
       "1609860            130                                                 []   \n",
       "1609975            199  [Car Radio 2 DIN Bluetooth connection FM RDS T...   \n",
       "\n",
       "         price                                             images     item_id  \n",
       "2        19.99  [{'hi_res': 'https://m.media-amazon.com/images...  B07SM135LS  \n",
       "3         9.99  [{'hi_res': 'https://m.media-amazon.com/images...  B089CNGZCW  \n",
       "6        14.89  [{'hi_res': 'https://m.media-amazon.com/images...  B07BJ7ZZL7  \n",
       "12        None  [{'hi_res': 'https://m.media-amazon.com/images...  B07PXWYLQX  \n",
       "13        None  [{'hi_res': None, 'large': 'https://m.media-am...  B00ABEQ6TY  \n",
       "...        ...                                                ...         ...  \n",
       "1609786   None  [{'hi_res': 'https://m.media-amazon.com/images...  B0817QF9BH  \n",
       "1609816   None  [{'hi_res': 'https://m.media-amazon.com/images...  B0BZ8K2LJX  \n",
       "1609838   None  [{'hi_res': 'https://m.media-amazon.com/images...  B0091MHMZ4  \n",
       "1609860   None  [{'hi_res': 'https://m.media-amazon.com/images...  B085L8BYPW  \n",
       "1609975   None  [{'hi_res': 'https://m.media-amazon.com/images...  B07RV29QQQ  \n",
       "\n",
       "[259987 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b94627dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_users(reviews): \n",
    "    \"\"\"\n",
    "    Given reviews, generate a user dataframe     \n",
    "    \"\"\"\n",
    "    users = reviews.groupby(['user_id']).rating.count()\n",
    "    users = pd.DataFrame(users).reset_index()\n",
    "    users.rename(columns={'rating':'ratings'}, inplace=True)\n",
    "    return users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fa2ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = extract_users(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "042fac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items = set(items.item_id)\n",
    "reviews = reviews[reviews.item_id.isin(all_items)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00344bd",
   "metadata": {},
   "source": [
    "❗in the notebook, ratings are thresholded ... do we need to follow suit? what are the ramifications if we don't? OH... in the notebook, a click is an interaction, there's no middle ground. the network is going to operate on 0s or 1s. by leaving low reviews in our matrix, the network would learn to recommend things users have interacted with, but not necessarily positively. our case is the same, a review is an interaction. we're aiming to recommend, and we should not want to recommend low reviews. so filter... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c389eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard reviews by users outside our core group \n",
    "reviews = reviews[reviews.user_id.isin(set(users.user_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "015fcc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>5</td>\n",
       "      <td>B07SMNZK8H</td>\n",
       "      <td>AGJY4LG74YJEJBVWIPIMIZ464ELA</td>\n",
       "      <td>2020-08-08 18:36:03.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>5</td>\n",
       "      <td>B081B15L2D</td>\n",
       "      <td>AGJY4LG74YJEJBVWIPIMIZ464ELA</td>\n",
       "      <td>2020-01-15 02:13:23.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>4</td>\n",
       "      <td>B076WXJPQ1</td>\n",
       "      <td>AGJY4LG74YJEJBVWIPIMIZ464ELA</td>\n",
       "      <td>2020-01-15 02:07:49.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>5</td>\n",
       "      <td>B08KZ1TZYB</td>\n",
       "      <td>AGJY4LG74YJEJBVWIPIMIZ464ELA</td>\n",
       "      <td>2020-01-15 01:37:19.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>5</td>\n",
       "      <td>B07961C64Q</td>\n",
       "      <td>AGJY4LG74YJEJBVWIPIMIZ464ELA</td>\n",
       "      <td>2020-01-15 01:34:23.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992866</th>\n",
       "      <td>2</td>\n",
       "      <td>B08LKZ27C9</td>\n",
       "      <td>AGZD4JETABL3LFXWWHAKX4LTZLYA</td>\n",
       "      <td>2021-09-17 02:12:14.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992867</th>\n",
       "      <td>2</td>\n",
       "      <td>B0BVH2SZRZ</td>\n",
       "      <td>AGZD4JETABL3LFXWWHAKX4LTZLYA</td>\n",
       "      <td>2021-08-08 23:14:55.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992868</th>\n",
       "      <td>3</td>\n",
       "      <td>B002GAXWFW</td>\n",
       "      <td>AGZD4JETABL3LFXWWHAKX4LTZLYA</td>\n",
       "      <td>2019-02-02 02:34:43.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992869</th>\n",
       "      <td>4</td>\n",
       "      <td>B013PKPP24</td>\n",
       "      <td>AGZD4JETABL3LFXWWHAKX4LTZLYA</td>\n",
       "      <td>2015-12-15 20:10:16.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992870</th>\n",
       "      <td>5</td>\n",
       "      <td>B003DKL57G</td>\n",
       "      <td>AGZD4JETABL3LFXWWHAKX4LTZLYA</td>\n",
       "      <td>2015-04-24 18:57:36.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158586 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating     item_id                       user_id  \\\n",
       "2458          5  B07SMNZK8H  AGJY4LG74YJEJBVWIPIMIZ464ELA   \n",
       "2459          5  B081B15L2D  AGJY4LG74YJEJBVWIPIMIZ464ELA   \n",
       "2460          4  B076WXJPQ1  AGJY4LG74YJEJBVWIPIMIZ464ELA   \n",
       "2461          5  B08KZ1TZYB  AGJY4LG74YJEJBVWIPIMIZ464ELA   \n",
       "2462          5  B07961C64Q  AGJY4LG74YJEJBVWIPIMIZ464ELA   \n",
       "...         ...         ...                           ...   \n",
       "9992866       2  B08LKZ27C9  AGZD4JETABL3LFXWWHAKX4LTZLYA   \n",
       "9992867       2  B0BVH2SZRZ  AGZD4JETABL3LFXWWHAKX4LTZLYA   \n",
       "9992868       3  B002GAXWFW  AGZD4JETABL3LFXWWHAKX4LTZLYA   \n",
       "9992869       4  B013PKPP24  AGZD4JETABL3LFXWWHAKX4LTZLYA   \n",
       "9992870       5  B003DKL57G  AGZD4JETABL3LFXWWHAKX4LTZLYA   \n",
       "\n",
       "                      timestamp  \n",
       "2458    2020-08-08 18:36:03.807  \n",
       "2459    2020-01-15 02:13:23.360  \n",
       "2460    2020-01-15 02:07:49.114  \n",
       "2461    2020-01-15 01:37:19.189  \n",
       "2462    2020-01-15 01:34:23.669  \n",
       "...                         ...  \n",
       "9992866 2021-09-17 02:12:14.502  \n",
       "9992867 2021-08-08 23:14:55.627  \n",
       "9992868 2019-02-02 02:34:43.866  \n",
       "9992869 2015-12-15 20:10:16.000  \n",
       "9992870 2015-04-24 18:57:36.000  \n",
       "\n",
       "[158586 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a0a5f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79e2df",
   "metadata": {},
   "source": [
    "### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e447f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a055980",
   "metadata": {},
   "source": [
    "### Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78279fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.datasets.sparse import AffinityMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3727ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop(['timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb1572e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "    \"col_user\": \"user_id\",\n",
    "    \"col_item\": \"item_id\",\n",
    "    \"col_rating\": \"rating\",\n",
    "}\n",
    "ui_sparse = AffinityMatrix(reviews, **header)\n",
    "\n",
    "# This isn't implied by the name, but this densifies the matrix, i.e. we have a contiguous u x i\n",
    "# matrix here (user vector of item ratings) ... though it's actually not clear how the memory is \n",
    "# managed underneath in scipy, the 'dense' array might just be a bunch of pointers to the DFs stored \n",
    "# in the AM object... \n",
    "ui_dense, u_map, i_map = ui_sparse.gen_affinity_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26538469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "28332216\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "print(sys.getsizeof(ui_sparse))\n",
    "print(sys.getsizeof(ui_sparse.df))\n",
    "print(sys.getsizeof(ui_dense))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6594c080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B014MO61ES': 0,\n",
       " 'B00U3FPN4U': 1,\n",
       " 'B0819W2H7V': 2,\n",
       " 'B019G1QAXY': 3,\n",
       " 'B074CV39CZ': 4,\n",
       " 'B0817JDQW5': 5,\n",
       " 'B08GQFGJC4': 6,\n",
       " 'B00CY9Q8AQ': 7,\n",
       " 'B07454F4JH': 8,\n",
       " 'B0C61FTDQR': 9,\n",
       " 'B00BH61UV4': 10,\n",
       " 'B0077RH91M': 11,\n",
       " 'B00PVMSO46': 12,\n",
       " 'B0082E9K7U': 13,\n",
       " 'B07P5JHFB3': 14,\n",
       " 'B00J4NLOOU': 15,\n",
       " 'B0095PZHPE': 16,\n",
       " 'B00Z9QVRS4': 17,\n",
       " 'B01M7NFWQ5': 18,\n",
       " 'B0BRTXHKYZ': 19,\n",
       " 'B00OUM3EL6': 20,\n",
       " 'B00WMLVJ1E': 21,\n",
       " 'B0171MRGME': 22,\n",
       " 'B083JCD7KH': 23,\n",
       " 'B07GGHPKSF': 24,\n",
       " 'B004FWHOE4': 25,\n",
       " 'B09BVNFTTL': 26,\n",
       " 'B00FE9R4DI': 27,\n",
       " 'B00QDF34UO': 28,\n",
       " 'B00U84SJRO': 29,\n",
       " 'B09S3MLR39': 30,\n",
       " 'B07WML2XTD': 31,\n",
       " 'B07XBNWBC1': 32,\n",
       " 'B092S9H4YX': 33,\n",
       " 'B08WRCLXVH': 34,\n",
       " 'B08K1RH6JJ': 35,\n",
       " 'B09GXBB183': 36,\n",
       " 'B0C59KGT61': 37,\n",
       " 'B0C1H1JRCN': 38,\n",
       " 'B07L6KFGND': 39,\n",
       " 'B0BYRMDDCP': 40,\n",
       " 'B0C374C95J': 41,\n",
       " 'B0BTLG3346': 42,\n",
       " 'B00HRUC1OO': 43,\n",
       " 'B00BUN22KC': 44,\n",
       " 'B0C53MJ96J': 45,\n",
       " 'B00CAJUVOE': 46,\n",
       " 'B004OGXY72': 47,\n",
       " 'B00ESDP9DI': 48,\n",
       " 'B08F1P3BCC': 49,\n",
       " 'B08DKZW2FH': 50,\n",
       " 'B0BTHR8VZ5': 51,\n",
       " 'B09Y9NMXZY': 52,\n",
       " 'B0C6GXS3G7': 53,\n",
       " 'B08DMXDPW5': 54,\n",
       " 'B005DP9SQO': 55,\n",
       " 'B08PCCXXJ2': 56,\n",
       " 'B004VM1T5S': 57,\n",
       " 'B0006HVM5E': 58,\n",
       " 'B08YB2CN2M': 59,\n",
       " 'B09CP7GCD3': 60,\n",
       " 'B01LXFFO8O': 61,\n",
       " 'B07CMV4XL2': 62,\n",
       " 'B01F9RGJJO': 63,\n",
       " 'B00V3VAWH6': 64,\n",
       " 'B01NBA9HT2': 65,\n",
       " 'B014GTUA0U': 66,\n",
       " 'B002KL8J8W': 67,\n",
       " 'B08V9VN5Q6': 68,\n",
       " 'B06VX1YGQX': 69,\n",
       " 'B01CL4CUI2': 70,\n",
       " 'B003UBI4XG': 71,\n",
       " 'B0B847CNKF': 72,\n",
       " 'B008XEGXMO': 73,\n",
       " 'B07TT95HRL': 74,\n",
       " 'B01JAGMI7M': 75,\n",
       " 'B08N8GCHGJ': 76,\n",
       " 'B08N1DF9BX': 77,\n",
       " 'B00FXYTLIK': 78,\n",
       " 'B00UVSJU4S': 79,\n",
       " 'B07ZGJ6T7B': 80,\n",
       " 'B009OOWFJ2': 81,\n",
       " 'B00NUB333W': 82,\n",
       " 'B003NR57BY': 83,\n",
       " 'B00QLEI0B0': 84,\n",
       " 'B09WQRRF2B': 85,\n",
       " 'B005L38VRU': 86,\n",
       " 'B00Q64O4KQ': 87,\n",
       " 'B00AKGH9KI': 88,\n",
       " 'B00CAMT26E': 89,\n",
       " 'B008Y18I3I': 90,\n",
       " 'B0C929C5MY': 91,\n",
       " 'B086JXJ1LF': 92,\n",
       " 'B00IOTINE4': 93,\n",
       " 'B09P4KJSTQ': 94,\n",
       " 'B00545WG4O': 95,\n",
       " 'B0CC7TJWFT': 96,\n",
       " 'B00TT3SNHG': 97,\n",
       " 'B003N3GRCQ': 98,\n",
       " 'B00W5Q06VU': 99,\n",
       " 'B00NH13I08': 100,\n",
       " 'B00F3TSH7Q': 101,\n",
       " 'B009WNR13U': 102,\n",
       " 'B00C9UFTGO': 103,\n",
       " 'B00G3NFFP8': 104,\n",
       " 'B0B5FV2J3S': 105,\n",
       " 'B092Y427N8': 106,\n",
       " 'B08YDKRV5S': 107,\n",
       " 'B0068N658Y': 108,\n",
       " 'B083BZS5WS': 109,\n",
       " 'B00DBV28TG': 110,\n",
       " 'B0BRJG6YGL': 111,\n",
       " 'B0CF1Q291V': 112,\n",
       " 'B00OUUXOUY': 113,\n",
       " 'B00OUUXC7O': 114,\n",
       " 'B07T2FNP5N': 115,\n",
       " 'B07YHHRGQY': 116,\n",
       " 'B076DWJCD5': 117,\n",
       " 'B00724W0N2': 118,\n",
       " 'B093ZX6X2W': 119,\n",
       " 'B019QUSKBA': 120,\n",
       " 'B0B9BK7PQN': 121,\n",
       " 'B016UFXLKO': 122,\n",
       " 'B01E3S1E18': 123,\n",
       " 'B097RTX8R9': 124,\n",
       " 'B07HD2W8XL': 125,\n",
       " 'B073HQJBCS': 126,\n",
       " 'B098RJMJTW': 127,\n",
       " 'B09J23MY1Z': 128,\n",
       " 'B01MSL64XG': 129,\n",
       " 'B0BPZFW1JH': 130,\n",
       " 'B012A1VACS': 131,\n",
       " 'B0BXTHNR2K': 132,\n",
       " 'B07F461779': 133,\n",
       " 'B007V9RXFI': 134,\n",
       " 'B08LQ2K8RL': 135,\n",
       " 'B082TZSMH1': 136,\n",
       " 'B013CCTM2E': 137,\n",
       " 'B073V6MVTP': 138,\n",
       " 'B07RG8GR58': 139,\n",
       " 'B01MS39GX8': 140,\n",
       " 'B01N78T39B': 141,\n",
       " 'B01M12RE4A': 142,\n",
       " 'B004K1EDG2': 143,\n",
       " 'B00K8GZED4': 144,\n",
       " 'B00KFAGCWK': 145,\n",
       " 'B07C5XV34B': 146,\n",
       " 'B07P9V8GSH': 147,\n",
       " 'B074CPK9SB': 148,\n",
       " 'B0949SYKMX': 149,\n",
       " 'B094NDM6ZH': 150,\n",
       " 'B00BJH6A1Q': 151,\n",
       " 'B0BTV585F9': 152,\n",
       " 'B00E0ISVLI': 153,\n",
       " 'B07FJGGWJL': 154,\n",
       " 'B0BYSRGFKQ': 155,\n",
       " 'B0B4FPB2ZK': 156,\n",
       " 'B07CLBNM1C': 157,\n",
       " 'B096GT8CJH': 158,\n",
       " 'B00HBJRV5K': 159,\n",
       " 'B07CSHTB9Q': 160,\n",
       " 'B0BGNG1294': 161,\n",
       " 'B07GDXCJLM': 162,\n",
       " 'B00R124LAK': 163,\n",
       " 'B001DFS49U': 164,\n",
       " 'B07C1RSV9C': 165,\n",
       " 'B093SVDY5V': 166,\n",
       " 'B0016AIYU6': 167,\n",
       " 'B007NTT6KG': 168,\n",
       " 'B00U80FUHA': 169,\n",
       " 'B08FVMRW4D': 170,\n",
       " 'B0BXSSK991': 171,\n",
       " 'B011BRUOMO': 172,\n",
       " 'B07RJKTHSG': 173,\n",
       " 'B07GXDLJP9': 174,\n",
       " 'B01I01Z1M2': 175,\n",
       " 'B073V2LY6B': 176,\n",
       " 'B083TH1B45': 177,\n",
       " 'B0C1J8RZ46': 178,\n",
       " 'B074F3M2W8': 179,\n",
       " 'B06XX123SH': 180,\n",
       " 'B07H6NPRBX': 181,\n",
       " 'B071PBN1FD': 182,\n",
       " 'B0866QSW4Q': 183,\n",
       " 'B09Z23GGQ1': 184,\n",
       " 'B0874YZVWK': 185,\n",
       " 'B08J7JPTF7': 186,\n",
       " 'B0BP8D1Z2V': 187,\n",
       " 'B077SF8KMG': 188,\n",
       " 'B08GZYBK6Z': 189,\n",
       " 'B0BQ5JTZ89': 190,\n",
       " 'B00NBUTHJG': 191,\n",
       " 'B0BWRLLXQL': 192,\n",
       " 'B00292BSFI': 193,\n",
       " 'B005058B5Q': 194,\n",
       " 'B00H8JVFCI': 195,\n",
       " 'B08HTNC8PJ': 196,\n",
       " 'B08QMV7BG8': 197,\n",
       " 'B00LX4RJXS': 198,\n",
       " 'B01F9RH0R4': 199,\n",
       " 'B0B1HR8JSR': 200,\n",
       " 'B01FQ5R0PG': 201,\n",
       " 'B07CQ5L73P': 202,\n",
       " 'B005CSOE1G': 203,\n",
       " 'B003TFEHYI': 204,\n",
       " 'B01NBTFNVA': 205,\n",
       " 'B07B6L2QCF': 206,\n",
       " 'B07GV2WKFZ': 207,\n",
       " 'B07TC22618': 208,\n",
       " 'B082SSGL9X': 209,\n",
       " 'B07VT4P7DH': 210,\n",
       " 'B0C2BVCBRV': 211,\n",
       " 'B0BK5KHMSQ': 212,\n",
       " 'B07J6SDCBD': 213,\n",
       " 'B0BTHQLV6Y': 214,\n",
       " 'B0BWCSWSV6': 215,\n",
       " 'B0BT4RYFPC': 216,\n",
       " 'B0C36JZG6Y': 217,\n",
       " 'B0CB61XSBD': 218,\n",
       " 'B0BB2SRNXZ': 219,\n",
       " 'B0BNDP4S74': 220,\n",
       " 'B0B3RRZ5QM': 221,\n",
       " 'B0BJDNMHJ5': 222,\n",
       " 'B09WR8LQGZ': 223,\n",
       " 'B0C2GZJRDC': 224,\n",
       " 'B0B9NYDFL8': 225,\n",
       " 'B0BXSN6644': 226,\n",
       " 'B0BHJRVVF4': 227,\n",
       " 'B0B93RSRLM': 228,\n",
       " 'B00MGMPT9W': 229,\n",
       " 'B074FR426S': 230,\n",
       " 'B09LDBJXZJ': 231,\n",
       " 'B00XO7AK9M': 232,\n",
       " 'B00IZN2E9O': 233,\n",
       " 'B0C8633DBV': 234,\n",
       " 'B0BT1BTW94': 235,\n",
       " 'B00I4DX3G8': 236,\n",
       " 'B01M6DHW26': 237,\n",
       " 'B077W8JVFY': 238,\n",
       " 'B09ZF4LT72': 239,\n",
       " 'B07WMB4XS4': 240,\n",
       " 'B06VW23SKR': 241,\n",
       " 'B075FWTFSR': 242,\n",
       " 'B06ZZD3LF4': 243,\n",
       " 'B09N7SXX1X': 244,\n",
       " 'B08R3X5FKJ': 245,\n",
       " 'B00CBD65WG': 246,\n",
       " 'B0828D3MMZ': 247,\n",
       " 'B07Y1NS6BF': 248,\n",
       " 'B09Z78GX66': 249,\n",
       " 'B0BX4QY3KF': 250,\n",
       " 'B07RGJYJS5': 251,\n",
       " 'B01KW560AG': 252,\n",
       " 'B09Z3BM734': 253,\n",
       " 'B071Y2SG3R': 254,\n",
       " 'B079TSV16M': 255,\n",
       " 'B07PKXBR3X': 256,\n",
       " 'B07CH7916H': 257,\n",
       " 'B071R715MZ': 258,\n",
       " 'B01LWP3001': 259,\n",
       " 'B015OAEQZA': 260,\n",
       " 'B07GZFM1ZM': 261,\n",
       " 'B088KNRJ8L': 262,\n",
       " 'B008J0Z9TA': 263,\n",
       " 'B00I8IVQ9K': 264,\n",
       " 'B008EQYRRY': 265,\n",
       " 'B00EHFJGW2': 266,\n",
       " 'B003VAHYQY': 267,\n",
       " 'B007PLL4CK': 268,\n",
       " 'B01DDIAX1Q': 269,\n",
       " 'B00HEEOQBO': 270,\n",
       " 'B005FVNGRS': 271,\n",
       " 'B07YT5SLJY': 272,\n",
       " 'B00IVPU7KE': 273,\n",
       " 'B07L9PLQKZ': 274,\n",
       " 'B075JZNHTD': 275,\n",
       " 'B074TC662N': 276,\n",
       " 'B01MG4DIDO': 277,\n",
       " 'B00DV56J9W': 278,\n",
       " 'B008Y6LG8W': 279,\n",
       " 'B081729KRH': 280,\n",
       " 'B0BTHV3YSV': 281,\n",
       " 'B002OMB7FE': 282,\n",
       " 'B001UI4RTG': 283,\n",
       " 'B00TEAFQWO': 284,\n",
       " 'B00GS80OQ8': 285,\n",
       " 'B0032HHXVM': 286,\n",
       " 'B00XIOUGZE': 287,\n",
       " 'B001M02TKG': 288,\n",
       " 'B0030MIU16': 289,\n",
       " 'B001FA1O18': 290,\n",
       " 'B00A35X42S': 291,\n",
       " 'B0096M8VR2': 292,\n",
       " 'B00B97758S': 293,\n",
       " 'B01N1WVADE': 294,\n",
       " 'B08L8ZNHRB': 295,\n",
       " 'B08PFW1S1V': 296,\n",
       " 'B073CNPCPY': 297,\n",
       " 'B0BQRNFHCV': 298,\n",
       " 'B0026ZCJN8': 299,\n",
       " 'B07NF6V8SC': 300,\n",
       " 'B06Y63W4SZ': 301,\n",
       " 'B0C6H85C1T': 302,\n",
       " 'B085BL3XH5': 303,\n",
       " 'B097HD4F8Z': 304,\n",
       " 'B08M6DDRM9': 305,\n",
       " 'B099FJB24J': 306,\n",
       " 'B07N4DHFZM': 307,\n",
       " 'B06VVXKYJC': 308,\n",
       " 'B09DTZKZ11': 309,\n",
       " 'B07LGWKX4S': 310,\n",
       " 'B08R6S1M1K': 311,\n",
       " 'B078G91T8X': 312,\n",
       " 'B00E44B18I': 313,\n",
       " 'B08RBNSHM9': 314,\n",
       " 'B0C1TK3YL6': 315,\n",
       " 'B00WUI2L5M': 316,\n",
       " 'B0096WD3S4': 317,\n",
       " 'B005ODKMOC': 318,\n",
       " 'B00N4UQV9W': 319,\n",
       " 'B00WU9POGO': 320,\n",
       " 'B00LE7YA18': 321,\n",
       " 'B07MLP2X79': 322,\n",
       " 'B07CY7NLNN': 323,\n",
       " 'B01F48MVTU': 324,\n",
       " 'B09WDPQZMN': 325,\n",
       " 'B00K372JHC': 326,\n",
       " 'B00HNZJLG4': 327,\n",
       " 'B08P39QZJK': 328,\n",
       " 'B078W38K66': 329,\n",
       " 'B094N8ZB1Z': 330,\n",
       " 'B0BR6PSL9F': 331,\n",
       " 'B010QZD6I6': 332,\n",
       " 'B071FXZBMV': 333,\n",
       " 'B09TWVB2TH': 334,\n",
       " 'B091ZHX225': 335,\n",
       " 'B0BVGG54JF': 336,\n",
       " 'B095LPY78T': 337,\n",
       " 'B0069LY4KG': 338,\n",
       " 'B0BSVCJGJC': 339,\n",
       " 'B0799G7XFJ': 340,\n",
       " 'B08X6FL951': 341,\n",
       " 'B0B59QBY9G': 342,\n",
       " 'B00J8NCVX4': 343,\n",
       " 'B0089E5R0W': 344,\n",
       " 'B005FDXMJS': 345,\n",
       " 'B00UZRVY12': 346,\n",
       " 'B079ZQT987': 347,\n",
       " 'B01L73OEOG': 348,\n",
       " 'B01LVWMZ3P': 349,\n",
       " 'B008PWUP00': 350,\n",
       " 'B01MSTHCDX': 351,\n",
       " 'B00FB50S0Q': 352,\n",
       " 'B07J42S1R1': 353,\n",
       " 'B0113ISNRE': 354,\n",
       " 'B00D9UTZX6': 355,\n",
       " 'B007PWXJ3Q': 356,\n",
       " 'B074DXQ5VL': 357,\n",
       " 'B00D2J8558': 358,\n",
       " 'B089M56XRY': 359,\n",
       " 'B00INNP5VU': 360,\n",
       " 'B01KJ9179Y': 361,\n",
       " 'B073ZBP9RB': 362,\n",
       " 'B07MNXVJ6Q': 363,\n",
       " 'B09VQ4HSHQ': 364,\n",
       " 'B07CH47861': 365,\n",
       " 'B01M3ULMWP': 366,\n",
       " 'B0BPSC5P6N': 367,\n",
       " 'B078RSZ4H9': 368,\n",
       " 'B07L428JNX': 369,\n",
       " 'B00IJ2J2K0': 370,\n",
       " 'B09MTQ5WMM': 371,\n",
       " 'B077GK3TTQ': 372,\n",
       " 'B07K9ZYP84': 373,\n",
       " 'B09RRSC9XF': 374,\n",
       " 'B073W1R4XQ': 375,\n",
       " 'B097QFQ8X3': 376,\n",
       " 'B00EL93M3S': 377,\n",
       " 'B07Z58GD12': 378,\n",
       " 'B08G9TJWW9': 379,\n",
       " 'B09K44M2HJ': 380,\n",
       " 'B07F6NDB5R': 381,\n",
       " 'B00EWCUK98': 382,\n",
       " 'B09BZGJCGD': 383,\n",
       " 'B01ERYKLMQ': 384,\n",
       " 'B00M14VAD4': 385,\n",
       " 'B008RBHP98': 386,\n",
       " 'B00PDLRHFW': 387,\n",
       " 'B00QQYM5O8': 388,\n",
       " 'B08145LN1D': 389,\n",
       " 'B0B6MCKBT3': 390,\n",
       " 'B017LKVMAS': 391,\n",
       " 'B0C1Z2FM57': 392,\n",
       " 'B07PYJ2KNC': 393,\n",
       " 'B09CK33BQF': 394,\n",
       " 'B08J5Y89C7': 395,\n",
       " 'B08TFRX9LM': 396,\n",
       " 'B0C2VZS9YP': 397,\n",
       " 'B0B9BHC6PP': 398,\n",
       " 'B000EI2I76': 399,\n",
       " 'B09FQMRHKT': 400,\n",
       " 'B01HL8LXQ8': 401,\n",
       " 'B07D6L7N1G': 402,\n",
       " 'B01JTLUCAS': 403,\n",
       " 'B01GGGV424': 404,\n",
       " 'B0BVY4JVNG': 405,\n",
       " 'B07V2RK8ZB': 406,\n",
       " 'B00GOZB17G': 407,\n",
       " 'B004USX7EE': 408,\n",
       " 'B01F20RKJG': 409,\n",
       " 'B07KCT9LB5': 410,\n",
       " 'B013WPA6YO': 411,\n",
       " 'B09YLDQS5Y': 412,\n",
       " 'B00PTJ43FU': 413,\n",
       " 'B0BFM4362X': 414,\n",
       " 'B01N6EIQQF': 415,\n",
       " 'B0192Q0U70': 416,\n",
       " 'B00COKNKS8': 417,\n",
       " 'B01D86RR0S': 418,\n",
       " 'B071YYKLW9': 419,\n",
       " 'B079561Z5P': 420,\n",
       " 'B00032Q30Q': 421,\n",
       " 'B01GA0NUBO': 422,\n",
       " 'B00GWVC39W': 423,\n",
       " 'B0B1SWPFZS': 424,\n",
       " 'B0BDP6P82W': 425,\n",
       " 'B00DGRUY3M': 426,\n",
       " 'B008GVOVK0': 427,\n",
       " 'B0177NUYIU': 428,\n",
       " 'B00D9AOU3G': 429,\n",
       " 'B006T9ZKAQ': 430,\n",
       " 'B00AF56QA8': 431,\n",
       " 'B0BDNT2YLK': 432,\n",
       " 'B00RBFRY9C': 433,\n",
       " 'B07QVP9MYK': 434,\n",
       " 'B01LKLWNWA': 435,\n",
       " 'B0BZJGGX2T': 436,\n",
       " 'B0BVR7B323': 437,\n",
       " 'B000X9O8SI': 438,\n",
       " 'B079M94X23': 439,\n",
       " 'B0BYHRL16S': 440,\n",
       " 'B0B8Z9J61N': 441,\n",
       " 'B09G2SFXSZ': 442,\n",
       " 'B083G8QM5V': 443,\n",
       " 'B09RL7NM59': 444,\n",
       " 'B07DNZZCPX': 445,\n",
       " 'B09MK5D6JH': 446,\n",
       " 'B08CLNX58K': 447,\n",
       " 'B07NJDRPB7': 448,\n",
       " 'B08PFQ1L9F': 449,\n",
       " 'B00XJ5JMHU': 450,\n",
       " 'B019FN63OO': 451,\n",
       " 'B07WNJQFP9': 452,\n",
       " 'B0000BYDKO': 453,\n",
       " 'B01LXHZLY7': 454,\n",
       " 'B07S764D9V': 455,\n",
       " 'B093W16MYC': 456,\n",
       " 'B0019R6SO0': 457,\n",
       " 'B0BPMN3FLC': 458,\n",
       " 'B002OKS0M4': 459,\n",
       " 'B08L6G8BWL': 460,\n",
       " 'B0C2P7CNWG': 461,\n",
       " 'B07D7SX9NS': 462,\n",
       " 'B08RLW7918': 463,\n",
       " 'B0BW4PFM58': 464,\n",
       " 'B07PGL2N7J': 465,\n",
       " 'B0BS6KLLT1': 466,\n",
       " 'B07XY2ZKYB': 467,\n",
       " 'B008MWBY6W': 468,\n",
       " 'B0BMQL6DMR': 469,\n",
       " 'B07KTYJ769': 470,\n",
       " 'B07DNSZPXG': 471,\n",
       " 'B0B6HR2RKV': 472,\n",
       " 'B08DJ5BRK5': 473,\n",
       " 'B07DQF8LHL': 474,\n",
       " 'B0791TX5P5': 475,\n",
       " 'B07LBRZ5TH': 476,\n",
       " 'B00EJ3IPWY': 477,\n",
       " 'B00EZMZTBO': 478,\n",
       " 'B00I2GBCCY': 479,\n",
       " 'B00N1OXXLU': 480,\n",
       " 'B0077L8YOO': 481,\n",
       " 'B0171PQLB8': 482,\n",
       " 'B094DS8NKL': 483,\n",
       " 'B07ZZRMLHK': 484,\n",
       " 'B07DJ98GBM': 485,\n",
       " 'B00RH29CJO': 486,\n",
       " 'B0781VC53L': 487,\n",
       " 'B01BH83OOM': 488,\n",
       " 'B017XC4KVW': 489,\n",
       " 'B08XVF418R': 490,\n",
       " 'B008NN54M0': 491,\n",
       " 'B08TR95QWL': 492,\n",
       " 'B08JPQFS1R': 493,\n",
       " 'B00451BQIU': 494,\n",
       " 'B07V5DDC7R': 495,\n",
       " 'B075X8471B': 496,\n",
       " 'B00KNNSKV0': 497,\n",
       " 'B00VAT701W': 498,\n",
       " 'B000IITQCC': 499,\n",
       " 'B002U6KT8U': 500,\n",
       " 'B0040U3MI8': 501,\n",
       " 'B00A3MY7KE': 502,\n",
       " 'B00KSBB7EY': 503,\n",
       " 'B00WUI6D9C': 504,\n",
       " 'B005AZ7BE8': 505,\n",
       " 'B0B58XNL52': 506,\n",
       " 'B01GHF5VS2': 507,\n",
       " 'B01E9AHU8Q': 508,\n",
       " 'B01MDKJXCH': 509,\n",
       " 'B06ZYSMKJ4': 510,\n",
       " 'B002UDK9U6': 511,\n",
       " 'B001AYCNIW': 512,\n",
       " 'B0051VVOB2': 513,\n",
       " 'B0095VP8D4': 514,\n",
       " 'B00CX5P8FC': 515,\n",
       " 'B0055ZCXVE': 516,\n",
       " 'B003KPBRRW': 517,\n",
       " 'B000WG3ZU4': 518,\n",
       " 'B000NWVAFO': 519,\n",
       " 'B0032ALZIQ': 520,\n",
       " 'B003MVZ60I': 521,\n",
       " 'B000CS7UTY': 522,\n",
       " 'B004PA2B6C': 523,\n",
       " 'B07VMZZNZL': 524,\n",
       " 'B00GSUVC1M': 525,\n",
       " 'B00C8T5KOW': 526,\n",
       " 'B008KVUAGU': 527,\n",
       " 'B004X8EO6Q': 528,\n",
       " 'B016PMVM7Q': 529,\n",
       " 'B00TWFHCLE': 530,\n",
       " 'B00FL4EWEK': 531,\n",
       " 'B0BYYJPGQB': 532,\n",
       " 'B07DWLSN96': 533,\n",
       " 'B0063K4NN6': 534,\n",
       " 'B00W4UIEBQ': 535,\n",
       " 'B07VHQW6F3': 536,\n",
       " 'B0C6D2VKPG': 537,\n",
       " 'B00F5NB7MW': 538,\n",
       " 'B09L52XKBD': 539,\n",
       " 'B09YH2K3FL': 540,\n",
       " 'B07961C64Q': 541,\n",
       " 'B08FX38CK9': 542,\n",
       " 'B0BXY6DP5B': 543,\n",
       " 'B07P374FF3': 544,\n",
       " 'B077ZBWFLP': 545,\n",
       " 'B08F98WSWH': 546,\n",
       " 'B001E2KAOO': 547,\n",
       " 'B007TISRBK': 548,\n",
       " 'B0B3CL5JW7': 549,\n",
       " 'B0B7HTGNQK': 550,\n",
       " 'B01IPY2XC0': 551,\n",
       " 'B0BYVZYK4N': 552,\n",
       " 'B07WQW7R35': 553,\n",
       " 'B0C3QSJ8SC': 554,\n",
       " 'B093XL47QG': 555,\n",
       " 'B09Y18L4R6': 556,\n",
       " 'B01DQIDRPW': 557,\n",
       " 'B07PCZV64H': 558,\n",
       " 'B01ECFQ9D0': 559,\n",
       " 'B08CKZ36N7': 560,\n",
       " 'B00PXTSMO4': 561,\n",
       " 'B00RYVA4Y0': 562,\n",
       " 'B00WNEU47U': 563,\n",
       " 'B0047Q9GT4': 564,\n",
       " 'B078BGLCS8': 565,\n",
       " 'B09CDRT7K9': 566,\n",
       " 'B01AOX5MX2': 567,\n",
       " 'B08NT5Y8H9': 568,\n",
       " 'B00FZYT278': 569,\n",
       " 'B07YMTF1VR': 570,\n",
       " 'B094FS4R5Y': 571,\n",
       " 'B093FMQJ73': 572,\n",
       " 'B0BPWG9DBX': 573,\n",
       " 'B08LGGLR31': 574,\n",
       " 'B012SXF71I': 575,\n",
       " 'B00YOX4JU6': 576,\n",
       " 'B07VD3M6M3': 577,\n",
       " 'B088PZR86K': 578,\n",
       " 'B01J94SWWU': 579,\n",
       " 'B0BZKKY978': 580,\n",
       " 'B07SYY1BBJ': 581,\n",
       " 'B01N9FIELY': 582,\n",
       " 'B01GF5ACUG': 583,\n",
       " 'B07BTM75WB': 584,\n",
       " 'B093CYLDBP': 585,\n",
       " 'B07H6JP7PS': 586,\n",
       " 'B0BKR9NMMF': 587,\n",
       " 'B07W8JY5G7': 588,\n",
       " 'B01AWBA8U8': 589,\n",
       " 'B01424SHIG': 590,\n",
       " 'B0030MHWWY': 591,\n",
       " 'B0B787CN26': 592,\n",
       " 'B0BB6R89VF': 593,\n",
       " 'B08VCZDZSP': 594,\n",
       " 'B003L13A7K': 595,\n",
       " 'B0C46HBG9F': 596,\n",
       " 'B07BN3MLNR': 597,\n",
       " 'B005NGQWL2': 598,\n",
       " 'B07SPHKZNN': 599,\n",
       " 'B06XSPNJF8': 600,\n",
       " 'B08JLLLR8B': 601,\n",
       " 'B00FFH4O9Q': 602,\n",
       " 'B00JB31RYK': 603,\n",
       " 'B00WTMYLBG': 604,\n",
       " 'B00MJ1YR8Y': 605,\n",
       " 'B09W4C9496': 606,\n",
       " 'B08G14NBCS': 607,\n",
       " 'B0171RDCWW': 608,\n",
       " 'B082FRKZ8D': 609,\n",
       " 'B081QPYS8J': 610,\n",
       " 'B0BBMDCH3S': 611,\n",
       " 'B00BZC31WQ': 612,\n",
       " 'B000FW60E8': 613,\n",
       " 'B00K73IBHE': 614,\n",
       " 'B075SV7P3Q': 615,\n",
       " 'B071HLJ3G3': 616,\n",
       " 'B0BRZPCQNJ': 617,\n",
       " 'B00SSTHDMI': 618,\n",
       " 'B0C6DLY4S8': 619,\n",
       " 'B07DX77DN3': 620,\n",
       " 'B07MMRTS4S': 621,\n",
       " 'B07VXXBTX4': 622,\n",
       " 'B07PXGQC1Q': 623,\n",
       " 'B0B786PFYJ': 624,\n",
       " 'B07WNKFL24': 625,\n",
       " 'B099V8GPR4': 626,\n",
       " 'B0854CTL5N': 627,\n",
       " 'B0765H4MND': 628,\n",
       " 'B06VX1PKQ7': 629,\n",
       " 'B073JYC4XM': 630,\n",
       " 'B08DJ24VMB': 631,\n",
       " 'B07T575145': 632,\n",
       " 'B08W5G45PR': 633,\n",
       " 'B07S9THRC5': 634,\n",
       " 'B0BSRNZMP9': 635,\n",
       " 'B07HZLHPKP': 636,\n",
       " 'B07176GBXQ': 637,\n",
       " 'B07RR5WZCR': 638,\n",
       " 'B07WGXHRNX': 639,\n",
       " 'B08J7TQ9FL': 640,\n",
       " 'B072QLXK2T': 641,\n",
       " 'B07MLY3JKV': 642,\n",
       " 'B00INO6JX2': 643,\n",
       " 'B00GA2P782': 644,\n",
       " 'B07PDHSLM6': 645,\n",
       " 'B000LP7EQM': 646,\n",
       " 'B0746MDWH9': 647,\n",
       " 'B0199HAOAU': 648,\n",
       " 'B0725ST7D5': 649,\n",
       " 'B075JCG29M': 650,\n",
       " 'B0BN534JBB': 651,\n",
       " 'B08HKGXGML': 652,\n",
       " 'B097D8D6L1': 653,\n",
       " 'B07RFZPZKP': 654,\n",
       " 'B092ZQKPZR': 655,\n",
       " 'B0BZ2NMZDY': 656,\n",
       " 'B01KT301YC': 657,\n",
       " 'B0B59D5468': 658,\n",
       " 'B00BQ5RYI4': 659,\n",
       " 'B07L913BK9': 660,\n",
       " 'B0BSF17PM2': 661,\n",
       " 'B09VS4V18K': 662,\n",
       " 'B006Z394L2': 663,\n",
       " 'B0CB1PRH8C': 664,\n",
       " 'B0076GEMGO': 665,\n",
       " 'B000WOIFGU': 666,\n",
       " 'B0099Y1QM4': 667,\n",
       " 'B088FVVDPL': 668,\n",
       " 'B008AI3XDA': 669,\n",
       " 'B06XQGVJN6': 670,\n",
       " 'B09G3MBH6V': 671,\n",
       " 'B09HGGTNHK': 672,\n",
       " 'B0BXMBWKY3': 673,\n",
       " 'B00EN9Q35A': 674,\n",
       " 'B08HJXQ6KD': 675,\n",
       " 'B00X5P8BJO': 676,\n",
       " 'B07FCKYFRC': 677,\n",
       " 'B00HT9MA1W': 678,\n",
       " 'B06WWL7MPY': 679,\n",
       " 'B01AS57B0I': 680,\n",
       " 'B01N6DC2ZE': 681,\n",
       " 'B0BS1QXF6M': 682,\n",
       " 'B08TMJFSV3': 683,\n",
       " 'B07HRMF9NN': 684,\n",
       " 'B0748J5ZBL': 685,\n",
       " 'B08GHHBPFB': 686,\n",
       " 'B01HIS30OY': 687,\n",
       " 'B0B696YT88': 688,\n",
       " 'B06Y2M9K11': 689,\n",
       " 'B00WUCTEI0': 690,\n",
       " 'B0088HP93A': 691,\n",
       " 'B0060N5LWI': 692,\n",
       " 'B08C29KLVP': 693,\n",
       " 'B0BC264P98': 694,\n",
       " 'B0BS1615YC': 695,\n",
       " 'B07N86MCD2': 696,\n",
       " 'B09H83QHPC': 697,\n",
       " 'B00YCWKBA6': 698,\n",
       " 'B00GFM2Q6S': 699,\n",
       " 'B002ZKTHD4': 700,\n",
       " 'B005DIBHCE': 701,\n",
       " 'B008DZKCQG': 702,\n",
       " 'B07CQ8Z21Z': 703,\n",
       " 'B00449F6I4': 704,\n",
       " 'B00PFQPX5Q': 705,\n",
       " 'B01M4LEEME': 706,\n",
       " 'B00Q3MG05S': 707,\n",
       " 'B00MLZ467A': 708,\n",
       " 'B01FGYVWB0': 709,\n",
       " 'B074M7B4BF': 710,\n",
       " 'B07K4XLFQS': 711,\n",
       " 'B07C1L6S9X': 712,\n",
       " 'B099NY674N': 713,\n",
       " 'B01LYCI04D': 714,\n",
       " 'B0B7XZB7V1': 715,\n",
       " 'B07KFQFDNB': 716,\n",
       " 'B01K8B8YA8': 717,\n",
       " 'B01MZ95PDM': 718,\n",
       " 'B008HFIWGO': 719,\n",
       " 'B00BCUNGZI': 720,\n",
       " 'B00DV56QC2': 721,\n",
       " 'B00KDRQEYQ': 722,\n",
       " 'B00AV4P0CI': 723,\n",
       " 'B00EPIWXYY': 724,\n",
       " 'B0163JVYEW': 725,\n",
       " 'B007TYUTY2': 726,\n",
       " 'B001D8AGA2': 727,\n",
       " 'B017U3LVF2': 728,\n",
       " 'B001DK9LB0': 729,\n",
       " 'B07SDH2Z56': 730,\n",
       " 'B07BTLS3R8': 731,\n",
       " 'B071KYY5K4': 732,\n",
       " 'B07C1M321K': 733,\n",
       " 'B0BHZ1GDVT': 734,\n",
       " 'B010BWYDYA': 735,\n",
       " 'B008I63HDA': 736,\n",
       " 'B011WVCIUA': 737,\n",
       " 'B00FGARIM2': 738,\n",
       " 'B01ND0UV73': 739,\n",
       " 'B079BZQ987': 740,\n",
       " 'B00002EQCW': 741,\n",
       " 'B0B292DC1Z': 742,\n",
       " 'B07KY5GXQT': 743,\n",
       " 'B00ODEU0PY': 744,\n",
       " 'B08P6ZJZM8': 745,\n",
       " 'B00G02YZ2Q': 746,\n",
       " 'B00LJP9JRK': 747,\n",
       " 'B09VNXS8K8': 748,\n",
       " 'B01M15WH9C': 749,\n",
       " 'B00BX0YKX4': 750,\n",
       " 'B006Z0Q2SI': 751,\n",
       " 'B07TLHH7SF': 752,\n",
       " 'B07F73MF9M': 753,\n",
       " 'B07JJCZ3WL': 754,\n",
       " 'B08K2RB5H3': 755,\n",
       " 'B09MF5XZ5V': 756,\n",
       " 'B0756QL4VV': 757,\n",
       " 'B00JO6RO8C': 758,\n",
       " 'B00005T3BD': 759,\n",
       " 'B015XPQ5KK': 760,\n",
       " 'B001GS8G2O': 761,\n",
       " 'B079DQNNM7': 762,\n",
       " 'B000I0RORO': 763,\n",
       " 'B001LDJJ16': 764,\n",
       " 'B000HDJT4S': 765,\n",
       " 'B001GS8FZ2': 766,\n",
       " 'B01LNIA7N2': 767,\n",
       " 'B002VFFA5M': 768,\n",
       " 'B0046EDOWW': 769,\n",
       " 'B002RWJD7A': 770,\n",
       " 'B0BK3LYMR2': 771,\n",
       " 'B0038JECKE': 772,\n",
       " 'B003B3P2BK': 773,\n",
       " 'B0014DUHLO': 774,\n",
       " 'B00XJQWP4Q': 775,\n",
       " 'B003I4FF28': 776,\n",
       " 'B07D8GPPKR': 777,\n",
       " 'B019PZPYK6': 778,\n",
       " 'B07V1W5C7Z': 779,\n",
       " 'B08C2X9JYZ': 780,\n",
       " 'B09V1FT19S': 781,\n",
       " 'B07JW7GT7H': 782,\n",
       " 'B0BDY12FNT': 783,\n",
       " 'B07W36WN5X': 784,\n",
       " 'B01DOB6YW4': 785,\n",
       " 'B01EN1PI8K': 786,\n",
       " 'B007T356BO': 787,\n",
       " 'B07YNMH7ML': 788,\n",
       " 'B008Y92PS4': 789,\n",
       " 'B01KSTSV76': 790,\n",
       " 'B01GEIP95C': 791,\n",
       " 'B076XWP741': 792,\n",
       " 'B00P7Z7SXU': 793,\n",
       " 'B00E0ISM6M': 794,\n",
       " 'B002Y3139I': 795,\n",
       " 'B07DNTNB17': 796,\n",
       " 'B00BS5HM3O': 797,\n",
       " 'B00FB50SBU': 798,\n",
       " 'B00CD4221G': 799,\n",
       " 'B00XIVH2LI': 800,\n",
       " 'B00IYOCBMO': 801,\n",
       " 'B009FGS6LA': 802,\n",
       " 'B009AYLDSU': 803,\n",
       " 'B00XICTJRC': 804,\n",
       " 'B005ERMB0G': 805,\n",
       " 'B0BYSP9676': 806,\n",
       " 'B008422IL0': 807,\n",
       " 'B0015AM38Q': 808,\n",
       " 'B0837QFNC7': 809,\n",
       " 'B001TKAE7O': 810,\n",
       " 'B004H912FC': 811,\n",
       " 'B00UP20VV6': 812,\n",
       " 'B00BONB6SW': 813,\n",
       " 'B01EL0GY1S': 814,\n",
       " 'B004CJ8DKE': 815,\n",
       " 'B00BEBAI4W': 816,\n",
       " 'B008TUQ7SC': 817,\n",
       " 'B00CLZWK64': 818,\n",
       " 'B00UVWUBKQ': 819,\n",
       " 'B000P3M2DK': 820,\n",
       " 'B00G5AEZOQ': 821,\n",
       " 'B09T78HB28': 822,\n",
       " 'B00FJIWK5G': 823,\n",
       " 'B00GY4LKYG': 824,\n",
       " 'B01HY5Y70W': 825,\n",
       " 'B008JOLO4U': 826,\n",
       " 'B087CRZSP3': 827,\n",
       " 'B06Y13JD9F': 828,\n",
       " 'B07GT8QRQ5': 829,\n",
       " 'B095F6DVJ3': 830,\n",
       " 'B089YVVLSW': 831,\n",
       " 'B07R638L8N': 832,\n",
       " 'B0836GHD61': 833,\n",
       " 'B07NW72QY9': 834,\n",
       " 'B07YNGX4WV': 835,\n",
       " 'B071R4R5B8': 836,\n",
       " 'B004VRQNS6': 837,\n",
       " 'B07MLVKBQM': 838,\n",
       " 'B08LH2B5YW': 839,\n",
       " 'B071FC3F3Z': 840,\n",
       " 'B0756HHHL2': 841,\n",
       " 'B0753PV4ZX': 842,\n",
       " 'B07SK6NJWP': 843,\n",
       " 'B07T4LTSZ8': 844,\n",
       " 'B005UVO37U': 845,\n",
       " 'B078HXF9H2': 846,\n",
       " 'B07RZVPTQQ': 847,\n",
       " 'B08L8QYJ8H': 848,\n",
       " 'B094JCVY13': 849,\n",
       " 'B006JH8T3S': 850,\n",
       " 'B09V28P31X': 851,\n",
       " 'B088FPBNQF': 852,\n",
       " 'B07X6KGF9R': 853,\n",
       " 'B09GFT3D9Q': 854,\n",
       " 'B09PY7M8N5': 855,\n",
       " 'B0BCQ9HJQQ': 856,\n",
       " 'B0BWL9DSW2': 857,\n",
       " 'B018XAK3VO': 858,\n",
       " 'B06XCTMSCW': 859,\n",
       " 'B07SNSRF6G': 860,\n",
       " 'B09BDX2C9X': 861,\n",
       " 'B0B5JJCPKF': 862,\n",
       " 'B0BD7FN8K9': 863,\n",
       " 'B08Q2D3XR1': 864,\n",
       " 'B09P2C15L1': 865,\n",
       " 'B001VJYGE0': 866,\n",
       " 'B018XF5MOM': 867,\n",
       " 'B0B7FN67QT': 868,\n",
       " 'B00UJU5MUE': 869,\n",
       " 'B08Y18HY3F': 870,\n",
       " 'B000OG88KY': 871,\n",
       " 'B0BH87ZD9W': 872,\n",
       " 'B00FKTMWDE': 873,\n",
       " 'B00X60CGSU': 874,\n",
       " 'B08HR2VDMS': 875,\n",
       " 'B099RZY28N': 876,\n",
       " 'B006U1YUZE': 877,\n",
       " 'B087Z34F3R': 878,\n",
       " 'B00JJGFRIQ': 879,\n",
       " 'B0BSKR4FML': 880,\n",
       " 'B09DFNP17D': 881,\n",
       " 'B07LC4F4SB': 882,\n",
       " 'B094V36L6Q': 883,\n",
       " 'B07KGVB6D6': 884,\n",
       " 'B07HJB2KSR': 885,\n",
       " 'B007SP2CO2': 886,\n",
       " 'B0042IBAOG': 887,\n",
       " 'B003CFATOW': 888,\n",
       " 'B07HFMZXR4': 889,\n",
       " 'B08LZKSMRH': 890,\n",
       " 'B0B8BFS21H': 891,\n",
       " 'B079SS1CCR': 892,\n",
       " 'B07YH8RQ3F': 893,\n",
       " 'B0B8J17B9L': 894,\n",
       " 'B082W816GW': 895,\n",
       " 'B015ZL5BCK': 896,\n",
       " 'B091J9DG4Z': 897,\n",
       " 'B07F8GP5F4': 898,\n",
       " 'B00XJBDM98': 899,\n",
       " 'B0C144YGXT': 900,\n",
       " 'B07YD2LT9D': 901,\n",
       " 'B08BKGSFXC': 902,\n",
       " 'B07K4PGMLX': 903,\n",
       " 'B005920DVA': 904,\n",
       " 'B09P4Q7JK4': 905,\n",
       " 'B01AI2YGK4': 906,\n",
       " 'B091K4WYD1': 907,\n",
       " 'B00DW1X5JC': 908,\n",
       " 'B00LU1RFLU': 909,\n",
       " 'B0C4NX9MHH': 910,\n",
       " 'B017FW09I8': 911,\n",
       " 'B07CZ6DCZ7': 912,\n",
       " 'B095NVKM7V': 913,\n",
       " 'B00PC07T02': 914,\n",
       " 'B0BBLRRKF7': 915,\n",
       " 'B09G2XYR9Z': 916,\n",
       " 'B084ZFGCMM': 917,\n",
       " 'B0935ZDCYD': 918,\n",
       " 'B01LXJFMGF': 919,\n",
       " 'B07RKNTD28': 920,\n",
       " 'B0C4Y7T5Z3': 921,\n",
       " 'B076919RKR': 922,\n",
       " 'B01NH0FTSM': 923,\n",
       " 'B01NBJW3T5': 924,\n",
       " 'B00K7146RU': 925,\n",
       " 'B0BL8RZJTV': 926,\n",
       " 'B0041OOFE8': 927,\n",
       " 'B01AH0TRTW': 928,\n",
       " 'B0B58Z3PBC': 929,\n",
       " 'B0B3N4KFY3': 930,\n",
       " 'B08FW1JZVB': 931,\n",
       " 'B08HSMSLRH': 932,\n",
       " 'B000VEP3XO': 933,\n",
       " 'B00CBZ8IW4': 934,\n",
       " 'B01CN6L1A6': 935,\n",
       " 'B0064I7J60': 936,\n",
       " 'B0064I7IRK': 937,\n",
       " 'B00A36QZ1Y': 938,\n",
       " 'B077XMJ1C2': 939,\n",
       " 'B0095ZKUD8': 940,\n",
       " 'B0985Y1JMQ': 941,\n",
       " 'B09SXP5VB5': 942,\n",
       " 'B07BX587SD': 943,\n",
       " 'B004M8S73S': 944,\n",
       " 'B0BVH1QB5C': 945,\n",
       " 'B00B2HOVAA': 946,\n",
       " 'B0BSRGRWNG': 947,\n",
       " 'B010Q29OW6': 948,\n",
       " 'B00OUUUIUI': 949,\n",
       " 'B00YPJXONW': 950,\n",
       " 'B00Q3MF9YQ': 951,\n",
       " 'B005979HBM': 952,\n",
       " 'B01D4ZJZTO': 953,\n",
       " 'B00FLLFM0Q': 954,\n",
       " 'B09L6XQF1C': 955,\n",
       " 'B0BXYXD1Q2': 956,\n",
       " 'B07PQTHXW9': 957,\n",
       " 'B008194UIU': 958,\n",
       " 'B011J55MBG': 959,\n",
       " 'B00IVPU7AO': 960,\n",
       " 'B0111SPOXW': 961,\n",
       " 'B00Q00XPII': 962,\n",
       " 'B09JY4SJ2G': 963,\n",
       " 'B002YJW7C4': 964,\n",
       " 'B0091R9XRY': 965,\n",
       " 'B00F19Q7YI': 966,\n",
       " 'B00I2VIR2M': 967,\n",
       " 'B07BXD6MB4': 968,\n",
       " 'B0153CASRY': 969,\n",
       " 'B00GX1R9EA': 970,\n",
       " 'B015WCV70W': 971,\n",
       " 'B092HSPZJ3': 972,\n",
       " 'B0114WOSZA': 973,\n",
       " 'B0C5WYZS7C': 974,\n",
       " 'B07RNSSPWX': 975,\n",
       " 'B09WR3VDZ7': 976,\n",
       " 'B07NJQLQWP': 977,\n",
       " 'B01LY6DEAC': 978,\n",
       " 'B09WQZGBB6': 979,\n",
       " 'B078GWJ44Z': 980,\n",
       " 'B072W6GLLT': 981,\n",
       " 'B0000BVYTV': 982,\n",
       " 'B001M56DI0': 983,\n",
       " 'B001GNC9IQ': 984,\n",
       " 'B074QNVY86': 985,\n",
       " 'B000A0GWN4': 986,\n",
       " 'B07FP8VLXS': 987,\n",
       " 'B004JO16KG': 988,\n",
       " 'B01MQI91Y0': 989,\n",
       " 'B07GB3SGSF': 990,\n",
       " 'B07NZ86T1L': 991,\n",
       " 'B076H2BCVT': 992,\n",
       " 'B01H3F8K1K': 993,\n",
       " 'B01ISM267G': 994,\n",
       " 'B075YDDLCK': 995,\n",
       " 'B010OPRNW8': 996,\n",
       " 'B0BZ33NL7T': 997,\n",
       " 'B004YKAGKQ': 998,\n",
       " 'B0C1YHZNH9': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e558b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "67f96404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_key(dict_, val): \n",
    "    \"\"\"\n",
    "    Return the key associated with a value\n",
    "    \"\"\"\n",
    "    for k, v in dict_.items(): \n",
    "        if v == val: \n",
    "            return k\n",
    "\n",
    "def find_keys(dict_, vals): \n",
    "    \"\"\"\n",
    "    Return the keys associated with a value list\n",
    "    \"\"\"\n",
    "    keys = []\n",
    "    for val in vals: \n",
    "        key = find_key(dict_, val)\n",
    "        if key: \n",
    "            keys.append(key)\n",
    "        else: \n",
    "            print(f\"* find_keys(): WARNING - failed to identify key associated with value {val}, omitting from results!\")\n",
    "    \n",
    "    return keys\n",
    "\n",
    "def map_keys(dict_a, a_vals, dict_b): \n",
    "    \"\"\"\n",
    "    Map unique values in dict A to their corresponding values in \n",
    "    dict B by way of (hopefully) common keys. \n",
    "    \"\"\"\n",
    "    keys = find_keys(dict_a, a_vals)\n",
    "    b_vals = []\n",
    "    for k in keys: \n",
    "        if k in dict_b: \n",
    "            b_vals.append(dict_b[k])\n",
    "        else: \n",
    "            print(f\"* map_keys(): WARNING - failed to map key {k} between dicts, omitting from mapping!\")\n",
    "    \n",
    "    return b_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5bdad492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* find_keys(): WARNING - failed to identify key associated with value 199999, omitting from results!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B00U3FPN4U', 'B0819W2H7V', 'B00W5Q06VU']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_keys(i_map, [1,2,99,199999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "426285a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_map_sub = {\n",
    "\n",
    "#low and in common \n",
    "'B014MO61ES': 14,\n",
    "'B00U3FPN4U': 143,\n",
    "'B0819W2H7V': 23,\n",
    "'B019G1QAXY': 343,\n",
    "'B074CV39CZ': 44,\n",
    "'B0817JDQW5': 554,\n",
    "'B08GQFGJC4': 64,\n",
    "'B00CY9Q8AQ': 7222,\n",
    "'B07454F4JH': 84,\n",
    "'B0C61FTDQR': 49,\n",
    "'B00BH61UV4': 120,\n",
    "'B0077RH91M': 11,\n",
    "'B00PVMSO46': 1442,\n",
    "'B0082E9K7U': 13,\n",
    " \n",
    "#high and in common\n",
    "'B0BRTXHKYZ': 19,\n",
    "'B010OPRNW8': 996,\n",
    "'B0BZ33NL7T': 997,\n",
    "'B004YKAGKQ': 998,\n",
    "\n",
    "#high index, but in common \n",
    "'B010OPRNW8': 111996,\n",
    "'B0BZ33NL7T': 111997,\n",
    "'B004YKAGKQ': 111998,\n",
    "\n",
    "#fake key ... shouldn't map \n",
    "'X07P5JHFB3': 534214,\n",
    "'X00J4NLOOU': 1515,\n",
    "'X0095PZHPE': 14326,\n",
    "'X00Z9QVRS4': 117,\n",
    "'X01M7NFWQ5': 131,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6479cfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B014MO61ES', 'X00J4NLOOU']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_keys(i_map_sub, [14,1515])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f562dd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B014MO61ES': 0,\n",
       " 'B00U3FPN4U': 1,\n",
       " 'B0819W2H7V': 2,\n",
       " 'B019G1QAXY': 3,\n",
       " 'B074CV39CZ': 4,\n",
       " 'B0817JDQW5': 5,\n",
       " 'B08GQFGJC4': 6,\n",
       " 'B00CY9Q8AQ': 7,\n",
       " 'B07454F4JH': 8,\n",
       " 'B0C61FTDQR': 9,\n",
       " 'B00BH61UV4': 10,\n",
       " 'B0077RH91M': 11,\n",
       " 'B00PVMSO46': 12,\n",
       " 'B0082E9K7U': 13,\n",
       " 'B07P5JHFB3': 14,\n",
       " 'B00J4NLOOU': 15,\n",
       " 'B0095PZHPE': 16,\n",
       " 'B00Z9QVRS4': 17,\n",
       " 'B01M7NFWQ5': 18,\n",
       " 'B0BRTXHKYZ': 19,\n",
       " 'B00OUM3EL6': 20,\n",
       " 'B00WMLVJ1E': 21,\n",
       " 'B0171MRGME': 22,\n",
       " 'B083JCD7KH': 23,\n",
       " 'B07GGHPKSF': 24,\n",
       " 'B004FWHOE4': 25,\n",
       " 'B09BVNFTTL': 26,\n",
       " 'B00FE9R4DI': 27,\n",
       " 'B00QDF34UO': 28,\n",
       " 'B00U84SJRO': 29,\n",
       " 'B09S3MLR39': 30,\n",
       " 'B07WML2XTD': 31,\n",
       " 'B07XBNWBC1': 32,\n",
       " 'B092S9H4YX': 33,\n",
       " 'B08WRCLXVH': 34,\n",
       " 'B08K1RH6JJ': 35,\n",
       " 'B09GXBB183': 36,\n",
       " 'B0C59KGT61': 37,\n",
       " 'B0C1H1JRCN': 38,\n",
       " 'B07L6KFGND': 39,\n",
       " 'B0BYRMDDCP': 40,\n",
       " 'B0C374C95J': 41,\n",
       " 'B0BTLG3346': 42,\n",
       " 'B00HRUC1OO': 43,\n",
       " 'B00BUN22KC': 44,\n",
       " 'B0C53MJ96J': 45,\n",
       " 'B00CAJUVOE': 46,\n",
       " 'B004OGXY72': 47,\n",
       " 'B00ESDP9DI': 48,\n",
       " 'B08F1P3BCC': 49,\n",
       " 'B08DKZW2FH': 50,\n",
       " 'B0BTHR8VZ5': 51,\n",
       " 'B09Y9NMXZY': 52,\n",
       " 'B0C6GXS3G7': 53,\n",
       " 'B08DMXDPW5': 54,\n",
       " 'B005DP9SQO': 55,\n",
       " 'B08PCCXXJ2': 56,\n",
       " 'B004VM1T5S': 57,\n",
       " 'B0006HVM5E': 58,\n",
       " 'B08YB2CN2M': 59,\n",
       " 'B09CP7GCD3': 60,\n",
       " 'B01LXFFO8O': 61,\n",
       " 'B07CMV4XL2': 62,\n",
       " 'B01F9RGJJO': 63,\n",
       " 'B00V3VAWH6': 64,\n",
       " 'B01NBA9HT2': 65,\n",
       " 'B014GTUA0U': 66,\n",
       " 'B002KL8J8W': 67,\n",
       " 'B08V9VN5Q6': 68,\n",
       " 'B06VX1YGQX': 69,\n",
       " 'B01CL4CUI2': 70,\n",
       " 'B003UBI4XG': 71,\n",
       " 'B0B847CNKF': 72,\n",
       " 'B008XEGXMO': 73,\n",
       " 'B07TT95HRL': 74,\n",
       " 'B01JAGMI7M': 75,\n",
       " 'B08N8GCHGJ': 76,\n",
       " 'B08N1DF9BX': 77,\n",
       " 'B00FXYTLIK': 78,\n",
       " 'B00UVSJU4S': 79,\n",
       " 'B07ZGJ6T7B': 80,\n",
       " 'B009OOWFJ2': 81,\n",
       " 'B00NUB333W': 82,\n",
       " 'B003NR57BY': 83,\n",
       " 'B00QLEI0B0': 84,\n",
       " 'B09WQRRF2B': 85,\n",
       " 'B005L38VRU': 86,\n",
       " 'B00Q64O4KQ': 87,\n",
       " 'B00AKGH9KI': 88,\n",
       " 'B00CAMT26E': 89,\n",
       " 'B008Y18I3I': 90,\n",
       " 'B0C929C5MY': 91,\n",
       " 'B086JXJ1LF': 92,\n",
       " 'B00IOTINE4': 93,\n",
       " 'B09P4KJSTQ': 94,\n",
       " 'B00545WG4O': 95,\n",
       " 'B0CC7TJWFT': 96,\n",
       " 'B00TT3SNHG': 97,\n",
       " 'B003N3GRCQ': 98,\n",
       " 'B00W5Q06VU': 99,\n",
       " 'B00NH13I08': 100,\n",
       " 'B00F3TSH7Q': 101,\n",
       " 'B009WNR13U': 102,\n",
       " 'B00C9UFTGO': 103,\n",
       " 'B00G3NFFP8': 104,\n",
       " 'B0B5FV2J3S': 105,\n",
       " 'B092Y427N8': 106,\n",
       " 'B08YDKRV5S': 107,\n",
       " 'B0068N658Y': 108,\n",
       " 'B083BZS5WS': 109,\n",
       " 'B00DBV28TG': 110,\n",
       " 'B0BRJG6YGL': 111,\n",
       " 'B0CF1Q291V': 112,\n",
       " 'B00OUUXOUY': 113,\n",
       " 'B00OUUXC7O': 114,\n",
       " 'B07T2FNP5N': 115,\n",
       " 'B07YHHRGQY': 116,\n",
       " 'B076DWJCD5': 117,\n",
       " 'B00724W0N2': 118,\n",
       " 'B093ZX6X2W': 119,\n",
       " 'B019QUSKBA': 120,\n",
       " 'B0B9BK7PQN': 121,\n",
       " 'B016UFXLKO': 122,\n",
       " 'B01E3S1E18': 123,\n",
       " 'B097RTX8R9': 124,\n",
       " 'B07HD2W8XL': 125,\n",
       " 'B073HQJBCS': 126,\n",
       " 'B098RJMJTW': 127,\n",
       " 'B09J23MY1Z': 128,\n",
       " 'B01MSL64XG': 129,\n",
       " 'B0BPZFW1JH': 130,\n",
       " 'B012A1VACS': 131,\n",
       " 'B0BXTHNR2K': 132,\n",
       " 'B07F461779': 133,\n",
       " 'B007V9RXFI': 134,\n",
       " 'B08LQ2K8RL': 135,\n",
       " 'B082TZSMH1': 136,\n",
       " 'B013CCTM2E': 137,\n",
       " 'B073V6MVTP': 138,\n",
       " 'B07RG8GR58': 139,\n",
       " 'B01MS39GX8': 140,\n",
       " 'B01N78T39B': 141,\n",
       " 'B01M12RE4A': 142,\n",
       " 'B004K1EDG2': 143,\n",
       " 'B00K8GZED4': 144,\n",
       " 'B00KFAGCWK': 145,\n",
       " 'B07C5XV34B': 146,\n",
       " 'B07P9V8GSH': 147,\n",
       " 'B074CPK9SB': 148,\n",
       " 'B0949SYKMX': 149,\n",
       " 'B094NDM6ZH': 150,\n",
       " 'B00BJH6A1Q': 151,\n",
       " 'B0BTV585F9': 152,\n",
       " 'B00E0ISVLI': 153,\n",
       " 'B07FJGGWJL': 154,\n",
       " 'B0BYSRGFKQ': 155,\n",
       " 'B0B4FPB2ZK': 156,\n",
       " 'B07CLBNM1C': 157,\n",
       " 'B096GT8CJH': 158,\n",
       " 'B00HBJRV5K': 159,\n",
       " 'B07CSHTB9Q': 160,\n",
       " 'B0BGNG1294': 161,\n",
       " 'B07GDXCJLM': 162,\n",
       " 'B00R124LAK': 163,\n",
       " 'B001DFS49U': 164,\n",
       " 'B07C1RSV9C': 165,\n",
       " 'B093SVDY5V': 166,\n",
       " 'B0016AIYU6': 167,\n",
       " 'B007NTT6KG': 168,\n",
       " 'B00U80FUHA': 169,\n",
       " 'B08FVMRW4D': 170,\n",
       " 'B0BXSSK991': 171,\n",
       " 'B011BRUOMO': 172,\n",
       " 'B07RJKTHSG': 173,\n",
       " 'B07GXDLJP9': 174,\n",
       " 'B01I01Z1M2': 175,\n",
       " 'B073V2LY6B': 176,\n",
       " 'B083TH1B45': 177,\n",
       " 'B0C1J8RZ46': 178,\n",
       " 'B074F3M2W8': 179,\n",
       " 'B06XX123SH': 180,\n",
       " 'B07H6NPRBX': 181,\n",
       " 'B071PBN1FD': 182,\n",
       " 'B0866QSW4Q': 183,\n",
       " 'B09Z23GGQ1': 184,\n",
       " 'B0874YZVWK': 185,\n",
       " 'B08J7JPTF7': 186,\n",
       " 'B0BP8D1Z2V': 187,\n",
       " 'B077SF8KMG': 188,\n",
       " 'B08GZYBK6Z': 189,\n",
       " 'B0BQ5JTZ89': 190,\n",
       " 'B00NBUTHJG': 191,\n",
       " 'B0BWRLLXQL': 192,\n",
       " 'B00292BSFI': 193,\n",
       " 'B005058B5Q': 194,\n",
       " 'B00H8JVFCI': 195,\n",
       " 'B08HTNC8PJ': 196,\n",
       " 'B08QMV7BG8': 197,\n",
       " 'B00LX4RJXS': 198,\n",
       " 'B01F9RH0R4': 199,\n",
       " 'B0B1HR8JSR': 200,\n",
       " 'B01FQ5R0PG': 201,\n",
       " 'B07CQ5L73P': 202,\n",
       " 'B005CSOE1G': 203,\n",
       " 'B003TFEHYI': 204,\n",
       " 'B01NBTFNVA': 205,\n",
       " 'B07B6L2QCF': 206,\n",
       " 'B07GV2WKFZ': 207,\n",
       " 'B07TC22618': 208,\n",
       " 'B082SSGL9X': 209,\n",
       " 'B07VT4P7DH': 210,\n",
       " 'B0C2BVCBRV': 211,\n",
       " 'B0BK5KHMSQ': 212,\n",
       " 'B07J6SDCBD': 213,\n",
       " 'B0BTHQLV6Y': 214,\n",
       " 'B0BWCSWSV6': 215,\n",
       " 'B0BT4RYFPC': 216,\n",
       " 'B0C36JZG6Y': 217,\n",
       " 'B0CB61XSBD': 218,\n",
       " 'B0BB2SRNXZ': 219,\n",
       " 'B0BNDP4S74': 220,\n",
       " 'B0B3RRZ5QM': 221,\n",
       " 'B0BJDNMHJ5': 222,\n",
       " 'B09WR8LQGZ': 223,\n",
       " 'B0C2GZJRDC': 224,\n",
       " 'B0B9NYDFL8': 225,\n",
       " 'B0BXSN6644': 226,\n",
       " 'B0BHJRVVF4': 227,\n",
       " 'B0B93RSRLM': 228,\n",
       " 'B00MGMPT9W': 229,\n",
       " 'B074FR426S': 230,\n",
       " 'B09LDBJXZJ': 231,\n",
       " 'B00XO7AK9M': 232,\n",
       " 'B00IZN2E9O': 233,\n",
       " 'B0C8633DBV': 234,\n",
       " 'B0BT1BTW94': 235,\n",
       " 'B00I4DX3G8': 236,\n",
       " 'B01M6DHW26': 237,\n",
       " 'B077W8JVFY': 238,\n",
       " 'B09ZF4LT72': 239,\n",
       " 'B07WMB4XS4': 240,\n",
       " 'B06VW23SKR': 241,\n",
       " 'B075FWTFSR': 242,\n",
       " 'B06ZZD3LF4': 243,\n",
       " 'B09N7SXX1X': 244,\n",
       " 'B08R3X5FKJ': 245,\n",
       " 'B00CBD65WG': 246,\n",
       " 'B0828D3MMZ': 247,\n",
       " 'B07Y1NS6BF': 248,\n",
       " 'B09Z78GX66': 249,\n",
       " 'B0BX4QY3KF': 250,\n",
       " 'B07RGJYJS5': 251,\n",
       " 'B01KW560AG': 252,\n",
       " 'B09Z3BM734': 253,\n",
       " 'B071Y2SG3R': 254,\n",
       " 'B079TSV16M': 255,\n",
       " 'B07PKXBR3X': 256,\n",
       " 'B07CH7916H': 257,\n",
       " 'B071R715MZ': 258,\n",
       " 'B01LWP3001': 259,\n",
       " 'B015OAEQZA': 260,\n",
       " 'B07GZFM1ZM': 261,\n",
       " 'B088KNRJ8L': 262,\n",
       " 'B008J0Z9TA': 263,\n",
       " 'B00I8IVQ9K': 264,\n",
       " 'B008EQYRRY': 265,\n",
       " 'B00EHFJGW2': 266,\n",
       " 'B003VAHYQY': 267,\n",
       " 'B007PLL4CK': 268,\n",
       " 'B01DDIAX1Q': 269,\n",
       " 'B00HEEOQBO': 270,\n",
       " 'B005FVNGRS': 271,\n",
       " 'B07YT5SLJY': 272,\n",
       " 'B00IVPU7KE': 273,\n",
       " 'B07L9PLQKZ': 274,\n",
       " 'B075JZNHTD': 275,\n",
       " 'B074TC662N': 276,\n",
       " 'B01MG4DIDO': 277,\n",
       " 'B00DV56J9W': 278,\n",
       " 'B008Y6LG8W': 279,\n",
       " 'B081729KRH': 280,\n",
       " 'B0BTHV3YSV': 281,\n",
       " 'B002OMB7FE': 282,\n",
       " 'B001UI4RTG': 283,\n",
       " 'B00TEAFQWO': 284,\n",
       " 'B00GS80OQ8': 285,\n",
       " 'B0032HHXVM': 286,\n",
       " 'B00XIOUGZE': 287,\n",
       " 'B001M02TKG': 288,\n",
       " 'B0030MIU16': 289,\n",
       " 'B001FA1O18': 290,\n",
       " 'B00A35X42S': 291,\n",
       " 'B0096M8VR2': 292,\n",
       " 'B00B97758S': 293,\n",
       " 'B01N1WVADE': 294,\n",
       " 'B08L8ZNHRB': 295,\n",
       " 'B08PFW1S1V': 296,\n",
       " 'B073CNPCPY': 297,\n",
       " 'B0BQRNFHCV': 298,\n",
       " 'B0026ZCJN8': 299,\n",
       " 'B07NF6V8SC': 300,\n",
       " 'B06Y63W4SZ': 301,\n",
       " 'B0C6H85C1T': 302,\n",
       " 'B085BL3XH5': 303,\n",
       " 'B097HD4F8Z': 304,\n",
       " 'B08M6DDRM9': 305,\n",
       " 'B099FJB24J': 306,\n",
       " 'B07N4DHFZM': 307,\n",
       " 'B06VVXKYJC': 308,\n",
       " 'B09DTZKZ11': 309,\n",
       " 'B07LGWKX4S': 310,\n",
       " 'B08R6S1M1K': 311,\n",
       " 'B078G91T8X': 312,\n",
       " 'B00E44B18I': 313,\n",
       " 'B08RBNSHM9': 314,\n",
       " 'B0C1TK3YL6': 315,\n",
       " 'B00WUI2L5M': 316,\n",
       " 'B0096WD3S4': 317,\n",
       " 'B005ODKMOC': 318,\n",
       " 'B00N4UQV9W': 319,\n",
       " 'B00WU9POGO': 320,\n",
       " 'B00LE7YA18': 321,\n",
       " 'B07MLP2X79': 322,\n",
       " 'B07CY7NLNN': 323,\n",
       " 'B01F48MVTU': 324,\n",
       " 'B09WDPQZMN': 325,\n",
       " 'B00K372JHC': 326,\n",
       " 'B00HNZJLG4': 327,\n",
       " 'B08P39QZJK': 328,\n",
       " 'B078W38K66': 329,\n",
       " 'B094N8ZB1Z': 330,\n",
       " 'B0BR6PSL9F': 331,\n",
       " 'B010QZD6I6': 332,\n",
       " 'B071FXZBMV': 333,\n",
       " 'B09TWVB2TH': 334,\n",
       " 'B091ZHX225': 335,\n",
       " 'B0BVGG54JF': 336,\n",
       " 'B095LPY78T': 337,\n",
       " 'B0069LY4KG': 338,\n",
       " 'B0BSVCJGJC': 339,\n",
       " 'B0799G7XFJ': 340,\n",
       " 'B08X6FL951': 341,\n",
       " 'B0B59QBY9G': 342,\n",
       " 'B00J8NCVX4': 343,\n",
       " 'B0089E5R0W': 344,\n",
       " 'B005FDXMJS': 345,\n",
       " 'B00UZRVY12': 346,\n",
       " 'B079ZQT987': 347,\n",
       " 'B01L73OEOG': 348,\n",
       " 'B01LVWMZ3P': 349,\n",
       " 'B008PWUP00': 350,\n",
       " 'B01MSTHCDX': 351,\n",
       " 'B00FB50S0Q': 352,\n",
       " 'B07J42S1R1': 353,\n",
       " 'B0113ISNRE': 354,\n",
       " 'B00D9UTZX6': 355,\n",
       " 'B007PWXJ3Q': 356,\n",
       " 'B074DXQ5VL': 357,\n",
       " 'B00D2J8558': 358,\n",
       " 'B089M56XRY': 359,\n",
       " 'B00INNP5VU': 360,\n",
       " 'B01KJ9179Y': 361,\n",
       " 'B073ZBP9RB': 362,\n",
       " 'B07MNXVJ6Q': 363,\n",
       " 'B09VQ4HSHQ': 364,\n",
       " 'B07CH47861': 365,\n",
       " 'B01M3ULMWP': 366,\n",
       " 'B0BPSC5P6N': 367,\n",
       " 'B078RSZ4H9': 368,\n",
       " 'B07L428JNX': 369,\n",
       " 'B00IJ2J2K0': 370,\n",
       " 'B09MTQ5WMM': 371,\n",
       " 'B077GK3TTQ': 372,\n",
       " 'B07K9ZYP84': 373,\n",
       " 'B09RRSC9XF': 374,\n",
       " 'B073W1R4XQ': 375,\n",
       " 'B097QFQ8X3': 376,\n",
       " 'B00EL93M3S': 377,\n",
       " 'B07Z58GD12': 378,\n",
       " 'B08G9TJWW9': 379,\n",
       " 'B09K44M2HJ': 380,\n",
       " 'B07F6NDB5R': 381,\n",
       " 'B00EWCUK98': 382,\n",
       " 'B09BZGJCGD': 383,\n",
       " 'B01ERYKLMQ': 384,\n",
       " 'B00M14VAD4': 385,\n",
       " 'B008RBHP98': 386,\n",
       " 'B00PDLRHFW': 387,\n",
       " 'B00QQYM5O8': 388,\n",
       " 'B08145LN1D': 389,\n",
       " 'B0B6MCKBT3': 390,\n",
       " 'B017LKVMAS': 391,\n",
       " 'B0C1Z2FM57': 392,\n",
       " 'B07PYJ2KNC': 393,\n",
       " 'B09CK33BQF': 394,\n",
       " 'B08J5Y89C7': 395,\n",
       " 'B08TFRX9LM': 396,\n",
       " 'B0C2VZS9YP': 397,\n",
       " 'B0B9BHC6PP': 398,\n",
       " 'B000EI2I76': 399,\n",
       " 'B09FQMRHKT': 400,\n",
       " 'B01HL8LXQ8': 401,\n",
       " 'B07D6L7N1G': 402,\n",
       " 'B01JTLUCAS': 403,\n",
       " 'B01GGGV424': 404,\n",
       " 'B0BVY4JVNG': 405,\n",
       " 'B07V2RK8ZB': 406,\n",
       " 'B00GOZB17G': 407,\n",
       " 'B004USX7EE': 408,\n",
       " 'B01F20RKJG': 409,\n",
       " 'B07KCT9LB5': 410,\n",
       " 'B013WPA6YO': 411,\n",
       " 'B09YLDQS5Y': 412,\n",
       " 'B00PTJ43FU': 413,\n",
       " 'B0BFM4362X': 414,\n",
       " 'B01N6EIQQF': 415,\n",
       " 'B0192Q0U70': 416,\n",
       " 'B00COKNKS8': 417,\n",
       " 'B01D86RR0S': 418,\n",
       " 'B071YYKLW9': 419,\n",
       " 'B079561Z5P': 420,\n",
       " 'B00032Q30Q': 421,\n",
       " 'B01GA0NUBO': 422,\n",
       " 'B00GWVC39W': 423,\n",
       " 'B0B1SWPFZS': 424,\n",
       " 'B0BDP6P82W': 425,\n",
       " 'B00DGRUY3M': 426,\n",
       " 'B008GVOVK0': 427,\n",
       " 'B0177NUYIU': 428,\n",
       " 'B00D9AOU3G': 429,\n",
       " 'B006T9ZKAQ': 430,\n",
       " 'B00AF56QA8': 431,\n",
       " 'B0BDNT2YLK': 432,\n",
       " 'B00RBFRY9C': 433,\n",
       " 'B07QVP9MYK': 434,\n",
       " 'B01LKLWNWA': 435,\n",
       " 'B0BZJGGX2T': 436,\n",
       " 'B0BVR7B323': 437,\n",
       " 'B000X9O8SI': 438,\n",
       " 'B079M94X23': 439,\n",
       " 'B0BYHRL16S': 440,\n",
       " 'B0B8Z9J61N': 441,\n",
       " 'B09G2SFXSZ': 442,\n",
       " 'B083G8QM5V': 443,\n",
       " 'B09RL7NM59': 444,\n",
       " 'B07DNZZCPX': 445,\n",
       " 'B09MK5D6JH': 446,\n",
       " 'B08CLNX58K': 447,\n",
       " 'B07NJDRPB7': 448,\n",
       " 'B08PFQ1L9F': 449,\n",
       " 'B00XJ5JMHU': 450,\n",
       " 'B019FN63OO': 451,\n",
       " 'B07WNJQFP9': 452,\n",
       " 'B0000BYDKO': 453,\n",
       " 'B01LXHZLY7': 454,\n",
       " 'B07S764D9V': 455,\n",
       " 'B093W16MYC': 456,\n",
       " 'B0019R6SO0': 457,\n",
       " 'B0BPMN3FLC': 458,\n",
       " 'B002OKS0M4': 459,\n",
       " 'B08L6G8BWL': 460,\n",
       " 'B0C2P7CNWG': 461,\n",
       " 'B07D7SX9NS': 462,\n",
       " 'B08RLW7918': 463,\n",
       " 'B0BW4PFM58': 464,\n",
       " 'B07PGL2N7J': 465,\n",
       " 'B0BS6KLLT1': 466,\n",
       " 'B07XY2ZKYB': 467,\n",
       " 'B008MWBY6W': 468,\n",
       " 'B0BMQL6DMR': 469,\n",
       " 'B07KTYJ769': 470,\n",
       " 'B07DNSZPXG': 471,\n",
       " 'B0B6HR2RKV': 472,\n",
       " 'B08DJ5BRK5': 473,\n",
       " 'B07DQF8LHL': 474,\n",
       " 'B0791TX5P5': 475,\n",
       " 'B07LBRZ5TH': 476,\n",
       " 'B00EJ3IPWY': 477,\n",
       " 'B00EZMZTBO': 478,\n",
       " 'B00I2GBCCY': 479,\n",
       " 'B00N1OXXLU': 480,\n",
       " 'B0077L8YOO': 481,\n",
       " 'B0171PQLB8': 482,\n",
       " 'B094DS8NKL': 483,\n",
       " 'B07ZZRMLHK': 484,\n",
       " 'B07DJ98GBM': 485,\n",
       " 'B00RH29CJO': 486,\n",
       " 'B0781VC53L': 487,\n",
       " 'B01BH83OOM': 488,\n",
       " 'B017XC4KVW': 489,\n",
       " 'B08XVF418R': 490,\n",
       " 'B008NN54M0': 491,\n",
       " 'B08TR95QWL': 492,\n",
       " 'B08JPQFS1R': 493,\n",
       " 'B00451BQIU': 494,\n",
       " 'B07V5DDC7R': 495,\n",
       " 'B075X8471B': 496,\n",
       " 'B00KNNSKV0': 497,\n",
       " 'B00VAT701W': 498,\n",
       " 'B000IITQCC': 499,\n",
       " 'B002U6KT8U': 500,\n",
       " 'B0040U3MI8': 501,\n",
       " 'B00A3MY7KE': 502,\n",
       " 'B00KSBB7EY': 503,\n",
       " 'B00WUI6D9C': 504,\n",
       " 'B005AZ7BE8': 505,\n",
       " 'B0B58XNL52': 506,\n",
       " 'B01GHF5VS2': 507,\n",
       " 'B01E9AHU8Q': 508,\n",
       " 'B01MDKJXCH': 509,\n",
       " 'B06ZYSMKJ4': 510,\n",
       " 'B002UDK9U6': 511,\n",
       " 'B001AYCNIW': 512,\n",
       " 'B0051VVOB2': 513,\n",
       " 'B0095VP8D4': 514,\n",
       " 'B00CX5P8FC': 515,\n",
       " 'B0055ZCXVE': 516,\n",
       " 'B003KPBRRW': 517,\n",
       " 'B000WG3ZU4': 518,\n",
       " 'B000NWVAFO': 519,\n",
       " 'B0032ALZIQ': 520,\n",
       " 'B003MVZ60I': 521,\n",
       " 'B000CS7UTY': 522,\n",
       " 'B004PA2B6C': 523,\n",
       " 'B07VMZZNZL': 524,\n",
       " 'B00GSUVC1M': 525,\n",
       " 'B00C8T5KOW': 526,\n",
       " 'B008KVUAGU': 527,\n",
       " 'B004X8EO6Q': 528,\n",
       " 'B016PMVM7Q': 529,\n",
       " 'B00TWFHCLE': 530,\n",
       " 'B00FL4EWEK': 531,\n",
       " 'B0BYYJPGQB': 532,\n",
       " 'B07DWLSN96': 533,\n",
       " 'B0063K4NN6': 534,\n",
       " 'B00W4UIEBQ': 535,\n",
       " 'B07VHQW6F3': 536,\n",
       " 'B0C6D2VKPG': 537,\n",
       " 'B00F5NB7MW': 538,\n",
       " 'B09L52XKBD': 539,\n",
       " 'B09YH2K3FL': 540,\n",
       " 'B07961C64Q': 541,\n",
       " 'B08FX38CK9': 542,\n",
       " 'B0BXY6DP5B': 543,\n",
       " 'B07P374FF3': 544,\n",
       " 'B077ZBWFLP': 545,\n",
       " 'B08F98WSWH': 546,\n",
       " 'B001E2KAOO': 547,\n",
       " 'B007TISRBK': 548,\n",
       " 'B0B3CL5JW7': 549,\n",
       " 'B0B7HTGNQK': 550,\n",
       " 'B01IPY2XC0': 551,\n",
       " 'B0BYVZYK4N': 552,\n",
       " 'B07WQW7R35': 553,\n",
       " 'B0C3QSJ8SC': 554,\n",
       " 'B093XL47QG': 555,\n",
       " 'B09Y18L4R6': 556,\n",
       " 'B01DQIDRPW': 557,\n",
       " 'B07PCZV64H': 558,\n",
       " 'B01ECFQ9D0': 559,\n",
       " 'B08CKZ36N7': 560,\n",
       " 'B00PXTSMO4': 561,\n",
       " 'B00RYVA4Y0': 562,\n",
       " 'B00WNEU47U': 563,\n",
       " 'B0047Q9GT4': 564,\n",
       " 'B078BGLCS8': 565,\n",
       " 'B09CDRT7K9': 566,\n",
       " 'B01AOX5MX2': 567,\n",
       " 'B08NT5Y8H9': 568,\n",
       " 'B00FZYT278': 569,\n",
       " 'B07YMTF1VR': 570,\n",
       " 'B094FS4R5Y': 571,\n",
       " 'B093FMQJ73': 572,\n",
       " 'B0BPWG9DBX': 573,\n",
       " 'B08LGGLR31': 574,\n",
       " 'B012SXF71I': 575,\n",
       " 'B00YOX4JU6': 576,\n",
       " 'B07VD3M6M3': 577,\n",
       " 'B088PZR86K': 578,\n",
       " 'B01J94SWWU': 579,\n",
       " 'B0BZKKY978': 580,\n",
       " 'B07SYY1BBJ': 581,\n",
       " 'B01N9FIELY': 582,\n",
       " 'B01GF5ACUG': 583,\n",
       " 'B07BTM75WB': 584,\n",
       " 'B093CYLDBP': 585,\n",
       " 'B07H6JP7PS': 586,\n",
       " 'B0BKR9NMMF': 587,\n",
       " 'B07W8JY5G7': 588,\n",
       " 'B01AWBA8U8': 589,\n",
       " 'B01424SHIG': 590,\n",
       " 'B0030MHWWY': 591,\n",
       " 'B0B787CN26': 592,\n",
       " 'B0BB6R89VF': 593,\n",
       " 'B08VCZDZSP': 594,\n",
       " 'B003L13A7K': 595,\n",
       " 'B0C46HBG9F': 596,\n",
       " 'B07BN3MLNR': 597,\n",
       " 'B005NGQWL2': 598,\n",
       " 'B07SPHKZNN': 599,\n",
       " 'B06XSPNJF8': 600,\n",
       " 'B08JLLLR8B': 601,\n",
       " 'B00FFH4O9Q': 602,\n",
       " 'B00JB31RYK': 603,\n",
       " 'B00WTMYLBG': 604,\n",
       " 'B00MJ1YR8Y': 605,\n",
       " 'B09W4C9496': 606,\n",
       " 'B08G14NBCS': 607,\n",
       " 'B0171RDCWW': 608,\n",
       " 'B082FRKZ8D': 609,\n",
       " 'B081QPYS8J': 610,\n",
       " 'B0BBMDCH3S': 611,\n",
       " 'B00BZC31WQ': 612,\n",
       " 'B000FW60E8': 613,\n",
       " 'B00K73IBHE': 614,\n",
       " 'B075SV7P3Q': 615,\n",
       " 'B071HLJ3G3': 616,\n",
       " 'B0BRZPCQNJ': 617,\n",
       " 'B00SSTHDMI': 618,\n",
       " 'B0C6DLY4S8': 619,\n",
       " 'B07DX77DN3': 620,\n",
       " 'B07MMRTS4S': 621,\n",
       " 'B07VXXBTX4': 622,\n",
       " 'B07PXGQC1Q': 623,\n",
       " 'B0B786PFYJ': 624,\n",
       " 'B07WNKFL24': 625,\n",
       " 'B099V8GPR4': 626,\n",
       " 'B0854CTL5N': 627,\n",
       " 'B0765H4MND': 628,\n",
       " 'B06VX1PKQ7': 629,\n",
       " 'B073JYC4XM': 630,\n",
       " 'B08DJ24VMB': 631,\n",
       " 'B07T575145': 632,\n",
       " 'B08W5G45PR': 633,\n",
       " 'B07S9THRC5': 634,\n",
       " 'B0BSRNZMP9': 635,\n",
       " 'B07HZLHPKP': 636,\n",
       " 'B07176GBXQ': 637,\n",
       " 'B07RR5WZCR': 638,\n",
       " 'B07WGXHRNX': 639,\n",
       " 'B08J7TQ9FL': 640,\n",
       " 'B072QLXK2T': 641,\n",
       " 'B07MLY3JKV': 642,\n",
       " 'B00INO6JX2': 643,\n",
       " 'B00GA2P782': 644,\n",
       " 'B07PDHSLM6': 645,\n",
       " 'B000LP7EQM': 646,\n",
       " 'B0746MDWH9': 647,\n",
       " 'B0199HAOAU': 648,\n",
       " 'B0725ST7D5': 649,\n",
       " 'B075JCG29M': 650,\n",
       " 'B0BN534JBB': 651,\n",
       " 'B08HKGXGML': 652,\n",
       " 'B097D8D6L1': 653,\n",
       " 'B07RFZPZKP': 654,\n",
       " 'B092ZQKPZR': 655,\n",
       " 'B0BZ2NMZDY': 656,\n",
       " 'B01KT301YC': 657,\n",
       " 'B0B59D5468': 658,\n",
       " 'B00BQ5RYI4': 659,\n",
       " 'B07L913BK9': 660,\n",
       " 'B0BSF17PM2': 661,\n",
       " 'B09VS4V18K': 662,\n",
       " 'B006Z394L2': 663,\n",
       " 'B0CB1PRH8C': 664,\n",
       " 'B0076GEMGO': 665,\n",
       " 'B000WOIFGU': 666,\n",
       " 'B0099Y1QM4': 667,\n",
       " 'B088FVVDPL': 668,\n",
       " 'B008AI3XDA': 669,\n",
       " 'B06XQGVJN6': 670,\n",
       " 'B09G3MBH6V': 671,\n",
       " 'B09HGGTNHK': 672,\n",
       " 'B0BXMBWKY3': 673,\n",
       " 'B00EN9Q35A': 674,\n",
       " 'B08HJXQ6KD': 675,\n",
       " 'B00X5P8BJO': 676,\n",
       " 'B07FCKYFRC': 677,\n",
       " 'B00HT9MA1W': 678,\n",
       " 'B06WWL7MPY': 679,\n",
       " 'B01AS57B0I': 680,\n",
       " 'B01N6DC2ZE': 681,\n",
       " 'B0BS1QXF6M': 682,\n",
       " 'B08TMJFSV3': 683,\n",
       " 'B07HRMF9NN': 684,\n",
       " 'B0748J5ZBL': 685,\n",
       " 'B08GHHBPFB': 686,\n",
       " 'B01HIS30OY': 687,\n",
       " 'B0B696YT88': 688,\n",
       " 'B06Y2M9K11': 689,\n",
       " 'B00WUCTEI0': 690,\n",
       " 'B0088HP93A': 691,\n",
       " 'B0060N5LWI': 692,\n",
       " 'B08C29KLVP': 693,\n",
       " 'B0BC264P98': 694,\n",
       " 'B0BS1615YC': 695,\n",
       " 'B07N86MCD2': 696,\n",
       " 'B09H83QHPC': 697,\n",
       " 'B00YCWKBA6': 698,\n",
       " 'B00GFM2Q6S': 699,\n",
       " 'B002ZKTHD4': 700,\n",
       " 'B005DIBHCE': 701,\n",
       " 'B008DZKCQG': 702,\n",
       " 'B07CQ8Z21Z': 703,\n",
       " 'B00449F6I4': 704,\n",
       " 'B00PFQPX5Q': 705,\n",
       " 'B01M4LEEME': 706,\n",
       " 'B00Q3MG05S': 707,\n",
       " 'B00MLZ467A': 708,\n",
       " 'B01FGYVWB0': 709,\n",
       " 'B074M7B4BF': 710,\n",
       " 'B07K4XLFQS': 711,\n",
       " 'B07C1L6S9X': 712,\n",
       " 'B099NY674N': 713,\n",
       " 'B01LYCI04D': 714,\n",
       " 'B0B7XZB7V1': 715,\n",
       " 'B07KFQFDNB': 716,\n",
       " 'B01K8B8YA8': 717,\n",
       " 'B01MZ95PDM': 718,\n",
       " 'B008HFIWGO': 719,\n",
       " 'B00BCUNGZI': 720,\n",
       " 'B00DV56QC2': 721,\n",
       " 'B00KDRQEYQ': 722,\n",
       " 'B00AV4P0CI': 723,\n",
       " 'B00EPIWXYY': 724,\n",
       " 'B0163JVYEW': 725,\n",
       " 'B007TYUTY2': 726,\n",
       " 'B001D8AGA2': 727,\n",
       " 'B017U3LVF2': 728,\n",
       " 'B001DK9LB0': 729,\n",
       " 'B07SDH2Z56': 730,\n",
       " 'B07BTLS3R8': 731,\n",
       " 'B071KYY5K4': 732,\n",
       " 'B07C1M321K': 733,\n",
       " 'B0BHZ1GDVT': 734,\n",
       " 'B010BWYDYA': 735,\n",
       " 'B008I63HDA': 736,\n",
       " 'B011WVCIUA': 737,\n",
       " 'B00FGARIM2': 738,\n",
       " 'B01ND0UV73': 739,\n",
       " 'B079BZQ987': 740,\n",
       " 'B00002EQCW': 741,\n",
       " 'B0B292DC1Z': 742,\n",
       " 'B07KY5GXQT': 743,\n",
       " 'B00ODEU0PY': 744,\n",
       " 'B08P6ZJZM8': 745,\n",
       " 'B00G02YZ2Q': 746,\n",
       " 'B00LJP9JRK': 747,\n",
       " 'B09VNXS8K8': 748,\n",
       " 'B01M15WH9C': 749,\n",
       " 'B00BX0YKX4': 750,\n",
       " 'B006Z0Q2SI': 751,\n",
       " 'B07TLHH7SF': 752,\n",
       " 'B07F73MF9M': 753,\n",
       " 'B07JJCZ3WL': 754,\n",
       " 'B08K2RB5H3': 755,\n",
       " 'B09MF5XZ5V': 756,\n",
       " 'B0756QL4VV': 757,\n",
       " 'B00JO6RO8C': 758,\n",
       " 'B00005T3BD': 759,\n",
       " 'B015XPQ5KK': 760,\n",
       " 'B001GS8G2O': 761,\n",
       " 'B079DQNNM7': 762,\n",
       " 'B000I0RORO': 763,\n",
       " 'B001LDJJ16': 764,\n",
       " 'B000HDJT4S': 765,\n",
       " 'B001GS8FZ2': 766,\n",
       " 'B01LNIA7N2': 767,\n",
       " 'B002VFFA5M': 768,\n",
       " 'B0046EDOWW': 769,\n",
       " 'B002RWJD7A': 770,\n",
       " 'B0BK3LYMR2': 771,\n",
       " 'B0038JECKE': 772,\n",
       " 'B003B3P2BK': 773,\n",
       " 'B0014DUHLO': 774,\n",
       " 'B00XJQWP4Q': 775,\n",
       " 'B003I4FF28': 776,\n",
       " 'B07D8GPPKR': 777,\n",
       " 'B019PZPYK6': 778,\n",
       " 'B07V1W5C7Z': 779,\n",
       " 'B08C2X9JYZ': 780,\n",
       " 'B09V1FT19S': 781,\n",
       " 'B07JW7GT7H': 782,\n",
       " 'B0BDY12FNT': 783,\n",
       " 'B07W36WN5X': 784,\n",
       " 'B01DOB6YW4': 785,\n",
       " 'B01EN1PI8K': 786,\n",
       " 'B007T356BO': 787,\n",
       " 'B07YNMH7ML': 788,\n",
       " 'B008Y92PS4': 789,\n",
       " 'B01KSTSV76': 790,\n",
       " 'B01GEIP95C': 791,\n",
       " 'B076XWP741': 792,\n",
       " 'B00P7Z7SXU': 793,\n",
       " 'B00E0ISM6M': 794,\n",
       " 'B002Y3139I': 795,\n",
       " 'B07DNTNB17': 796,\n",
       " 'B00BS5HM3O': 797,\n",
       " 'B00FB50SBU': 798,\n",
       " 'B00CD4221G': 799,\n",
       " 'B00XIVH2LI': 800,\n",
       " 'B00IYOCBMO': 801,\n",
       " 'B009FGS6LA': 802,\n",
       " 'B009AYLDSU': 803,\n",
       " 'B00XICTJRC': 804,\n",
       " 'B005ERMB0G': 805,\n",
       " 'B0BYSP9676': 806,\n",
       " 'B008422IL0': 807,\n",
       " 'B0015AM38Q': 808,\n",
       " 'B0837QFNC7': 809,\n",
       " 'B001TKAE7O': 810,\n",
       " 'B004H912FC': 811,\n",
       " 'B00UP20VV6': 812,\n",
       " 'B00BONB6SW': 813,\n",
       " 'B01EL0GY1S': 814,\n",
       " 'B004CJ8DKE': 815,\n",
       " 'B00BEBAI4W': 816,\n",
       " 'B008TUQ7SC': 817,\n",
       " 'B00CLZWK64': 818,\n",
       " 'B00UVWUBKQ': 819,\n",
       " 'B000P3M2DK': 820,\n",
       " 'B00G5AEZOQ': 821,\n",
       " 'B09T78HB28': 822,\n",
       " 'B00FJIWK5G': 823,\n",
       " 'B00GY4LKYG': 824,\n",
       " 'B01HY5Y70W': 825,\n",
       " 'B008JOLO4U': 826,\n",
       " 'B087CRZSP3': 827,\n",
       " 'B06Y13JD9F': 828,\n",
       " 'B07GT8QRQ5': 829,\n",
       " 'B095F6DVJ3': 830,\n",
       " 'B089YVVLSW': 831,\n",
       " 'B07R638L8N': 832,\n",
       " 'B0836GHD61': 833,\n",
       " 'B07NW72QY9': 834,\n",
       " 'B07YNGX4WV': 835,\n",
       " 'B071R4R5B8': 836,\n",
       " 'B004VRQNS6': 837,\n",
       " 'B07MLVKBQM': 838,\n",
       " 'B08LH2B5YW': 839,\n",
       " 'B071FC3F3Z': 840,\n",
       " 'B0756HHHL2': 841,\n",
       " 'B0753PV4ZX': 842,\n",
       " 'B07SK6NJWP': 843,\n",
       " 'B07T4LTSZ8': 844,\n",
       " 'B005UVO37U': 845,\n",
       " 'B078HXF9H2': 846,\n",
       " 'B07RZVPTQQ': 847,\n",
       " 'B08L8QYJ8H': 848,\n",
       " 'B094JCVY13': 849,\n",
       " 'B006JH8T3S': 850,\n",
       " 'B09V28P31X': 851,\n",
       " 'B088FPBNQF': 852,\n",
       " 'B07X6KGF9R': 853,\n",
       " 'B09GFT3D9Q': 854,\n",
       " 'B09PY7M8N5': 855,\n",
       " 'B0BCQ9HJQQ': 856,\n",
       " 'B0BWL9DSW2': 857,\n",
       " 'B018XAK3VO': 858,\n",
       " 'B06XCTMSCW': 859,\n",
       " 'B07SNSRF6G': 860,\n",
       " 'B09BDX2C9X': 861,\n",
       " 'B0B5JJCPKF': 862,\n",
       " 'B0BD7FN8K9': 863,\n",
       " 'B08Q2D3XR1': 864,\n",
       " 'B09P2C15L1': 865,\n",
       " 'B001VJYGE0': 866,\n",
       " 'B018XF5MOM': 867,\n",
       " 'B0B7FN67QT': 868,\n",
       " 'B00UJU5MUE': 869,\n",
       " 'B08Y18HY3F': 870,\n",
       " 'B000OG88KY': 871,\n",
       " 'B0BH87ZD9W': 872,\n",
       " 'B00FKTMWDE': 873,\n",
       " 'B00X60CGSU': 874,\n",
       " 'B08HR2VDMS': 875,\n",
       " 'B099RZY28N': 876,\n",
       " 'B006U1YUZE': 877,\n",
       " 'B087Z34F3R': 878,\n",
       " 'B00JJGFRIQ': 879,\n",
       " 'B0BSKR4FML': 880,\n",
       " 'B09DFNP17D': 881,\n",
       " 'B07LC4F4SB': 882,\n",
       " 'B094V36L6Q': 883,\n",
       " 'B07KGVB6D6': 884,\n",
       " 'B07HJB2KSR': 885,\n",
       " 'B007SP2CO2': 886,\n",
       " 'B0042IBAOG': 887,\n",
       " 'B003CFATOW': 888,\n",
       " 'B07HFMZXR4': 889,\n",
       " 'B08LZKSMRH': 890,\n",
       " 'B0B8BFS21H': 891,\n",
       " 'B079SS1CCR': 892,\n",
       " 'B07YH8RQ3F': 893,\n",
       " 'B0B8J17B9L': 894,\n",
       " 'B082W816GW': 895,\n",
       " 'B015ZL5BCK': 896,\n",
       " 'B091J9DG4Z': 897,\n",
       " 'B07F8GP5F4': 898,\n",
       " 'B00XJBDM98': 899,\n",
       " 'B0C144YGXT': 900,\n",
       " 'B07YD2LT9D': 901,\n",
       " 'B08BKGSFXC': 902,\n",
       " 'B07K4PGMLX': 903,\n",
       " 'B005920DVA': 904,\n",
       " 'B09P4Q7JK4': 905,\n",
       " 'B01AI2YGK4': 906,\n",
       " 'B091K4WYD1': 907,\n",
       " 'B00DW1X5JC': 908,\n",
       " 'B00LU1RFLU': 909,\n",
       " 'B0C4NX9MHH': 910,\n",
       " 'B017FW09I8': 911,\n",
       " 'B07CZ6DCZ7': 912,\n",
       " 'B095NVKM7V': 913,\n",
       " 'B00PC07T02': 914,\n",
       " 'B0BBLRRKF7': 915,\n",
       " 'B09G2XYR9Z': 916,\n",
       " 'B084ZFGCMM': 917,\n",
       " 'B0935ZDCYD': 918,\n",
       " 'B01LXJFMGF': 919,\n",
       " 'B07RKNTD28': 920,\n",
       " 'B0C4Y7T5Z3': 921,\n",
       " 'B076919RKR': 922,\n",
       " 'B01NH0FTSM': 923,\n",
       " 'B01NBJW3T5': 924,\n",
       " 'B00K7146RU': 925,\n",
       " 'B0BL8RZJTV': 926,\n",
       " 'B0041OOFE8': 927,\n",
       " 'B01AH0TRTW': 928,\n",
       " 'B0B58Z3PBC': 929,\n",
       " 'B0B3N4KFY3': 930,\n",
       " 'B08FW1JZVB': 931,\n",
       " 'B08HSMSLRH': 932,\n",
       " 'B000VEP3XO': 933,\n",
       " 'B00CBZ8IW4': 934,\n",
       " 'B01CN6L1A6': 935,\n",
       " 'B0064I7J60': 936,\n",
       " 'B0064I7IRK': 937,\n",
       " 'B00A36QZ1Y': 938,\n",
       " 'B077XMJ1C2': 939,\n",
       " 'B0095ZKUD8': 940,\n",
       " 'B0985Y1JMQ': 941,\n",
       " 'B09SXP5VB5': 942,\n",
       " 'B07BX587SD': 943,\n",
       " 'B004M8S73S': 944,\n",
       " 'B0BVH1QB5C': 945,\n",
       " 'B00B2HOVAA': 946,\n",
       " 'B0BSRGRWNG': 947,\n",
       " 'B010Q29OW6': 948,\n",
       " 'B00OUUUIUI': 949,\n",
       " 'B00YPJXONW': 950,\n",
       " 'B00Q3MF9YQ': 951,\n",
       " 'B005979HBM': 952,\n",
       " 'B01D4ZJZTO': 953,\n",
       " 'B00FLLFM0Q': 954,\n",
       " 'B09L6XQF1C': 955,\n",
       " 'B0BXYXD1Q2': 956,\n",
       " 'B07PQTHXW9': 957,\n",
       " 'B008194UIU': 958,\n",
       " 'B011J55MBG': 959,\n",
       " 'B00IVPU7AO': 960,\n",
       " 'B0111SPOXW': 961,\n",
       " 'B00Q00XPII': 962,\n",
       " 'B09JY4SJ2G': 963,\n",
       " 'B002YJW7C4': 964,\n",
       " 'B0091R9XRY': 965,\n",
       " 'B00F19Q7YI': 966,\n",
       " 'B00I2VIR2M': 967,\n",
       " 'B07BXD6MB4': 968,\n",
       " 'B0153CASRY': 969,\n",
       " 'B00GX1R9EA': 970,\n",
       " 'B015WCV70W': 971,\n",
       " 'B092HSPZJ3': 972,\n",
       " 'B0114WOSZA': 973,\n",
       " 'B0C5WYZS7C': 974,\n",
       " 'B07RNSSPWX': 975,\n",
       " 'B09WR3VDZ7': 976,\n",
       " 'B07NJQLQWP': 977,\n",
       " 'B01LY6DEAC': 978,\n",
       " 'B09WQZGBB6': 979,\n",
       " 'B078GWJ44Z': 980,\n",
       " 'B072W6GLLT': 981,\n",
       " 'B0000BVYTV': 982,\n",
       " 'B001M56DI0': 983,\n",
       " 'B001GNC9IQ': 984,\n",
       " 'B074QNVY86': 985,\n",
       " 'B000A0GWN4': 986,\n",
       " 'B07FP8VLXS': 987,\n",
       " 'B004JO16KG': 988,\n",
       " 'B01MQI91Y0': 989,\n",
       " 'B07GB3SGSF': 990,\n",
       " 'B07NZ86T1L': 991,\n",
       " 'B076H2BCVT': 992,\n",
       " 'B01H3F8K1K': 993,\n",
       " 'B01ISM267G': 994,\n",
       " 'B075YDDLCK': 995,\n",
       " 'B010OPRNW8': 996,\n",
       " 'B0BZ33NL7T': 997,\n",
       " 'B004YKAGKQ': 998,\n",
       " 'B0C1YHZNH9': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c0ddff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* find_keys(): WARNING - failed to identify key associated with value 0, omitting from results!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[996, 19, 0, 1, 8]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_keys(i_map_sub, [111996, 19, 14, 143, 84, 0], i_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ef8aadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "02d868fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_key(u_map, 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac4cf5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui_dense[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7acd5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui_dense[1][[0,413]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = np.nonzero(ui_dense[0])[0]\n",
    "b = np.nonzero(ui_dense[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59f95cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([list_, b], axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05b9d73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 4, 2, 5, 5, 5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui_dense[0][np.nonzero(ui_dense[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a67ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = set(np.nonzero(ui_dense[0])[0]) \n",
    "b = set(np.nonzero(ui_dense[6])[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4810c999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab295e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(11)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db02bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80be98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_a = cosine_similarity([ui_dense[0]], [ui_dense[33]])\n",
    "sims = [0] *len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca166cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims[0] = sim_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44ec4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b12b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[0]*2]*top_k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8969c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_ratings = np.array([ np.random.random() for x in range(100) ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5ebcb4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_key(dict_, val): \n",
    "    for k, v in dict_.items(): \n",
    "        if v == val: \n",
    "            return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8a1b26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_(list_, exclude): \n",
    "    \"\"\"Argmax with a list of indices to include, and exclude\"\"\"    \n",
    "    max_i = 0 \n",
    "    for i, a in enumerate(list_): \n",
    "        if i not in exclude: \n",
    "            if a > list_[max_i]: \n",
    "                max_i = i \n",
    "    return max_i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e36ddb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "ui = ui_dense \n",
    "\n",
    "for u in range(len(u_map)): \n",
    "    rated = list(np.nonzero(ui[u])[0]) \n",
    "    recommended = []\n",
    "    while len(recommended) < 10: \n",
    "        best_rated = argmax_(fake_ratings, exclude=rated + recommended)\n",
    "        recommended.append(best_rated) \n",
    "\n",
    "    recommendations = [ { find_key(i_map, x): fake_ratings[x] } for x in recommended ]\n",
    "    preds.append(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "56887b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'B01LXFFO8O': np.float64(0.9964913244381501)},\n",
       " {'B074CV39CZ': np.float64(0.9832080627781924)},\n",
       " {'B004VM1T5S': np.float64(0.9675099580232271)},\n",
       " {'B00UVSJU4S': np.float64(0.9586008552468466)},\n",
       " {'B0819W2H7V': np.float64(0.9547344230493247)},\n",
       " {'B0082E9K7U': np.float64(0.9339118106753722)},\n",
       " {'B00NUB333W': np.float64(0.930857640711958)},\n",
       " {'B0BYRMDDCP': np.float64(0.8828239187931431)},\n",
       " {'B00QDF34UO': np.float64(0.8783519687827609)},\n",
       " {'B019G1QAXY': np.float64(0.8657701458766286)}]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c06894aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(758),\n",
       " np.int64(1062),\n",
       " np.int64(2834),\n",
       " np.int64(18321),\n",
       " np.int64(50205),\n",
       " np.int64(57059)]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d65450a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79972592, 0.96773651, 0.03627581, ..., 0.56387805, 0.10178226,\n",
       "       0.52135765])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "98b1e4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9380747051543531)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.argmax(fake_ratings[candidates])\n",
    "fake_ratings[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "da0338d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79972592, 0.96773651, 0.03627581, 0.94500918, 0.6972711 ,\n",
       "       0.10736279, 0.46726819, 0.34114489, 0.29949057, 0.92829034])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "f = fake_ratings[:10]\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0717c80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(7830)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(fake_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b299d125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'B017M5T894': np.float64(0.44170344314473553)},\n",
       " {'B098S85M4X': np.float64(0.37548236440174165)},\n",
       " {'B097MSG8LM': np.float64(0.47973793534366904)},\n",
       " {'B01KUEGE1E': np.float64(0.7132452507268774)},\n",
       " {'B0B1M66ZGQ': np.float64(0.34813045609918136)},\n",
       " {'B00B9Z23NM': np.float64(0.9766051685195317)},\n",
       " {'B00ESYW40S': np.float64(0.8228181869014046)},\n",
       " {'B009D7BJR4': np.float64(0.20749694824672038)},\n",
       " {'B00B97KDV4': np.float64(0.9558561656733956)},\n",
       " {'B0098OCKDE': np.float64(0.7962374139470548)}]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "465343dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22362651, 0.10736279])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_ratings[[13, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1b6c126b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1052)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui[-2].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db591d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr \n",
    "\n",
    "def pearson_similarity(a, b):\n",
    "    \"\"\"\n",
    "    Compute Pearson similarity\n",
    "    \"\"\"\n",
    "    return (1 + pearsonr(a, b).statistic) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populating a full user similarity matrix is inherently limited by (and is a questionable \n",
    "# strategy because of) the u^2 memory requirement. Unlike our affinity matrices, \n",
    "# these are not sparse. Since our goal is recommending items, we'll compute the similarity\n",
    "# iterativealy and store the most similar users to get down to C * u memory\n",
    "similarity_matrix = np.array([[0.] * top_k] * len(users))\n",
    "for list_ in range(len(users)): \n",
    "\n",
    "    # Collect our similarities w/ respect to user A\n",
    "    sim_a = {}\n",
    "    for b in range(len(users)): \n",
    "        if list_ != b: \n",
    "            \n",
    "            # Given the sparsity of our review vectors, cosine similarity is going to be \n",
    "            # effectively zero if we look across the entire item space... compare only those \n",
    "            # items these two users have in common (at least 1 rating between the two). \n",
    "            a_item_ix = np.nonzero(ui_dense[list_])[0]            \n",
    "            b_item_ix = np.nonzero(ui_dense[b])[0]\n",
    "            all_ix = np.concatenate([a_item_ix, b_item_ix])\n",
    "            a_items = ui_dense[list_][all_ix]            \n",
    "            b_items = ui_dense[b][all_ix]\n",
    "\n",
    "            # Fill non-ratings with middling scores. Non-interactions appear \n",
    "            # dissimilar to positive reviews and similar to negative ones otherwise.\n",
    "            a_items[a_items==0] = 4\n",
    "            b_items[b_items==0] = 2\n",
    "            \n",
    "            # Cosine similarity risks insensitivity to rating value, while imperfect here, \n",
    "            # Pearson similarity gets us sensitivty to rating magnitude and trends\n",
    "            sim_a[b] = pearson_similarity(a_items, b_items)\n",
    "        \n",
    "    # Find and store the top k user matches, in order    \n",
    "    # NOTE: dict sorting logic courtesy of gpt-4o (https://chatgpt.com/share/687dc72f-54b4-8013-806e-b1de20d0ef12)\n",
    "    top = sorted(sim_a.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    similarity_matrix[list_] = [x[0] for x in top]\n",
    "\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0e22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_items[-7] = 2\n",
    "a_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2eefd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e73b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity([a_items],[b_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ebe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_similarity(a_items, b_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accf5e2b",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bbe07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.datasets.sparse import AffinityMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only relevant to VAE strategy \n",
    "reviews = reviews[reviews.rating >= 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff7ffe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e12fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608aec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Strategy adapted from tutorials available in the Recommenders project, see \n",
    "# https://github.com/recommenders-team/recommenders/tree/main\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "\n",
    "# Split along user boundaries to ensure no leakage of preference between train and test\n",
    "train_users, test_users, val_users = python_random_split(users, [.9, .05, .05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630664c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_users.shape, test_users.shape, val_users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reviews[reviews.user_id.isin(train_users.user_id)]\n",
    "val = reviews[reviews.user_id.isin(val_users.user_id)]\n",
    "test = reviews[reviews.user_id.isin(test_users.user_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc5ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technique from Recommenders (see https://github.com/recommenders-team/recommenders/blob/45e1b215a35e69b92390e16eb818d4528d0a33a2/examples/02_model_collaborative_filtering/standard_vae_deep_dive.ipynb) \n",
    "# to improve utility of validation set during training - only allow items in\n",
    "# the validation set that are also present in the train set\n",
    "val = val[val.item_id.isin(train.item_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d5886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.datasets.python_splitters import python_stratified_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbcf82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another technique employed in Recommenders (see above link for notebook), for in-flight validation to be \n",
    "# meaningful during training, our validation set needs not just ground truth, but unseen validation samples \n",
    "# to see if predictions for validation users are relevant (to those users). Anyway, break down our val and test \n",
    "# sets again to support this strategy\n",
    "val_src, val_target = python_stratified_split(\n",
    "    data=val, \n",
    "    ratio=0.8, \n",
    "    filter_by=\"item\", \n",
    "    col_user=\"user_id\", \n",
    "    col_item=\"item_id\"\n",
    "    )\n",
    "test_src, test_target = python_stratified_split(\n",
    "    data=test, \n",
    "    ratio=0.8, \n",
    "    filter_by=\"item\", \n",
    "    col_user=\"user_id\", \n",
    "    col_item=\"item_id\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16b6946",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val.shape, \" -> \", val_src.shape, val_target.shape)\n",
    "print(test.shape, \" -> \", test_src.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to use standard names across the analysis \n",
    "header = {\n",
    "        \"col_user\": \"user_id\",\n",
    "        \"col_item\": \"item_id\",\n",
    "        \"col_rating\": \"rating\",\n",
    "        # Unclear why this doesn't also eat a timestamp, but many of the functions that split temporally use, fortunately \n",
    "        # the column 'timestamp' (i.e. DEFAULT_TIMESTAMP_COL='timestamp') so I think we're fine. \n",
    "        # \"col_timestamp\" : \"timestamp\"\n",
    "    }\n",
    "\n",
    "train_matrix = AffinityMatrix(df=train, **header)\n",
    "val_matrix = AffinityMatrix(df=val, **header)\n",
    "val_src_matrix = AffinityMatrix(df=val_src, **header)\n",
    "val_tgt_matrix = AffinityMatrix(df=val_target, **header)\n",
    "test_src_matrix = AffinityMatrix(df=test_src, **header)\n",
    "test_tgt_matrix = AffinityMatrix(df=test_target, **header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6664d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This generates a sparse array of user vectors, aka user-item matrix\n",
    "# X[0] is the first user in the list, with entries for all items known when the matrix was constructed in that row\n",
    "train, _, _ = train_matrix.gen_affinity_matrix()\n",
    "val, _, _ = val_matrix.gen_affinity_matrix() \n",
    "val_src, _, _ = val_src_matrix.gen_affinity_matrix()\n",
    "val_tgt, _, _ = val_tgt_matrix.gen_affinity_matrix()\n",
    "test_src, _, _ = test_src_matrix.gen_affinity_matrix()\n",
    "test_tgt, _, _ = test_src_matrix.gen_affinity_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ed4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.utils.python_utils import binarize\n",
    "\n",
    "train = binarize(train, 3)\n",
    "val = binarize(train, 3)\n",
    "val_src = binarize(val_src, 3) \n",
    "val_tgt = binarize(val_tgt, 3)\n",
    "test_src = binarize(test_src, 3)\n",
    "test_tgt = binarize(test_tgt, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d68d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make sure this is reported during training/configuration\n",
    "sparsity = np.count_nonzero(train)/(train.shape[0]*train.shape[1])*100\n",
    "print(f\"sparsity: {sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585601b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "985102a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 20:43:56.923222: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-21 20:43:57.118547: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753145037.183633 1891196 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753145037.208377 1891196 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753145037.373871 1891196 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753145037.373930 1891196 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753145037.373936 1891196 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753145037.373940 1891196 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-21 20:43:57.400216: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrecommenders\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvae\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstandard_vae\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardVAE\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school/deepcart/venv/lib/python3.12/site-packages/recommenders/models/vae/standard_vae.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlosses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m binary_crossentropy\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "from recommenders.models.vae.standard_vae import StandardVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2bf5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StandardVAE(\n",
    "    n_users = train.shape[0], \n",
    "    original_dim = train.shape[1],\n",
    "    intermediate_dim=250, \n",
    "    latent_dim=50, \n",
    "    n_epochs=1, \n",
    "    batch_size=1, \n",
    "    k=10, \n",
    "    verbose=1, \n",
    "    seed=4, \n",
    "    save_path=\"models/svae.hdf5\", \n",
    "    drop_encoder=0.5, \n",
    "    drop_decoder=0.5, \n",
    "    annealing=False, \n",
    "    beta=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56eb549",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc01bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x_train=train, \n",
    "    x_valid=val, \n",
    "    x_val_tr=val_src, \n",
    "    x_val_te=val_tgt, \n",
    "    mapper=val_matrix,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d4cbf",
   "metadata": {},
   "source": [
    "Managing text-based reviews at this scale could be a challenge, and I'd like to steer clear of LLMs for this effort. We could do an embedding on the review and use that for similarity, but we have pretty rich item data. Perhaps let's ignore the collaborative aspect here and build a shopping interface that: \n",
    "- surfaces the most popular items, and encourages you to add items to your shopping cart for a big discount/promo\n",
    "- based on clicks and cart items, improves the recommendations and surfaces new products\n",
    "\n",
    "We can use an autoencoder to accept a sparse matrix of users and items, learn to reproduce that matrix, and in so doing support prediction on missing values. However, this matrix is of size users x items, which here is 1.8e7 x 1.6e6 = 28,125,000,000 KB (best-case, higher if stored as np floats) ~= 26 TB !! WTF. \n",
    "- In the standard VAE example (https://github.com/recommenders-team/recommenders/blob/main/examples/02_model_collaborative_filtering/standard_vae_deep_dive.ipynb) the clicks are turned into a histogram for each user ... so we have n_user vector of length n_items... then I guess each of these is a training sample. The VAE presumably learns, given a sparse user vector, to predict every rating. This takes the complexity down and gives us a training set we can iterate over. \n",
    "\n",
    "Let's avoid any distributional pressure (present in VAE, SVAE, disentangled VAE) and go for a basic autoencoder using the strategy laid out above, i.e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891606e6",
   "metadata": {},
   "source": [
    "### Scratch Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cbbcb4",
   "metadata": {},
   "source": [
    "That damned Recommenders VAE is a dependency dumpster fire ... walking away after 10h of fighting crusty environments that generate more errors than outcomes. Shift to a basic autoencoder in pytorch and just eat the cost of having to implement our own validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59907dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd37f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0501d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93e6a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math \n",
    "import torch \n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from recommenders.datasets.sparse import AffinityMatrix\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.datasets.python_splitters import python_stratified_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder\n",
    "\n",
    "    NOTE: with cues from https://www.geeksforgeeks.org/deep-learning/implementing-an-autoencoder-in-pytorch/\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dims=1000):\n",
    "        \"\"\"\n",
    "        Initialize a new object given an item count \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(dims, 500),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(500, 75),\n",
    "            nn.ReLU(), \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(75, 500),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(500, dims),\n",
    "            nn.ReLU(), \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Implement our forward pass \n",
    "        \"\"\"\n",
    "        h = self.encoder(x) \n",
    "        r = self.decoder(h)\n",
    "\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d97ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCartDataset(torch.utils.data.Dataset): \n",
    "    \"\"\"\n",
    "    Custom pytorch-compatible dataset. Adapted from \n",
    "    https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n",
    "    \"\"\"\n",
    "    def __init__(self, users, reviews): \n",
    "        \"\"\"\n",
    "        Initialize a new instance\n",
    "\n",
    "        Oof. The ideal pattern here is for the dataset to be blissfully ignorant of our split strategy and just \n",
    "        make a dataset available to its client based on the raw data passed. However the split strategy is rather intricate below ... \n",
    "        note the five splits. Can we easily raise that up to a higher level? The refactoring might not be trivial and it may result in \n",
    "        residue of this split strategy bleeding over to the other models -- what's common and what's not? \n",
    "\n",
    "        common: \n",
    "        - train, val, test split\n",
    "        - val test and test test bonus splits - for all validation stages we need to check performance, however non-NN techniques \n",
    "          really only need a test split, right? if we do train holdout for validation, we essentially have three test sets (train-test, val, test)\n",
    "        - a need to operate on the same validation or at least test data, lest the comparison be biased by the selection method each model applies\n",
    "\n",
    "        unique\n",
    "        - logic to prune reviews < 3.5 -- we don't do this in cfnn, and naive doesn't care (predicts highest review in the matrix), if this is \n",
    "          done during training, it will also need to be done during inference\n",
    "        - need for a pytorch-style dataset ... the naive method is doing a O(n) search, the cfnn needs dataframes -- while refactoring is \n",
    "          possible, why understake the risk it will be a disjoint and inelegant fit? \n",
    "        - the VAE implementation wants all train and val, but doesn't require a test dataset. we ou\n",
    "\n",
    "\n",
    "        we could: \n",
    "        - pass train and val, hold test out\n",
    "        - pass test to predict function, which we need for the demo anyway\n",
    "        - keep the pytorch dataset unique to the pytorch-compatible class... doesn't make sense to try and foist on other algos... we are \n",
    "        doing this in the wrong order, filtering and then splitting... we need to outsource the splitting and then do the filtering inside each \n",
    "        model \n",
    "\n",
    "        right now this is speculation, just get something working! we can figure out how to streamline after -- oh, but we need a dataset \n",
    "        implementation\n",
    "        \"\"\"\n",
    "        self.users = users \n",
    "        self.reviews = reviews \n",
    "        self.matrix = \n",
    "\n",
    "    def build_affinity_matrices(): \n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        oof\n",
    "\n",
    "    def split(users, reviews, items):\n",
    "        \"\"\"\n",
    "        Generate splits \n",
    "        \"\"\"\n",
    "        print(f\"Full user-item matrix is {len(users) * len(items)}\")\n",
    "\n",
    "\n",
    "\n",
    "# generic need\n",
    "        # NOTE: Strategy adapted from tutorials available in the Recommenders project, see \n",
    "        # https://github.com/recommenders-team/recommenders/tree/main\n",
    "        # Split along user boundaries to ensure no leakage of preference between train and test\n",
    "        train_users, test_users, val_users = python_random_split(users, [.9, .05, .05])\n",
    "        print(train_users.shape, test_users.shape, val_users.shape)\n",
    "\n",
    "        train = reviews[reviews.user_id.isin(train_users.user_id)]\n",
    "        val = reviews[reviews.user_id.isin(val_users.user_id)]\n",
    "        test = reviews[reviews.user_id.isin(test_users.user_id)]\n",
    "        print(train.shape, val.shape, test.shape)\n",
    "\n",
    "\n",
    "\n",
    "        # Technique from Recommenders (see https://github.com/recommenders-team/recommenders/blob/45e1b215a35e69b92390e16eb818d4528d0a33a2/examples/02_model_collaborative_filtering/standard_vae_deep_dive.ipynb) \n",
    "        # to improve utility of validation set during training - only allow items in\n",
    "        # the validation set that are also present in the train set\n",
    "        val = val[val.item_id.isin(train.item_id.unique())]\n",
    "        print(val.shape)\n",
    "\n",
    "        # Another technique employed in Recommenders (see above link for notebook), for in-flight validation to be \n",
    "        # meaningful during training, our validation set needs not just ground truth, but unseen validation samples \n",
    "        # to see if predictions for validation users are relevant (to those users). Anyway, break down our val and test \n",
    "        # sets again to support this strategy\n",
    "        val_src, val_target = python_stratified_split(\n",
    "            data=val, \n",
    "            ratio=0.8, \n",
    "            filter_by=\"item\", \n",
    "            col_user=\"user_id\", \n",
    "            col_item=\"item_id\"\n",
    "            )\n",
    "        test_src, test_target = python_stratified_split(\n",
    "            data=test, \n",
    "            ratio=0.8, \n",
    "            filter_by=\"item\", \n",
    "            col_user=\"user_id\", \n",
    "            col_item=\"item_id\"\n",
    "            )\n",
    "        \n",
    "        print(val.shape, \" -> \", val_src.shape, val_target.shape)\n",
    "        print(test.shape, \" -> \", test_src.shape, test_target.shape)\n",
    "\n",
    "# really all of these models just need the review data to train, the users and item lists can be extracted from that\n",
    "\n",
    "# AE specific ... \n",
    "        # We are trying to teach the model what a good interaction is like, and we'll \n",
    "        # ultimately be interested only in whether to recommend an item or not ... \n",
    "        # low reviews are not something we want the model suggesting... \n",
    "        reviews_low = reviews[reviews.rating < 3]\n",
    "        reviews = reviews[reviews.rating >= 3]\n",
    "\n",
    "        header = {\n",
    "            \"col_user\": \"user_id\",\n",
    "            \"col_item\": \"item_id\",\n",
    "            \"col_rating\": \"rating\",\n",
    "        }\n",
    "\n",
    "        train_matrix = AffinityMatrix(df=train, **header)\n",
    "        val_matrix = AffinityMatrix(df=val, **header)\n",
    "        val_src_matrix = AffinityMatrix(df=val_src, **header)\n",
    "        val_tgt_matrix = AffinityMatrix(df=val_target, **header)\n",
    "        test_src_matrix = AffinityMatrix(df=test_src, **header)\n",
    "        test_tgt_matrix = AffinityMatrix(df=test_target, **header)\n",
    "\n",
    "        # This generates a sparse array of user vectors, aka user-item matrix\n",
    "        # X[0] is the first user in the list, with entries for all items known when the matrix was constructed in that row\n",
    "        train, _, _ = train_matrix.gen_affinity_matrix()\n",
    "        val, _, _ = val_matrix.gen_affinity_matrix() \n",
    "        val_src, _, _ = val_src_matrix.gen_affinity_matrix()\n",
    "        val_tgt, _, _ = val_tgt_matrix.gen_affinity_matrix()\n",
    "        test_src, _, _ = test_src_matrix.gen_affinity_matrix()\n",
    "        test_tgt, _, _ = test_src_matrix.gen_affinity_matrix()    \n",
    "\n",
    "        train = binarize(train, 3)\n",
    "        val = binarize(train, 3)\n",
    "        val_src = binarize(val_src, 3) \n",
    "        val_tgt = binarize(val_tgt, 3)\n",
    "        test_src = binarize(test_src, 3)\n",
    "        test_tgt = binarize(test_tgt, 3)\n",
    "\n",
    "        sparsity = np.count_nonzero(train)/(train.shape[0]*train.shape[1])*100\n",
    "        print(f\"sparsity: {sparsity:.2f}%\")\n",
    "    def __len__(self): \n",
    "        \"\"\"\n",
    "        Retrieve length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.img_labels) \n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        \"\"\"\n",
    "        Retrieve an item at the provided index\n",
    "        \"\"\"\n",
    "        #TODO: implement\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(batch_size=5, shuffle=True): \n",
    "    \"\"\"\n",
    "    Retrieve a pytorch-style dataloader \n",
    "    \"\"\"\n",
    "\n",
    "    #TODO: implement\n",
    "    #transform = transforms.Compose([\n",
    "    #     transforms.ConvertImageDtype(torch.float),\n",
    "    #     transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    #])\n",
    "\n",
    "    #data = DeepCartDataset(transform=transform)\n",
    "    #loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    #return loader\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, loss_interval=20, epochs=2, lr=0.01, momentum=0.9):\n",
    "    \"\"\"\n",
    "    Train the model with the provided dataset\n",
    "\n",
    "    NOTE: this is a similar training loop as we used for our vision model in the \n",
    "    the vision project, forward pass\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    train_loss = []\n",
    "\n",
    "    tqdm.write(f\"Starting training run...\")    \n",
    "    # TODO: configure WandB\n",
    "    # see https://docs.wandb.ai/guides/integrations/pytorch/\n",
    "    config = {}\n",
    "    run = wandb.init(config=config) \n",
    "\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(loader):\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # collect metrics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (i % loss_interval) == (loss_interval - 1): \n",
    "                train_loss.append(running_loss / loss_interval)\n",
    "                tqdm.write(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / loss_interval:.3f}\")\n",
    "                running_loss = 0 \n",
    "    \n",
    "    tqdm.write(\"Training complete!\") \n",
    "\n",
    "    return train_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = [[]] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef998d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_[0].append('butt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409e8947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['butt'], ['butt']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0989921f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
