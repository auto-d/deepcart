{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ad0120",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83962e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_USE_LEGACY_KERAS=True\n"
     ]
    }
   ],
   "source": [
    "%set_env TF_USE_LEGACY_KERAS=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "914076d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 01:54:43.045119: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-20 01:54:43.052562: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752990883.060887 1988837 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752990883.063426 1988837 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752990883.069750 1988837 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752990883.069762 1988837 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752990883.069763 1988837 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752990883.069764 1988837 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-20 01:54:43.072169: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tf_keras as keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1862e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_parquet(\"../data/2023/Electronics_min.parquet\")\n",
    "items = pd.read_parquet(\"../data/2023/meta_Electronics.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8255337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>B083NRGZMM</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-07-18 22:58:37.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B07N69T6TM</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2020-06-20 18:42:29.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>B01G8JO5F2</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2018-04-07 09:23:37.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>B001OC5JKY</td>\n",
       "      <td>AGGZ357AO26RQZVRLGU4D4N52DZQ</td>\n",
       "      <td>2010-11-20 18:41:35.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B07CJYMRWM</td>\n",
       "      <td>AG2L7H23R5LLKDKLBEF2Q3L2MVDA</td>\n",
       "      <td>2023-02-17 02:39:41.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999995</th>\n",
       "      <td>4</td>\n",
       "      <td>B0BR6FBPD9</td>\n",
       "      <td>AHG2SVUXNKVWEHVTVRZHIDRCWFQA</td>\n",
       "      <td>2021-07-07 17:10:50.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999996</th>\n",
       "      <td>5</td>\n",
       "      <td>B07DVRGM9M</td>\n",
       "      <td>AHG2SVUXNKVWEHVTVRZHIDRCWFQA</td>\n",
       "      <td>2018-07-19 14:04:49.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999997</th>\n",
       "      <td>5</td>\n",
       "      <td>B0B3TJMN8P</td>\n",
       "      <td>AGT6T3SMU577AW4KZOWCX7VIY3IQ</td>\n",
       "      <td>2022-08-26 16:29:27.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999998</th>\n",
       "      <td>5</td>\n",
       "      <td>B0B3158RQ2</td>\n",
       "      <td>AFY2KJ5YAVB77AAACLXEAHT4CHWQ</td>\n",
       "      <td>2022-12-06 20:21:24.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>5</td>\n",
       "      <td>B091KQ3D6C</td>\n",
       "      <td>AFY2KJ5YAVB77AAACLXEAHT4CHWQ</td>\n",
       "      <td>2022-02-03 20:14:50.149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating parent_asin                       user_id  \\\n",
       "0             3  B083NRGZMM  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ   \n",
       "1             1  B07N69T6TM  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ   \n",
       "2             5  B01G8JO5F2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ   \n",
       "3             5  B001OC5JKY  AGGZ357AO26RQZVRLGU4D4N52DZQ   \n",
       "4             5  B07CJYMRWM  AG2L7H23R5LLKDKLBEF2Q3L2MVDA   \n",
       "...         ...         ...                           ...   \n",
       "9999995       4  B0BR6FBPD9  AHG2SVUXNKVWEHVTVRZHIDRCWFQA   \n",
       "9999996       5  B07DVRGM9M  AHG2SVUXNKVWEHVTVRZHIDRCWFQA   \n",
       "9999997       5  B0B3TJMN8P  AGT6T3SMU577AW4KZOWCX7VIY3IQ   \n",
       "9999998       5  B0B3158RQ2  AFY2KJ5YAVB77AAACLXEAHT4CHWQ   \n",
       "9999999       5  B091KQ3D6C  AFY2KJ5YAVB77AAACLXEAHT4CHWQ   \n",
       "\n",
       "                      timestamp  \n",
       "0       2022-07-18 22:58:37.948  \n",
       "1       2020-06-20 18:42:29.731  \n",
       "2       2018-04-07 09:23:37.534  \n",
       "3       2010-11-20 18:41:35.000  \n",
       "4       2023-02-17 02:39:41.238  \n",
       "...                         ...  \n",
       "9999995 2021-07-07 17:10:50.418  \n",
       "9999996 2018-07-19 14:04:49.157  \n",
       "9999997 2022-08-26 16:29:27.240  \n",
       "9999998 2022-12-06 20:21:24.745  \n",
       "9999999 2022-02-03 20:14:50.149  \n",
       "\n",
       "[10000000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a83408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>images</th>\n",
       "      <th>parent_asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FS-1051 FATSHARK TELEPORTER V3 HEADSET</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>[Teleporter V3 The “Teleporter V3” kit sets a ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': None, 'large': 'https://m.media-am...</td>\n",
       "      <td>B00MCW7G9M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ce-H22B12-S1 4Kx2K Hdmi 4Port</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[HDMI In - HDMI Out]</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B00YT6XQSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Digi-Tatoo Decal Skin Compatible With MacBook ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>246</td>\n",
       "      <td>[]</td>\n",
       "      <td>19.99</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B07SM135LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NotoCity Compatible with Vivoactive 4 band 22m...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>233</td>\n",
       "      <td>[]</td>\n",
       "      <td>9.99</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B089CNGZCW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Motorola Droid X Essentials Combo Pack</td>\n",
       "      <td>3.8</td>\n",
       "      <td>64</td>\n",
       "      <td>[all Genuine High Quality Motorola Made Access...</td>\n",
       "      <td>14.99</td>\n",
       "      <td>[{'hi_res': None, 'large': 'https://m.media-am...</td>\n",
       "      <td>B004E2Z88O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610007</th>\n",
       "      <td>Wintec FileMate Pro USB Flash Drive, 3FMUSB32G...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[--New in retail packaging --Fast USB 2.0 data...</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B003NUIU9M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610008</th>\n",
       "      <td>Tsugar Noise Reduction Wireless Headphones Blu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Description: 100% brand new high quality 1.Hi...</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': None, 'large': 'https://m.media-am...</td>\n",
       "      <td>B0BHVY33TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610009</th>\n",
       "      <td>Hardshell Case for MacBook Pro (16-inch, 2021)...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>11</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B09SQGRFFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610010</th>\n",
       "      <td>FYY 12-13.3\" Laptop Sleeve Case Bag, PU Leathe...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B091JWCSG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610011</th>\n",
       "      <td>4MP Full Time Color Night Vision POE IP Camera...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>10</td>\n",
       "      <td>[Camera, Image Sensor: 1/1.8\" Progressive Scan...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B08K7KC4GR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1610012 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  average_rating  \\\n",
       "0                   FS-1051 FATSHARK TELEPORTER V3 HEADSET             3.5   \n",
       "1                            Ce-H22B12-S1 4Kx2K Hdmi 4Port             5.0   \n",
       "2        Digi-Tatoo Decal Skin Compatible With MacBook ...             4.5   \n",
       "3        NotoCity Compatible with Vivoactive 4 band 22m...             4.5   \n",
       "4                   Motorola Droid X Essentials Combo Pack             3.8   \n",
       "...                                                    ...             ...   \n",
       "1610007  Wintec FileMate Pro USB Flash Drive, 3FMUSB32G...             5.0   \n",
       "1610008  Tsugar Noise Reduction Wireless Headphones Blu...             1.0   \n",
       "1610009  Hardshell Case for MacBook Pro (16-inch, 2021)...             4.6   \n",
       "1610010  FYY 12-13.3\" Laptop Sleeve Case Bag, PU Leathe...             4.0   \n",
       "1610011  4MP Full Time Color Night Vision POE IP Camera...             4.1   \n",
       "\n",
       "         rating_number                                        description  \\\n",
       "0                    6  [Teleporter V3 The “Teleporter V3” kit sets a ...   \n",
       "1                    1                               [HDMI In - HDMI Out]   \n",
       "2                  246                                                 []   \n",
       "3                  233                                                 []   \n",
       "4                   64  [all Genuine High Quality Motorola Made Access...   \n",
       "...                ...                                                ...   \n",
       "1610007              1  [--New in retail packaging --Fast USB 2.0 data...   \n",
       "1610008              2  [Description: 100% brand new high quality 1.Hi...   \n",
       "1610009             11                                                 []   \n",
       "1610010             35                                                 []   \n",
       "1610011             10  [Camera, Image Sensor: 1/1.8\" Progressive Scan...   \n",
       "\n",
       "         price                                             images parent_asin  \n",
       "0         None  [{'hi_res': None, 'large': 'https://m.media-am...  B00MCW7G9M  \n",
       "1         None  [{'hi_res': 'https://m.media-amazon.com/images...  B00YT6XQSE  \n",
       "2        19.99  [{'hi_res': 'https://m.media-amazon.com/images...  B07SM135LS  \n",
       "3         9.99  [{'hi_res': 'https://m.media-amazon.com/images...  B089CNGZCW  \n",
       "4        14.99  [{'hi_res': None, 'large': 'https://m.media-am...  B004E2Z88O  \n",
       "...        ...                                                ...         ...  \n",
       "1610007   None  [{'hi_res': 'https://m.media-amazon.com/images...  B003NUIU9M  \n",
       "1610008   None  [{'hi_res': None, 'large': 'https://m.media-am...  B0BHVY33TL  \n",
       "1610009   None  [{'hi_res': 'https://m.media-amazon.com/images...  B09SQGRFFH  \n",
       "1610010   None  [{'hi_res': 'https://m.media-amazon.com/images...  B091JWCSG5  \n",
       "1610011  119.0  [{'hi_res': 'https://m.media-amazon.com/images...  B08K7KC4GR  \n",
       "\n",
       "[1610012 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be17af",
   "metadata": {},
   "source": [
    "We need to build a compact user-centric representation of preference, collapse review data into a sparse matrix of user -> item preferences. There are some heuristics that need to be applied in the process: \n",
    "1. users with few interactions are a very weak signal -- without associations with multiple products, we are not teaching the model about positive associations\n",
    "2. products with few interactions are also a very weak signal -- we are looking to connect users and items that have tiny interaction graphs are not going to improve our macro-level predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00609d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42604"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: This should be a configuration option hyper parameter, we can relax this if training isn't suepr computationally expensive\n",
    "min_ratings = 1000\n",
    "items = items[items.rating_number > min_ratings]\n",
    "len(items) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "042fac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1988837/1979523271.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews.rename(columns={'parent_asin':'item_id'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# The above item filtering serves to reduce the computational complexity as well as \n",
    "# reduce sparsity, before we filter reviews make sure we remove those associated with \n",
    "# dropped items\n",
    "all_items = set(items.parent_asin)\n",
    "reviews = reviews[reviews.parent_asin.isin(all_items)]\n",
    "reviews.rename(columns={'parent_asin':'item_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af200300",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = reviews.groupby(['user_id']).rating.count()\n",
    "users = pd.DataFrame(users).reset_index()\n",
    "users.rename(columns={'rating':'ratings'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae9b879e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23050</th>\n",
       "      <td>AE3LZ5EMSN5BJ5USW4SJRDHI5M4A</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24389</th>\n",
       "      <td>AE3ORZRCEZPHFNQV5AT27AZXRCBA</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31444</th>\n",
       "      <td>AE45ZGMA3H5BVWXV5ZOUTXMWDKXQ</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41304</th>\n",
       "      <td>AE4SX2IMZGVQSS5SFWP6NEE2HQ4Q</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42562</th>\n",
       "      <td>AE4VNCNZ5XJON3GQWHFJPZ626HVQ</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693773</th>\n",
       "      <td>AHMNA5UK3V66O2V3DZSBJA4FYMOA</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792892</th>\n",
       "      <td>AHTDYGXHONM2BHENDRMKMC34ZZZA</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850059</th>\n",
       "      <td>AHX7ER6ODLRXMZF3WLEFJVRUJUXQ</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862291</th>\n",
       "      <td>AHXZR7HLPSKRUPHX35GKRLVTX3ZA</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868984</th>\n",
       "      <td>AHYI3O22APDQVJ3CXEJRHUYYR2BA</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              user_id  ratings\n",
       "23050    AE3LZ5EMSN5BJ5USW4SJRDHI5M4A      122\n",
       "24389    AE3ORZRCEZPHFNQV5AT27AZXRCBA      116\n",
       "31444    AE45ZGMA3H5BVWXV5ZOUTXMWDKXQ      132\n",
       "41304    AE4SX2IMZGVQSS5SFWP6NEE2HQ4Q       96\n",
       "42562    AE4VNCNZ5XJON3GQWHFJPZ626HVQ      101\n",
       "...                               ...      ...\n",
       "1693773  AHMNA5UK3V66O2V3DZSBJA4FYMOA      233\n",
       "1792892  AHTDYGXHONM2BHENDRMKMC34ZZZA       96\n",
       "1850059  AHX7ER6ODLRXMZF3WLEFJVRUJUXQ      122\n",
       "1862291  AHXZR7HLPSKRUPHX35GKRLVTX3ZA      122\n",
       "1868984  AHYI3O22APDQVJ3CXEJRHUYYR2BA      115\n",
       "\n",
       "[72 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a configuration parameter, as above ... relax if we don't have issues with compute\n",
    "min_reviews = 95\n",
    "users = users[users.ratings > min_reviews] \n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00344bd",
   "metadata": {},
   "source": [
    "❗in the notebook, ratings are thresholded ... do we need to follow suit? what are the ramifications if we don't? OH... in the notebook, a click is an interaction, there's no middle ground. the network is going to operate on 0s or 1s. by leaving low reviews in our matrix, the network would learn to recommend things users have interacted with, but not necessarily positively. our case is the same, a review is an interaction. we're aiming to recommend, and we should not want to recommend low reviews. so filter... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e76856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: decide if we need to keep the low reviews around \n",
    "reviews = reviews[reviews.rating >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c389eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard reviews by users outside our core group \n",
    "reviews = reviews[reviews.user_id.isin(set(users.user_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "015fcc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>5</td>\n",
       "      <td>B07H65KP63</td>\n",
       "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
       "      <td>2023-01-09 18:29:43.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>5</td>\n",
       "      <td>B0BC87S9SY</td>\n",
       "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
       "      <td>2023-01-01 00:38:53.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>5</td>\n",
       "      <td>B09B36FJVT</td>\n",
       "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
       "      <td>2023-01-01 00:28:42.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>5</td>\n",
       "      <td>B095KD3MNN</td>\n",
       "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
       "      <td>2022-11-26 21:08:54.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>5</td>\n",
       "      <td>B07Z18JVPH</td>\n",
       "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
       "      <td>2022-08-01 19:04:43.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568118</th>\n",
       "      <td>4</td>\n",
       "      <td>B004QGXWSQ</td>\n",
       "      <td>AEOGM6IKVQXQUUMQSLR2DCLDFFUA</td>\n",
       "      <td>2013-03-09 15:16:13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568119</th>\n",
       "      <td>5</td>\n",
       "      <td>B07961C64Q</td>\n",
       "      <td>AEOGM6IKVQXQUUMQSLR2DCLDFFUA</td>\n",
       "      <td>2013-03-09 15:10:31.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568121</th>\n",
       "      <td>5</td>\n",
       "      <td>B009RWAYTE</td>\n",
       "      <td>AEOGM6IKVQXQUUMQSLR2DCLDFFUA</td>\n",
       "      <td>2013-02-12 15:21:44.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568122</th>\n",
       "      <td>5</td>\n",
       "      <td>B07BSJCMGS</td>\n",
       "      <td>AEOGM6IKVQXQUUMQSLR2DCLDFFUA</td>\n",
       "      <td>2013-02-12 15:14:18.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568123</th>\n",
       "      <td>5</td>\n",
       "      <td>B00WWI9UW2</td>\n",
       "      <td>AEOGM6IKVQXQUUMQSLR2DCLDFFUA</td>\n",
       "      <td>2013-02-12 14:32:53.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7929 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating     item_id                       user_id  \\\n",
       "487           5  B07H65KP63  AFZUK3MTBIBEDQOPAK3OATUOUKLA   \n",
       "489           5  B0BC87S9SY  AFZUK3MTBIBEDQOPAK3OATUOUKLA   \n",
       "490           5  B09B36FJVT  AFZUK3MTBIBEDQOPAK3OATUOUKLA   \n",
       "491           5  B095KD3MNN  AFZUK3MTBIBEDQOPAK3OATUOUKLA   \n",
       "495           5  B07Z18JVPH  AFZUK3MTBIBEDQOPAK3OATUOUKLA   \n",
       "...         ...         ...                           ...   \n",
       "7568118       4  B004QGXWSQ  AEOGM6IKVQXQUUMQSLR2DCLDFFUA   \n",
       "7568119       5  B07961C64Q  AEOGM6IKVQXQUUMQSLR2DCLDFFUA   \n",
       "7568121       5  B009RWAYTE  AEOGM6IKVQXQUUMQSLR2DCLDFFUA   \n",
       "7568122       5  B07BSJCMGS  AEOGM6IKVQXQUUMQSLR2DCLDFFUA   \n",
       "7568123       5  B00WWI9UW2  AEOGM6IKVQXQUUMQSLR2DCLDFFUA   \n",
       "\n",
       "                      timestamp  \n",
       "487     2023-01-09 18:29:43.584  \n",
       "489     2023-01-01 00:38:53.148  \n",
       "490     2023-01-01 00:28:42.952  \n",
       "491     2022-11-26 21:08:54.526  \n",
       "495     2022-08-01 19:04:43.671  \n",
       "...                         ...  \n",
       "7568118 2013-03-09 15:16:13.000  \n",
       "7568119 2013-03-09 15:10:31.000  \n",
       "7568121 2013-02-12 15:21:44.000  \n",
       "7568122 2013-02-12 15:14:18.000  \n",
       "7568123 2013-02-12 14:32:53.000  \n",
       "\n",
       "[7929 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94423619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3067488"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_size = len(users) * len(items)\n",
    "matrix_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3bbe07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.datasets.sparse import AffinityMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a0a5f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1e12fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'item_id', 'user_id', 'timestamp'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "608aec7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>5</td>\n",
       "      <td>B07H65KP63</td>\n",
       "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
       "      <td>2023-01-09 18:29:43.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>5</td>\n",
       "      <td>B0BC87S9SY</td>\n",
       "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
       "      <td>2023-01-01 00:38:53.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>5</td>\n",
       "      <td>B09B36FJVT</td>\n",
       "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
       "      <td>2023-01-01 00:28:42.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>5</td>\n",
       "      <td>B095KD3MNN</td>\n",
       "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
       "      <td>2022-11-26 21:08:54.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>5</td>\n",
       "      <td>B07Z18JVPH</td>\n",
       "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
       "      <td>2022-08-01 19:04:43.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568118</th>\n",
       "      <td>4</td>\n",
       "      <td>B004QGXWSQ</td>\n",
       "      <td>AEOGM6IKVQXQUUMQSLR2DCLDFFUA</td>\n",
       "      <td>2013-03-09 15:16:13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568119</th>\n",
       "      <td>5</td>\n",
       "      <td>B07961C64Q</td>\n",
       "      <td>AEOGM6IKVQXQUUMQSLR2DCLDFFUA</td>\n",
       "      <td>2013-03-09 15:10:31.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568121</th>\n",
       "      <td>5</td>\n",
       "      <td>B009RWAYTE</td>\n",
       "      <td>AEOGM6IKVQXQUUMQSLR2DCLDFFUA</td>\n",
       "      <td>2013-02-12 15:21:44.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568122</th>\n",
       "      <td>5</td>\n",
       "      <td>B07BSJCMGS</td>\n",
       "      <td>AEOGM6IKVQXQUUMQSLR2DCLDFFUA</td>\n",
       "      <td>2013-02-12 15:14:18.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568123</th>\n",
       "      <td>5</td>\n",
       "      <td>B00WWI9UW2</td>\n",
       "      <td>AEOGM6IKVQXQUUMQSLR2DCLDFFUA</td>\n",
       "      <td>2013-02-12 14:32:53.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7929 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating     item_id                       user_id  \\\n",
       "487           5  B07H65KP63  AFZUK3MTBIBEDQOPAK3OATUOUKLA   \n",
       "489           5  B0BC87S9SY  AFZUK3MTBIBEDQOPAK3OATUOUKLA   \n",
       "490           5  B09B36FJVT  AFZUK3MTBIBEDQOPAK3OATUOUKLA   \n",
       "491           5  B095KD3MNN  AFZUK3MTBIBEDQOPAK3OATUOUKLA   \n",
       "495           5  B07Z18JVPH  AFZUK3MTBIBEDQOPAK3OATUOUKLA   \n",
       "...         ...         ...                           ...   \n",
       "7568118       4  B004QGXWSQ  AEOGM6IKVQXQUUMQSLR2DCLDFFUA   \n",
       "7568119       5  B07961C64Q  AEOGM6IKVQXQUUMQSLR2DCLDFFUA   \n",
       "7568121       5  B009RWAYTE  AEOGM6IKVQXQUUMQSLR2DCLDFFUA   \n",
       "7568122       5  B07BSJCMGS  AEOGM6IKVQXQUUMQSLR2DCLDFFUA   \n",
       "7568123       5  B00WWI9UW2  AEOGM6IKVQXQUUMQSLR2DCLDFFUA   \n",
       "\n",
       "                      timestamp  \n",
       "487     2023-01-09 18:29:43.584  \n",
       "489     2023-01-01 00:38:53.148  \n",
       "490     2023-01-01 00:28:42.952  \n",
       "491     2022-11-26 21:08:54.526  \n",
       "495     2022-08-01 19:04:43.671  \n",
       "...                         ...  \n",
       "7568118 2013-03-09 15:16:13.000  \n",
       "7568119 2013-03-09 15:10:31.000  \n",
       "7568121 2013-02-12 15:21:44.000  \n",
       "7568122 2013-02-12 15:14:18.000  \n",
       "7568123 2013-02-12 14:32:53.000  \n",
       "\n",
       "[7929 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a454f070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Strategy adapted from tutorials available in the Recommenders project, see \n",
    "# https://github.com/recommenders-team/recommenders/tree/main\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "\n",
    "# Split along user boundaries to ensure no leakage of preference between train and test\n",
    "train_users, test_users, val_users = python_random_split(users, [.9, .05, .05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "630664c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 2) (3, 2) (4, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_users.shape, test_users.shape, val_users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a4d4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reviews[reviews.user_id.isin(train_users.user_id)]\n",
    "val = reviews[reviews.user_id.isin(val_users.user_id)]\n",
    "test = reviews[reviews.user_id.isin(test_users.user_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06cc5ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7091, 4) (518, 4) (320, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc06db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technique from Recommenders (see https://github.com/recommenders-team/recommenders/blob/45e1b215a35e69b92390e16eb818d4528d0a33a2/examples/02_model_collaborative_filtering/standard_vae_deep_dive.ipynb) \n",
    "# to improve utility of validation set during training - only allow items in\n",
    "# the validation set that are also present in the train set\n",
    "val = val[val.item_id.isin(train.item_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3d5886f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bbcf82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/recommenders/datasets/python_splitters.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"random\"] = np.random.rand(data.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from recommenders.datasets.python_splitters import python_stratified_split \n",
    "\n",
    "# Another technique employed in Recommenders (see above link for notebook), for in-flight validation to be \n",
    "# meaningful during training, our validation set needs not just ground truth, but unseen validation samples \n",
    "# to see if predictions for validation users are relevant (to those users). Anyway, break down our val and test \n",
    "# sets again to support this strategy\n",
    "val_src, val_target = python_stratified_split(\n",
    "    data=val, \n",
    "    ratio=0.8, \n",
    "    filter_by=\"item\", \n",
    "    col_user=\"user_id\", \n",
    "    col_item=\"item_id\"\n",
    "    )\n",
    "test_src, test_target = python_stratified_split(\n",
    "    data=test, \n",
    "    ratio=0.8, \n",
    "    filter_by=\"item\", \n",
    "    col_user=\"user_id\", \n",
    "    col_item=\"item_id\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c16b6946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309, 5)  ->  (306, 4) (3, 4)\n",
      "(320, 5)  ->  (319, 4) (1, 4)\n"
     ]
    }
   ],
   "source": [
    "print(val.shape, \" -> \", val_src.shape, val_target.shape)\n",
    "print(test.shape, \" -> \", test_src.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e5b4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to use standard names across the analysis \n",
    "header = {\n",
    "        \"col_user\": \"user_id\",\n",
    "        \"col_item\": \"item_id\",\n",
    "        \"col_rating\": \"rating\",\n",
    "        # Unclear why this doesn't also eat a timestamp, but many of the functions that split temporally use, fortunately \n",
    "        # the column 'timestamp' (i.e. DEFAULT_TIMESTAMP_COL='timestamp') so I think we're fine. \n",
    "        # \"col_timestamp\" : \"timestamp\"\n",
    "    }\n",
    "\n",
    "train_matrix = AffinityMatrix(df=train, **header)\n",
    "val_matrix = AffinityMatrix(df=val, **header)\n",
    "val_src_matrix = AffinityMatrix(df=val_src, **header)\n",
    "val_tgt_matrix = AffinityMatrix(df=val_target, **header)\n",
    "test_src_matrix = AffinityMatrix(df=test_src, **header)\n",
    "test_tgt_matrix = AffinityMatrix(df=test_target, **header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c6664d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This generates a sparse array of user vectors, aka user-item matrix\n",
    "# X[0] is the first user in the list, with entries for all items known when the matrix was constructed in that row\n",
    "train, _, _ = train_matrix.gen_affinity_matrix()\n",
    "val, _, _ = val_matrix.gen_affinity_matrix() \n",
    "val_src, _, _ = val_src_matrix.gen_affinity_matrix()\n",
    "val_tgt, _, _ = val_tgt_matrix.gen_affinity_matrix()\n",
    "test_src, _, _ = test_src_matrix.gen_affinity_matrix()\n",
    "test_tgt, _, _ = test_src_matrix.gen_affinity_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70ed4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.utils.python_utils import binarize\n",
    "\n",
    "train = binarize(train, 3)\n",
    "val = binarize(train, 3)\n",
    "val_src = binarize(val_src, 3) \n",
    "val_tgt = binarize(val_tgt, 3)\n",
    "test_src = binarize(test_src, 3)\n",
    "test_tgt = binarize(test_tgt, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5d68d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021021061273729536"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Make sure this is reported during training/configuration\n",
    "sparsity = np.count_nonzero(train)/(train.shape[0]*train.shape[1])\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aaa640",
   "metadata": {},
   "source": [
    "## Model Design "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "585601b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.19.0'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "985102a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.models.vae.standard_vae import StandardVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be2bf5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752990895.769779 1988837 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16874 MB memory:  -> device: 0, name: NVIDIA RTX A5500, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = StandardVAE(\n",
    "    n_users = train.shape[0], \n",
    "    original_dim = train.shape[1],\n",
    "    intermediate_dim=250, \n",
    "    latent_dim=50, \n",
    "    n_epochs=1, \n",
    "    batch_size=1, \n",
    "    k=10, \n",
    "    verbose=1, \n",
    "    seed=4, \n",
    "    save_path=\"models/svae.hdf5\", \n",
    "    drop_encoder=0.5, \n",
    "    drop_decoder=0.5, \n",
    "    annealing=False, \n",
    "    beta=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76cc01bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/recommenders/models/vae/standard_vae.py:402: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  self.model.fit_generator(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1381, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1148, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1206, in compute_loss\n        return self.compiled_loss(\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/compile_utils.py\", line 329, in __call__\n        self._total_loss_mean.update_state(\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/utils/metrics_utils.py\", line 77, in decorated\n        result = update_state_fn(*args, **kwargs)\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/metrics/base_metric.py\", line 508, in update_state  **\n        sample_weight = tf.__internal__.ops.broadcast_weights(\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/keras_tensor.py\", line 290, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'tf.cast_2'\"), an intermediate TF-Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. TF-Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom TF-Keras layer `call` and calling that layer on this symbolic input/output.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx_val_tr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx_val_te\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_tgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school/deepcart/venv/lib/python3.12/site-packages/recommenders/models/vae/standard_vae.py:402\u001b[39m, in \u001b[36mStandardVAE.fit\u001b[39m\u001b[34m(self, x_train, x_valid, x_val_tr, x_val_te, mapper)\u001b[39m\n\u001b[32m    399\u001b[39m     \u001b[38;5;28mself\u001b[39m.ls_beta = anneal.get_data()\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnn_batch_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumber_of_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;66;03m# save lists\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;28mself\u001b[39m.train_loss = history.losses\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/training.py:2908\u001b[39m, in \u001b[36mModel.fit_generator\u001b[39m\u001b[34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[39m\n\u001b[32m   2896\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[32m   2897\u001b[39m \n\u001b[32m   2898\u001b[39m \u001b[33;03mDEPRECATED:\u001b[39;00m\n\u001b[32m   2899\u001b[39m \u001b[33;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[32m   2900\u001b[39m \u001b[33;03m  use this endpoint.\u001b[39;00m\n\u001b[32m   2901\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2902\u001b[39m warnings.warn(\n\u001b[32m   2903\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m`Model.fit_generator` is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2904\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future version. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2905\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2906\u001b[39m     stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   2907\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2908\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2910\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2911\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2913\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2919\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2921\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2922\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/__autograph_generated_filed58o08el.py:15\u001b[39m, in \u001b[36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     14\u001b[39m     do_return = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(\u001b[38;5;28mself\u001b[39m), ag__.ld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     17\u001b[39m     do_return = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: in user code:\n\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1381, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1148, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1206, in compute_loss\n        return self.compiled_loss(\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/compile_utils.py\", line 329, in __call__\n        self._total_loss_mean.update_state(\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/utils/metrics_utils.py\", line 77, in decorated\n        result = update_state_fn(*args, **kwargs)\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/metrics/base_metric.py\", line 508, in update_state  **\n        sample_weight = tf.__internal__.ops.broadcast_weights(\n    File \"/home/grim/projects/school/deepcart/venv/lib/python3.12/site-packages/tf_keras/src/engine/keras_tensor.py\", line 290, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'tf.cast_2'\"), an intermediate TF-Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. TF-Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom TF-Keras layer `call` and calling that layer on this symbolic input/output.\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train=train, \n",
    "    x_valid=val, \n",
    "    x_val_tr=val_src, \n",
    "    x_val_te=val_tgt, \n",
    "    mapper=val_matrix,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d4cbf",
   "metadata": {},
   "source": [
    "Managing text-based reviews at this scale could be a challenge, and I'd like to steer clear of LLMs for this effort. We could do an embedding on the review and use that for similarity, but we have pretty rich item data. Perhaps let's ignore the collaborative aspect here and build a shopping interface that: \n",
    "- surfaces the most popular items, and encourages you to add items to your shopping cart for a big discount/promo\n",
    "- based on clicks and cart items, improves the recommendations and surfaces new products\n",
    "\n",
    "We can use an autoencoder to accept a sparse matrix of users and items, learn to reproduce that matrix, and in so doing support prediction on missing values. However, this matrix is of size users x items, which here is 1.8e7 x 1.6e6 = 28,125,000,000 KB (best-case, higher if stored as np floats) ~= 26 TB !! WTF. \n",
    "- In the standard VAE example (https://github.com/recommenders-team/recommenders/blob/main/examples/02_model_collaborative_filtering/standard_vae_deep_dive.ipynb) the clicks are turned into a histogram for each user ... so we have n_user vector of length n_items... then I guess each of these is a training sample. The VAE presumably learns, given a sparse user vector, to predict every rating. This takes the complexity down and gives us a training set we can iterate over. \n",
    "\n",
    "Let's avoid any distributional pressure (present in VAE, SVAE, disentangled VAE) and go for a basic autoencoder using the strategy laid out above, i.e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891606e6",
   "metadata": {},
   "source": [
    "## Autoencoder Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder\n",
    "\n",
    "    NOTE: with cues from https://www.geeksforgeeks.org/deep-learning/implementing-an-autoencoder-in-pytorch/\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dims=1000):\n",
    "        \"\"\"\n",
    "        Initialize a new object \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(dims, 500),\n",
    "            nn.Linear(500, 75),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(75, 500),\n",
    "            nn.Linear(500, dims),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Implement our forward pass \n",
    "        \"\"\"\n",
    "        h = self.encoder(x) \n",
    "        r = self.decoder(h)\n",
    "\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d97ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCartDataset(torch.utils.data.Dataset): \n",
    "    \"\"\"\n",
    "    Custom pytorch-compatible dataset. Adapted from \n",
    "    https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n",
    "    \"\"\"\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None): \n",
    "\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "\n",
    "        #TODO: implement\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.img_labels) \n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        #TODO: implement\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(batch_size=5, shuffle=True): \n",
    "    \"\"\"\n",
    "    Retrieve a pytorch-style dataloader \n",
    "    \"\"\"\n",
    "\n",
    "    #TODO: implement\n",
    "    #transform = transforms.Compose([\n",
    "    #     transforms.ConvertImageDtype(torch.float),\n",
    "    #     transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    #])\n",
    "\n",
    "    #data = DeepCartDataset(transform=transform)\n",
    "    #loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    #return loader\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, loss_interval=20, epochs=2, lr=0.01, momentum=0.9):\n",
    "    \"\"\"\n",
    "    Train the model with the provided dataset\n",
    "\n",
    "    NOTE: this is a similar training loop as we used for our vision model in the \n",
    "    the vision project, forward pass\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    train_loss = []\n",
    "\n",
    "    tqdm.write(f\"Starting training run...\")    \n",
    "    # TODO: configure WandB\n",
    "    # see https://docs.wandb.ai/guides/integrations/pytorch/\n",
    "    config = {}\n",
    "    run = wandb.init(config=config) \n",
    "\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(loader):\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # collect metrics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (i % loss_interval) == (loss_interval - 1): \n",
    "                train_loss.append(running_loss / loss_interval)\n",
    "                tqdm.write(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / loss_interval:.3f}\")\n",
    "                running_loss = 0 \n",
    "    \n",
    "    tqdm.write(\"Training complete!\") \n",
    "\n",
    "    return train_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f6037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
