{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ad0120",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6aea5c",
   "metadata": {},
   "source": [
    "Python version spiral ... \n",
    "- > tf 2.11.0 introduced changes that break recommenders integration, need to step back in time \n",
    "- pyenv install 3.9\n",
    "- pyenv virtualenv 3.9 recommenders\n",
    "- pyenv uninstall recommenders\n",
    "- pyenv activate recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83962e5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module '_sqlite3'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "%set_env TF_USE_LEGACY_KERAS=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "914076d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 13:14:02.848350: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-20 13:14:02.892199: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-20 13:14:02.894005: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-07-20 13:14:02.894014: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-07-20 13:14:03.194331: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-07-20 13:14:03.194436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-07-20 13:14:03.194438: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1862e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_parquet(\"../data/2023/reviews_small.parquet\")\n",
    "items = pd.read_parquet(\"../data/2023/items_small.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8255337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>4</td>\n",
       "      <td>B07XXWZKBT</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-07-17 02:39:36.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>5</td>\n",
       "      <td>B0BRZFGB6R</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-07-17 02:38:29.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>3</td>\n",
       "      <td>B09VBWBHBC</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-07-17 02:22:03.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>5</td>\n",
       "      <td>B09GLQ2PFV</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-05-07 21:54:28.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>3</td>\n",
       "      <td>B084HM5WG1</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-03-06 17:53:00.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995511</th>\n",
       "      <td>5</td>\n",
       "      <td>B00CLFB3ZI</td>\n",
       "      <td>AEJVQFZNE5CH5TFE2EFOXSQ5LX6Q</td>\n",
       "      <td>2016-04-07 15:58:10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995512</th>\n",
       "      <td>5</td>\n",
       "      <td>B003C8RGJ0</td>\n",
       "      <td>AEJVQFZNE5CH5TFE2EFOXSQ5LX6Q</td>\n",
       "      <td>2015-04-22 17:15:34.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995513</th>\n",
       "      <td>4</td>\n",
       "      <td>B00B91KYV4</td>\n",
       "      <td>AEJVQFZNE5CH5TFE2EFOXSQ5LX6Q</td>\n",
       "      <td>2014-11-19 01:01:47.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995514</th>\n",
       "      <td>5</td>\n",
       "      <td>B004NDEWWW</td>\n",
       "      <td>AEJVQFZNE5CH5TFE2EFOXSQ5LX6Q</td>\n",
       "      <td>2014-09-05 02:12:45.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995515</th>\n",
       "      <td>3</td>\n",
       "      <td>B000255ICI</td>\n",
       "      <td>AEJVQFZNE5CH5TFE2EFOXSQ5LX6Q</td>\n",
       "      <td>2006-07-07 17:19:03.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21241 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating parent_asin                       user_id  \\\n",
       "3556          4  B07XXWZKBT  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "3557          5  B0BRZFGB6R  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "3558          3  B09VBWBHBC  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "3559          5  B09GLQ2PFV  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "3560          3  B084HM5WG1  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "...         ...         ...                           ...   \n",
       "9995511       5  B00CLFB3ZI  AEJVQFZNE5CH5TFE2EFOXSQ5LX6Q   \n",
       "9995512       5  B003C8RGJ0  AEJVQFZNE5CH5TFE2EFOXSQ5LX6Q   \n",
       "9995513       4  B00B91KYV4  AEJVQFZNE5CH5TFE2EFOXSQ5LX6Q   \n",
       "9995514       5  B004NDEWWW  AEJVQFZNE5CH5TFE2EFOXSQ5LX6Q   \n",
       "9995515       3  B000255ICI  AEJVQFZNE5CH5TFE2EFOXSQ5LX6Q   \n",
       "\n",
       "                      timestamp  \n",
       "3556    2022-07-17 02:39:36.234  \n",
       "3557    2022-07-17 02:38:29.878  \n",
       "3558    2022-07-17 02:22:03.994  \n",
       "3559    2022-05-07 21:54:28.387  \n",
       "3560    2022-03-06 17:53:00.543  \n",
       "...                         ...  \n",
       "9995511 2016-04-07 15:58:10.000  \n",
       "9995512 2015-04-22 17:15:34.000  \n",
       "9995513 2014-11-19 01:01:47.000  \n",
       "9995514 2014-09-05 02:12:45.000  \n",
       "9995515 2006-07-07 17:19:03.000  \n",
       "\n",
       "[21241 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5a83408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>images</th>\n",
       "      <th>parent_asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>KHOMO - iPad 2 3 and 4 Generation Case - DUAL ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2745</td>\n",
       "      <td>[KHOMO dual Series case choom introduces its b...</td>\n",
       "      <td>11.95</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B06XKRXLDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>HGST Touro Desk Pro 3TB USB 3.0 External Hard ...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>15</td>\n",
       "      <td>[Product Description, Hitachi Touro Desk Pro 3...</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B004W7DR02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Tiffen 77mm Photo Essentials Kit with UV Prote...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>576</td>\n",
       "      <td>[Product Description, This kit consists of a: ...</td>\n",
       "      <td>89.99</td>\n",
       "      <td>[{'hi_res': None, 'large': 'https://m.media-am...</td>\n",
       "      <td>B0067HY1EQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Technical Pro C-QS-1225 25' 1/4\" to Speakon Sp...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>11</td>\n",
       "      <td>[Available in 12 and 16 gauge speaker wire. Av...</td>\n",
       "      <td>15.95</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B0029L7IYY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>CaseBot Leather Case for Kindle Oasis (10th an...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1444</td>\n",
       "      <td>[CaseBot, a premium series brought to you by F...</td>\n",
       "      <td>7.99</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B07M67FJDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380025</th>\n",
       "      <td>MONICONA Air Tube Earpiece Surveillance Kit Ea...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35</td>\n",
       "      <td>[]</td>\n",
       "      <td>29.99</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B09N8YFX24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380045</th>\n",
       "      <td>Galaxy Tab S2 8.0 Case, IVSO Samsung Galaxy Ta...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>62</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': None, 'large': 'https://m.media-am...</td>\n",
       "      <td>B00UP5Q67Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380090</th>\n",
       "      <td>Drop Protected Case Cover Compatible with Airp...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>426</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B08CBV77FD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380577</th>\n",
       "      <td>Logitech iPad Pro 10.5 inch Keyboard Case | SL...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1581</td>\n",
       "      <td>[Slim Combo is the ultimate companion to your ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B0753223KN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541568</th>\n",
       "      <td>HDMI Audio Extractor 4K 120Hz, avedio links HD...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>543</td>\n",
       "      <td>[]</td>\n",
       "      <td>89.99</td>\n",
       "      <td>[{'hi_res': 'https://m.media-amazon.com/images...</td>\n",
       "      <td>B0CFL3SFTP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16433 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  average_rating  \\\n",
       "102      KHOMO - iPad 2 3 and 4 Generation Case - DUAL ...             4.5   \n",
       "140      HGST Touro Desk Pro 3TB USB 3.0 External Hard ...             3.2   \n",
       "153      Tiffen 77mm Photo Essentials Kit with UV Prote...             4.6   \n",
       "190      Technical Pro C-QS-1225 25' 1/4\" to Speakon Sp...             4.4   \n",
       "234      CaseBot Leather Case for Kindle Oasis (10th an...             4.5   \n",
       "...                                                    ...             ...   \n",
       "1380025  MONICONA Air Tube Earpiece Surveillance Kit Ea...             4.0   \n",
       "1380045  Galaxy Tab S2 8.0 Case, IVSO Samsung Galaxy Ta...             3.7   \n",
       "1380090  Drop Protected Case Cover Compatible with Airp...             4.1   \n",
       "1380577  Logitech iPad Pro 10.5 inch Keyboard Case | SL...             4.3   \n",
       "1541568  HDMI Audio Extractor 4K 120Hz, avedio links HD...             3.9   \n",
       "\n",
       "         rating_number                                        description  \\\n",
       "102               2745  [KHOMO dual Series case choom introduces its b...   \n",
       "140                 15  [Product Description, Hitachi Touro Desk Pro 3...   \n",
       "153                576  [Product Description, This kit consists of a: ...   \n",
       "190                 11  [Available in 12 and 16 gauge speaker wire. Av...   \n",
       "234               1444  [CaseBot, a premium series brought to you by F...   \n",
       "...                ...                                                ...   \n",
       "1380025             35                                                 []   \n",
       "1380045             62                                                 []   \n",
       "1380090            426                                                 []   \n",
       "1380577           1581  [Slim Combo is the ultimate companion to your ...   \n",
       "1541568            543                                                 []   \n",
       "\n",
       "         price                                             images parent_asin  \n",
       "102      11.95  [{'hi_res': 'https://m.media-amazon.com/images...  B06XKRXLDR  \n",
       "140       None  [{'hi_res': 'https://m.media-amazon.com/images...  B004W7DR02  \n",
       "153      89.99  [{'hi_res': None, 'large': 'https://m.media-am...  B0067HY1EQ  \n",
       "190      15.95  [{'hi_res': 'https://m.media-amazon.com/images...  B0029L7IYY  \n",
       "234       7.99  [{'hi_res': 'https://m.media-amazon.com/images...  B07M67FJDB  \n",
       "...        ...                                                ...         ...  \n",
       "1380025  29.99  [{'hi_res': 'https://m.media-amazon.com/images...  B09N8YFX24  \n",
       "1380045   None  [{'hi_res': None, 'large': 'https://m.media-am...  B00UP5Q67Q  \n",
       "1380090   None  [{'hi_res': 'https://m.media-amazon.com/images...  B08CBV77FD  \n",
       "1380577   None  [{'hi_res': 'https://m.media-amazon.com/images...  B0753223KN  \n",
       "1541568  89.99  [{'hi_res': 'https://m.media-amazon.com/images...  B0CFL3SFTP  \n",
       "\n",
       "[16433 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be17af",
   "metadata": {},
   "source": [
    "We need to build a compact user-centric representation of preference, collapse review data into a sparse matrix of user -> item preferences. There are some heuristics that need to be applied in the process: \n",
    "1. users with few interactions are a very weak signal -- without associations with multiple products, we are not teaching the model about positive associations\n",
    "2. products with few interactions are also a very weak signal -- we are looking to connect users and items that have tiny interaction graphs are not going to improve our macro-level predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00609d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13739"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: This should be a configuration option hyper parameter, we can relax this if training isn't suepr computationally expensive\n",
    "min_ratings = 50\n",
    "items = items[items.rating_number > min_ratings]\n",
    "len(items) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "042fac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_320665/1979523271.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews.rename(columns={'parent_asin':'item_id'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# The above item filtering serves to reduce the computational complexity as well as \n",
    "# reduce sparsity, before we filter reviews make sure we remove those associated with \n",
    "# dropped items\n",
    "all_items = set(items.parent_asin)\n",
    "reviews = reviews[reviews.parent_asin.isin(all_items)]\n",
    "reviews.rename(columns={'parent_asin':'item_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af200300",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = reviews.groupby(['user_id']).rating.count()\n",
    "users = pd.DataFrame(users).reset_index()\n",
    "users.rename(columns={'rating':'ratings'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae9b879e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE2254CLKQFGLVCWHFRAMSW4CNZQ</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE25DZNJUA4LF4CLKKF4QPT4FGTQ</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE25GLEND5ZFPDAQGUQYLMOZO6OQ</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE27EIR4TWXNPPU7T2BEY6KLOZPA</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AE2PYLWJATZRIBVWEPWEAWB6DHDQ</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>AHZH6HT3H7BJWXLHDXEDLBNVESDQ</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>AHZJI67Q35ZP6VYLCYPZNBY4EI6A</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>AHZRDAQ2DUMUE43OEIKOIIPJMU2Q</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>AHZVRZG2OPZCTDQCH5RWZL6AGKCA</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>AHZVW2SKT6BVLJCGXGPWNZL3IRZA</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user_id  ratings\n",
       "0    AE2254CLKQFGLVCWHFRAMSW4CNZQ       21\n",
       "1    AE25DZNJUA4LF4CLKKF4QPT4FGTQ       38\n",
       "2    AE25GLEND5ZFPDAQGUQYLMOZO6OQ       47\n",
       "3    AE27EIR4TWXNPPU7T2BEY6KLOZPA       27\n",
       "6    AE2PYLWJATZRIBVWEPWEAWB6DHDQ       16\n",
       "..                            ...      ...\n",
       "995  AHZH6HT3H7BJWXLHDXEDLBNVESDQ       24\n",
       "996  AHZJI67Q35ZP6VYLCYPZNBY4EI6A       18\n",
       "997  AHZRDAQ2DUMUE43OEIKOIIPJMU2Q       31\n",
       "998  AHZVRZG2OPZCTDQCH5RWZL6AGKCA       12\n",
       "999  AHZVW2SKT6BVLJCGXGPWNZL3IRZA       15\n",
       "\n",
       "[815 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a configuration parameter, as above ... relax if we don't have issues with compute\n",
    "min_reviews = 10\n",
    "users = users[users.ratings > min_reviews] \n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00344bd",
   "metadata": {},
   "source": [
    "❗in the notebook, ratings are thresholded ... do we need to follow suit? what are the ramifications if we don't? OH... in the notebook, a click is an interaction, there's no middle ground. the network is going to operate on 0s or 1s. by leaving low reviews in our matrix, the network would learn to recommend things users have interacted with, but not necessarily positively. our case is the same, a review is an interaction. we're aiming to recommend, and we should not want to recommend low reviews. so filter... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82e76856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: decide if we need to keep the low reviews around \n",
    "reviews = reviews[reviews.rating >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c389eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard reviews by users outside our core group \n",
    "reviews = reviews[reviews.user_id.isin(set(users.user_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "015fcc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>4</td>\n",
       "      <td>B07XXWZKBT</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-07-17 02:39:36.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>5</td>\n",
       "      <td>B0BRZFGB6R</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-07-17 02:38:29.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>3</td>\n",
       "      <td>B09VBWBHBC</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-07-17 02:22:03.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>5</td>\n",
       "      <td>B09GLQ2PFV</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-05-07 21:54:28.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>3</td>\n",
       "      <td>B084HM5WG1</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-03-06 17:53:00.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982314</th>\n",
       "      <td>3</td>\n",
       "      <td>B00E1CRC86</td>\n",
       "      <td>AFCFZWIEVL4RIJM66PUTOYA4LFIQ</td>\n",
       "      <td>2016-03-09 01:32:41.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982316</th>\n",
       "      <td>3</td>\n",
       "      <td>B004ZMG55I</td>\n",
       "      <td>AFCFZWIEVL4RIJM66PUTOYA4LFIQ</td>\n",
       "      <td>2016-03-09 01:32:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982317</th>\n",
       "      <td>4</td>\n",
       "      <td>B0033Z2BAQ</td>\n",
       "      <td>AFCFZWIEVL4RIJM66PUTOYA4LFIQ</td>\n",
       "      <td>2016-03-09 01:31:52.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982318</th>\n",
       "      <td>4</td>\n",
       "      <td>B019SU6YA2</td>\n",
       "      <td>AFCFZWIEVL4RIJM66PUTOYA4LFIQ</td>\n",
       "      <td>2016-03-09 01:31:47.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982320</th>\n",
       "      <td>3</td>\n",
       "      <td>B0085GULFA</td>\n",
       "      <td>AFCFZWIEVL4RIJM66PUTOYA4LFIQ</td>\n",
       "      <td>2016-03-09 01:31:29.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14819 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating     item_id                       user_id  \\\n",
       "3556          4  B07XXWZKBT  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "3557          5  B0BRZFGB6R  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "3558          3  B09VBWBHBC  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "3559          5  B09GLQ2PFV  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "3560          3  B084HM5WG1  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "...         ...         ...                           ...   \n",
       "9982314       3  B00E1CRC86  AFCFZWIEVL4RIJM66PUTOYA4LFIQ   \n",
       "9982316       3  B004ZMG55I  AFCFZWIEVL4RIJM66PUTOYA4LFIQ   \n",
       "9982317       4  B0033Z2BAQ  AFCFZWIEVL4RIJM66PUTOYA4LFIQ   \n",
       "9982318       4  B019SU6YA2  AFCFZWIEVL4RIJM66PUTOYA4LFIQ   \n",
       "9982320       3  B0085GULFA  AFCFZWIEVL4RIJM66PUTOYA4LFIQ   \n",
       "\n",
       "                      timestamp  \n",
       "3556    2022-07-17 02:39:36.234  \n",
       "3557    2022-07-17 02:38:29.878  \n",
       "3558    2022-07-17 02:22:03.994  \n",
       "3559    2022-05-07 21:54:28.387  \n",
       "3560    2022-03-06 17:53:00.543  \n",
       "...                         ...  \n",
       "9982314 2016-03-09 01:32:41.000  \n",
       "9982316 2016-03-09 01:32:00.000  \n",
       "9982317 2016-03-09 01:31:52.000  \n",
       "9982318 2016-03-09 01:31:47.000  \n",
       "9982320 2016-03-09 01:31:29.000  \n",
       "\n",
       "[14819 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94423619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11197285"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_size = len(users) * len(items)\n",
    "matrix_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3bbe07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.datasets.sparse import AffinityMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff7ffe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a0a5f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1e12fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'item_id', 'user_id', 'timestamp'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "608aec7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>4</td>\n",
       "      <td>B07XXWZKBT</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-07-17 02:39:36.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>5</td>\n",
       "      <td>B0BRZFGB6R</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-07-17 02:38:29.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>3</td>\n",
       "      <td>B09VBWBHBC</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-07-17 02:22:03.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>5</td>\n",
       "      <td>B09GLQ2PFV</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-05-07 21:54:28.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>3</td>\n",
       "      <td>B084HM5WG1</td>\n",
       "      <td>AHBZRDFYB2FWUAO63DCSF2VSTJ2Q</td>\n",
       "      <td>2022-03-06 17:53:00.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982314</th>\n",
       "      <td>3</td>\n",
       "      <td>B00E1CRC86</td>\n",
       "      <td>AFCFZWIEVL4RIJM66PUTOYA4LFIQ</td>\n",
       "      <td>2016-03-09 01:32:41.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982316</th>\n",
       "      <td>3</td>\n",
       "      <td>B004ZMG55I</td>\n",
       "      <td>AFCFZWIEVL4RIJM66PUTOYA4LFIQ</td>\n",
       "      <td>2016-03-09 01:32:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982317</th>\n",
       "      <td>4</td>\n",
       "      <td>B0033Z2BAQ</td>\n",
       "      <td>AFCFZWIEVL4RIJM66PUTOYA4LFIQ</td>\n",
       "      <td>2016-03-09 01:31:52.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982318</th>\n",
       "      <td>4</td>\n",
       "      <td>B019SU6YA2</td>\n",
       "      <td>AFCFZWIEVL4RIJM66PUTOYA4LFIQ</td>\n",
       "      <td>2016-03-09 01:31:47.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982320</th>\n",
       "      <td>3</td>\n",
       "      <td>B0085GULFA</td>\n",
       "      <td>AFCFZWIEVL4RIJM66PUTOYA4LFIQ</td>\n",
       "      <td>2016-03-09 01:31:29.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14819 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating     item_id                       user_id  \\\n",
       "3556          4  B07XXWZKBT  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "3557          5  B0BRZFGB6R  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "3558          3  B09VBWBHBC  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "3559          5  B09GLQ2PFV  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "3560          3  B084HM5WG1  AHBZRDFYB2FWUAO63DCSF2VSTJ2Q   \n",
       "...         ...         ...                           ...   \n",
       "9982314       3  B00E1CRC86  AFCFZWIEVL4RIJM66PUTOYA4LFIQ   \n",
       "9982316       3  B004ZMG55I  AFCFZWIEVL4RIJM66PUTOYA4LFIQ   \n",
       "9982317       4  B0033Z2BAQ  AFCFZWIEVL4RIJM66PUTOYA4LFIQ   \n",
       "9982318       4  B019SU6YA2  AFCFZWIEVL4RIJM66PUTOYA4LFIQ   \n",
       "9982320       3  B0085GULFA  AFCFZWIEVL4RIJM66PUTOYA4LFIQ   \n",
       "\n",
       "                      timestamp  \n",
       "3556    2022-07-17 02:39:36.234  \n",
       "3557    2022-07-17 02:38:29.878  \n",
       "3558    2022-07-17 02:22:03.994  \n",
       "3559    2022-05-07 21:54:28.387  \n",
       "3560    2022-03-06 17:53:00.543  \n",
       "...                         ...  \n",
       "9982314 2016-03-09 01:32:41.000  \n",
       "9982316 2016-03-09 01:32:00.000  \n",
       "9982317 2016-03-09 01:31:52.000  \n",
       "9982318 2016-03-09 01:31:47.000  \n",
       "9982320 2016-03-09 01:31:29.000  \n",
       "\n",
       "[14819 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a454f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Strategy adapted from tutorials available in the Recommenders project, see \n",
    "# https://github.com/recommenders-team/recommenders/tree/main\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "\n",
    "# Split along user boundaries to ensure no leakage of preference between train and test\n",
    "train_users, test_users, val_users = python_random_split(users, [.9, .05, .05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "630664c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(734, 2) (40, 2) (41, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_users.shape, test_users.shape, val_users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a4d4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reviews[reviews.user_id.isin(train_users.user_id)]\n",
    "val = reviews[reviews.user_id.isin(val_users.user_id)]\n",
    "test = reviews[reviews.user_id.isin(test_users.user_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06cc5ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13241, 4) (845, 4) (733, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc06db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technique from Recommenders (see https://github.com/recommenders-team/recommenders/blob/45e1b215a35e69b92390e16eb818d4528d0a33a2/examples/02_model_collaborative_filtering/standard_vae_deep_dive.ipynb) \n",
    "# to improve utility of validation set during training - only allow items in\n",
    "# the validation set that are also present in the train set\n",
    "val = val[val.item_id.isin(train.item_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3d5886f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bbcf82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.datasets.python_splitters import python_stratified_split \n",
    "\n",
    "# Another technique employed in Recommenders (see above link for notebook), for in-flight validation to be \n",
    "# meaningful during training, our validation set needs not just ground truth, but unseen validation samples \n",
    "# to see if predictions for validation users are relevant (to those users). Anyway, break down our val and test \n",
    "# sets again to support this strategy\n",
    "val_src, val_target = python_stratified_split(\n",
    "    data=val, \n",
    "    ratio=0.8, \n",
    "    filter_by=\"item\", \n",
    "    col_user=\"user_id\", \n",
    "    col_item=\"item_id\"\n",
    "    )\n",
    "test_src, test_target = python_stratified_split(\n",
    "    data=test, \n",
    "    ratio=0.8, \n",
    "    filter_by=\"item\", \n",
    "    col_user=\"user_id\", \n",
    "    col_item=\"item_id\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c16b6946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 4)  ->  (268, 4) (4, 4)\n",
      "(733, 4)  ->  (727, 4) (6, 4)\n"
     ]
    }
   ],
   "source": [
    "print(val.shape, \" -> \", val_src.shape, val_target.shape)\n",
    "print(test.shape, \" -> \", test_src.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e5b4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to use standard names across the analysis \n",
    "header = {\n",
    "        \"col_user\": \"user_id\",\n",
    "        \"col_item\": \"item_id\",\n",
    "        \"col_rating\": \"rating\",\n",
    "        # Unclear why this doesn't also eat a timestamp, but many of the functions that split temporally use, fortunately \n",
    "        # the column 'timestamp' (i.e. DEFAULT_TIMESTAMP_COL='timestamp') so I think we're fine. \n",
    "        # \"col_timestamp\" : \"timestamp\"\n",
    "    }\n",
    "\n",
    "train_matrix = AffinityMatrix(df=train, **header)\n",
    "val_matrix = AffinityMatrix(df=val, **header)\n",
    "val_src_matrix = AffinityMatrix(df=val_src, **header)\n",
    "val_tgt_matrix = AffinityMatrix(df=val_target, **header)\n",
    "test_src_matrix = AffinityMatrix(df=test_src, **header)\n",
    "test_tgt_matrix = AffinityMatrix(df=test_target, **header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c6664d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This generates a sparse array of user vectors, aka user-item matrix\n",
    "# X[0] is the first user in the list, with entries for all items known when the matrix was constructed in that row\n",
    "train, _, _ = train_matrix.gen_affinity_matrix()\n",
    "val, _, _ = val_matrix.gen_affinity_matrix() \n",
    "val_src, _, _ = val_src_matrix.gen_affinity_matrix()\n",
    "val_tgt, _, _ = val_tgt_matrix.gen_affinity_matrix()\n",
    "test_src, _, _ = test_src_matrix.gen_affinity_matrix()\n",
    "test_tgt, _, _ = test_src_matrix.gen_affinity_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70ed4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.utils.python_utils import binarize\n",
    "\n",
    "train = binarize(train, 3)\n",
    "val = binarize(train, 3)\n",
    "val_src = binarize(val_src, 3) \n",
    "val_tgt = binarize(val_tgt, 3)\n",
    "test_src = binarize(test_src, 3)\n",
    "test_tgt = binarize(test_tgt, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5d68d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.16%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Make sure this is reported during training/configuration\n",
    "sparsity = np.count_nonzero(train)/(train.shape[0]*train.shape[1])*100\n",
    "print(f\"sparsity: {sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aaa640",
   "metadata": {},
   "source": [
    "## Model Design "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "585601b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "985102a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.models.vae.standard_vae import StandardVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be2bf5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 13:19:13.671508: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-20 13:19:13.671627: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-07-20 13:19:13.671663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2025-07-20 13:19:13.671685: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2025-07-20 13:19:13.671706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2025-07-20 13:19:13.705663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2025-07-20 13:19:13.705701: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2025-07-20 13:19:13.705708: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-07-20 13:19:13.706697: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = StandardVAE(\n",
    "    n_users = train.shape[0], \n",
    "    original_dim = train.shape[1],\n",
    "    intermediate_dim=250, \n",
    "    latent_dim=50, \n",
    "    n_epochs=1, \n",
    "    batch_size=1, \n",
    "    k=10, \n",
    "    verbose=1, \n",
    "    seed=4, \n",
    "    save_path=\"models/svae.hdf5\", \n",
    "    drop_encoder=0.5, \n",
    "    drop_decoder=0.5, \n",
    "    annealing=False, \n",
    "    beta=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c56eb549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76cc01bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/recommenders/models/vae/standard_vae.py:402: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  self.model.fit_generator(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 317, in __call__\n        self._total_loss_mean.update_state(\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 477, in update_state  **\n        sample_weight = tf.__internal__.ops.broadcast_weights(\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/keras_tensor.py\", line 283, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'tf.cast_2'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_valid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_val_tr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_val_te\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_tgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recommenders/lib/python3.9/site-packages/recommenders/models/vae/standard_vae.py:402\u001b[0m, in \u001b[0;36mStandardVAE.fit\u001b[0;34m(self, x_train, x_valid, x_val_tr, x_val_te, mapper)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mls_beta \u001b[38;5;241m=\u001b[39m anneal\u001b[38;5;241m.\u001b[39mget_data()\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_batch_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumber_of_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# save lists\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mlosses\n",
      "File \u001b[0;32m~/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/training.py:2604\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2593\u001b[0m \n\u001b[1;32m   2594\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2595\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2597\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2598\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2599\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2600\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2601\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2602\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2603\u001b[0m )\n\u001b[0;32m-> 2604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filex6l5iwdd.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 317, in __call__\n        self._total_loss_mean.update_state(\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 477, in update_state  **\n        sample_weight = tf.__internal__.ops.broadcast_weights(\n    File \"/home/grim/.pyenv/versions/recommenders/lib/python3.9/site-packages/keras/engine/keras_tensor.py\", line 283, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'tf.cast_2'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train=train, \n",
    "    x_valid=val, \n",
    "    x_val_tr=val_src, \n",
    "    x_val_te=val_tgt, \n",
    "    mapper=val_matrix,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d4cbf",
   "metadata": {},
   "source": [
    "Managing text-based reviews at this scale could be a challenge, and I'd like to steer clear of LLMs for this effort. We could do an embedding on the review and use that for similarity, but we have pretty rich item data. Perhaps let's ignore the collaborative aspect here and build a shopping interface that: \n",
    "- surfaces the most popular items, and encourages you to add items to your shopping cart for a big discount/promo\n",
    "- based on clicks and cart items, improves the recommendations and surfaces new products\n",
    "\n",
    "We can use an autoencoder to accept a sparse matrix of users and items, learn to reproduce that matrix, and in so doing support prediction on missing values. However, this matrix is of size users x items, which here is 1.8e7 x 1.6e6 = 28,125,000,000 KB (best-case, higher if stored as np floats) ~= 26 TB !! WTF. \n",
    "- In the standard VAE example (https://github.com/recommenders-team/recommenders/blob/main/examples/02_model_collaborative_filtering/standard_vae_deep_dive.ipynb) the clicks are turned into a histogram for each user ... so we have n_user vector of length n_items... then I guess each of these is a training sample. The VAE presumably learns, given a sparse user vector, to predict every rating. This takes the complexity down and gives us a training set we can iterate over. \n",
    "\n",
    "Let's avoid any distributional pressure (present in VAE, SVAE, disentangled VAE) and go for a basic autoencoder using the strategy laid out above, i.e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891606e6",
   "metadata": {},
   "source": [
    "## Autoencoder Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder\n",
    "\n",
    "    NOTE: with cues from https://www.geeksforgeeks.org/deep-learning/implementing-an-autoencoder-in-pytorch/\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dims=1000):\n",
    "        \"\"\"\n",
    "        Initialize a new object \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(dims, 500),\n",
    "            nn.Linear(500, 75),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(75, 500),\n",
    "            nn.Linear(500, dims),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Implement our forward pass \n",
    "        \"\"\"\n",
    "        h = self.encoder(x) \n",
    "        r = self.decoder(h)\n",
    "\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d97ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCartDataset(torch.utils.data.Dataset): \n",
    "    \"\"\"\n",
    "    Custom pytorch-compatible dataset. Adapted from \n",
    "    https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n",
    "    \"\"\"\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None): \n",
    "\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "\n",
    "        #TODO: implement\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.img_labels) \n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        #TODO: implement\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(batch_size=5, shuffle=True): \n",
    "    \"\"\"\n",
    "    Retrieve a pytorch-style dataloader \n",
    "    \"\"\"\n",
    "\n",
    "    #TODO: implement\n",
    "    #transform = transforms.Compose([\n",
    "    #     transforms.ConvertImageDtype(torch.float),\n",
    "    #     transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    #])\n",
    "\n",
    "    #data = DeepCartDataset(transform=transform)\n",
    "    #loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    #return loader\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, loss_interval=20, epochs=2, lr=0.01, momentum=0.9):\n",
    "    \"\"\"\n",
    "    Train the model with the provided dataset\n",
    "\n",
    "    NOTE: this is a similar training loop as we used for our vision model in the \n",
    "    the vision project, forward pass\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    train_loss = []\n",
    "\n",
    "    tqdm.write(f\"Starting training run...\")    \n",
    "    # TODO: configure WandB\n",
    "    # see https://docs.wandb.ai/guides/integrations/pytorch/\n",
    "    config = {}\n",
    "    run = wandb.init(config=config) \n",
    "\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(loader):\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # collect metrics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (i % loss_interval) == (loss_interval - 1): \n",
    "                train_loss.append(running_loss / loss_interval)\n",
    "                tqdm.write(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / loss_interval:.3f}\")\n",
    "                running_loss = 0 \n",
    "    \n",
    "    tqdm.write(\"Training complete!\") \n",
    "\n",
    "    return train_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f6037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommenders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
